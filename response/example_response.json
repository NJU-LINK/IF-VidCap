{
    "clip_001": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- attire color: light green top, dark gray pants\n- carried items: a bag with a glowing blue part"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "the character runs forward|the character stops at the top of the hill"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. Small blue and white flowers are scattered among the grass.\n2. Distant mountains, a volcano with smoke, and a clear sky with some clouds are visible.\n3. The protagonist has light skin, brown hair, and is wearing a green shirt and dark pants."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Narrative: 游戏画面中一个角色在草地上向前奔跑，背景里能看到远处的火山。角色跑到一处高地后停下，前方展现出广阔的自然风景，火山在远处清晰可见。 ---"
        }
    ],
    "clip_002": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"main_event\": \"A man fires a gun, causing explosions and chaos among people and cars below.\",\n    \"sub_events\": [\"The man loads the gun\", \"He aims and shoots\", \"Vehicles explode\", \"People react to the blasts\"]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Sequence: The Terminator loads a grenade launcher; The Terminator aims a grenade launcher out of a window at a parking lot with police cars; The Terminator aims a grenade launcher out of a window at a parking lot with police cars; The Terminator fires a grenade launcher out of a window at a parking lot with police cars, hitting one of the police cars, which explodes; three police officers are caught in the explosion --End Sequence--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "night|1 man|1 gun|1 car explosion|3 cars"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man in a black leather jacket reloads a gun, then fires at a police car, causing it to explode and making nearby people fall to the ground."
        }
    ],
    "clip_003": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- green-haired child, pink\n- purple-haired child, purple and red\n- wolf-eared human, white and green\n- yellow-dressed person, yellow and white"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the information based on your instructions.\n\n| Entity | Clothing | Camera Focus |\n|---|---|---|\n| Green-haired Child | Pink coat | Focus |\n| Purple-haired Person | Purple shirt, red skirt | Focus |\n| Market Stalls | - | Background |\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"embracing\",\n  \"market\",\n  \"character\",\n  \"walking\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The marketplace has cobblestone streets. Fruit stalls on the left display vibrant produce. Stalls have colorful canopies—green, blue, pink. Customers, including a white - haired figure with a basket and people in varied attire, walk and interact. Two girls embrace in the center."
        }
    ],
    "clip_004": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Creature color: Orange\n- ID: 04114\n- Eye color: Red\n- Attire: Gloves (Green and black)"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The camera cuts (a type of camera movement where the shot changes abruptly) to a medium shot (showing the subjects from around the waist up) when the green monsters first appear."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Video Tags: Orange Suits, Green Monsters, Smoke, Running, Hand Signals|End|"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The green monsters look frightened and worried as they are approached by the suited figures."
        }
    ],
    "clip_005": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Sure, here is the table describing vehicles based on the video:\n\n| VehicleType | Color | Direction |\n| ----------- | ----------- | ----------- |\n| Volkswagen sedan      | Black       | Left |\n| Land Rover SUV      | Gray       | Left       |\n| Bus   | Blue and White        | Left  |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Black sedan: Medium shot, soft diffused lighting from overcast sky; Medium close - up, headlights create bright focal points against ambient light\n- Bus: Wide shot, even lighting with streetlights adding subtle brightness; Medium shot, reflections on bus windows show interplay of natural and artificial light"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A. The large historic building with multiple windows remains a constant backdrop throughout.\nB. Trees with autumn-colored leaves stay visible, providing a consistent natural element.\nC. Pedestrians walking near the intersection are present initially and then move out of the frame.\nD. Streetlights and traffic signals maintain their positions without any noticeable change.\nE. As the video progresses, different sections of the city street and buildings come into view as the camera follows the moving vehicles.\nF. A bus with illuminated signage appears in the later part of the video, moving across the frame."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here's the video description:\n\nThe scene is a city intersection with cars and a bus moving. A black car is turning left in front, followed by a green SUV and a sleek black sedan.  Yellow trees line the street, and buildings stand tall in the background.\n\nHere are two evidences to explain whether the photographer can reach the opposite side of the road at this time.\n- The traffic lights are red.\n- Someone is crossing the road."
        }
    ],
    "clip_006": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Power Bank Specs:\n| Feature | Description |\n| --- | --- |\n| built-in charging cable | Integrated cable for charging, no need for separate cables. |\n| size compared to tissue box | Smaller than a tissue box, compact and portable. |\n---End Specs"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Holding a power bank in hand; Showing different color power banks; Comparing power bank size with a small pack of tissue; Plugging phone into power bank."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here is the requested unordered list:\n\n- This power bank looks so cute.\n- It comes with a charging cable.\n- It is on sale for a low price.\n- It is smaller than a pack of facial tissue.\n- It has a 10000 mAh capacity.\n- It can charge a cell phone two or three times.\n- It charges quickly."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The person is holding a compact, rectangular-shaped power bank. It has a small black rectangle in the center of the charger. The colors include white, light pink, green, and purple. A short white cable is attached and tucked underneath it for easy storage. The power bank can be easily pulled out for charging a cell phone."
        }
    ],
    "clip_007": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- summer street with green trees and buildings\n- summer crosswalk with buildings and parked cars\n- autumn city road with bare trees and buildings\n- winter urban street with trees and buildings\n- spring street with green trees and buildings\n- the foliage and clothing suggest a transition through spring, summer, autumn, and winter"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Cinematic Script:\n\n- **Blue**\n1. Carries children to school.\n2. Rides bike.\n\n- **White**\n1. Takes the kids to the park.\n2. Crosses road.\n\n- **Beige**\n1. Delivers kids.\n2. Rides bike.\n\n- **Black**\n1. Goes straight to school.\n2. Drives through a city.\n\n- **Black**\n1. Goes for a walk with the kids.\n2. Rides bike.\n\n- **Blue**\n1. Takes a ride with kids.\n2. Carries child in hand.\n\nMothers on bikes with baby seats take their kids for a ride in the neighborhood."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A woman is riding a bicycle with one child seated in front and another at the back."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "There are a total of six women riding bicycles.\nA. Black.\nB. Olive green.\nC. Earth yellow."
        }
    ],
    "clip_008": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"playing cards\": \"red\",\n    \"black box\": \"black\",\n    \"background\": \"green\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "insert or put the playing cards into the box; show the box to the audience; block out the playing cards; show the vanished playing cards"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "- The magician inserts the deck into the black container.\n- The magician rubs the black container.\n- The magician shows the black container to be empty."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "看，一个人将一副扑克牌插入一个黑色盒子里，并且摩挲了一下，\n看，然后将其翻转，扑克牌竟然不见了，\n看，这可能是个魔术技巧。"
        }
    ],
    "clip_009": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- car\n- van\n- bicycle\n- truck"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here is the shot description:\nThe camera remains stationary, capturing the view from inside a vehicle waiting at an intersection in a city. Pedestrians cross the street in front of the vehicle, utilizing the crosswalk. A cyclist crosses the street going against traffic. Several vehicles remain stationary in the street, waiting for the red traffic light to change. The street is surrounded by tall buildings and trees. The sky is bright with a slight glare."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "- The car moves forward, with a large truck on the right; the traffic light ahead turns red.\n- A cyclist rides on the left, and pedestrians cross the zebra crossing.\n- Tall buildings line both sides, with trees and parked cars visible; a Verizon van drives by."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Car moves forward as cyclist rides left.\n2. Cyclist rides across crosswalk, pedestrians walk.\n3. Verizon van drives across crosswalk behind pedestrians."
        }
    ],
    "clip_010": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Bus Interior Summary: Passengers lie on seats, watch TV with underwater scenes, and use remotes. --End--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**SUPER**\n- *fabric*\n- *wood*\nHandmade with elaborate details, the bus offers luxurious interior spaces."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Red and yellow double - decker. Two doors open outside. Multiple doors open inside."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here are the video details:\nThe video shows a bus in Pakistan that has been converted into a luxurious mobile hotel. The passenger relaxes on a bed, watching TV. The passenger seems relaxed and satisfied with the amenities provided on this first-class bus."
        }
    ],
    "clip_011": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the video event descriptions:\n1. The video begins by showing the Guan Yin statue in the Qingshan scenic area of Dongguan, Guangdong.\n2. Next, there is a person in a red dress attached to a wire, riding a decorative peacock.\n3. Finally, the Guan Yin statue is shown from a close up perspective, and with a larger crowd surrounding it."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n[\n  {\"description\": \"Wide shot of a large **statue** of a woman in white robes, surrounded by buildings, against a blue sky backdrop.\"},\n  {\"description\": \"A long shot shows a woman in a red dress, appearing to fly on a colorful bird-like creature against a background of a green mountain and a distant white statue.\"},\n  {\"description\": \"Wide shot of a large **statue** of a woman surrounded by a crowd of people, with buildings and mountains in the background.\"}\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the 5 keywords for the video: statue, temple roof, flying, praying, people."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A large Guanyin statue is shown, then a woman in red rides a phoenix - shaped object, with crowds and incense smoke at the statue."
        }
    ],
    "clip_012": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, I'm ready to create the table.\n\n| Tree_ID | Color_Pattern | Shape |\n| ------------- | ------------- | ------------- |\n| 1 | Gray, Red | Snake-like |\n| 2 | Gray, Pink | Snake-like |\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here is the controlled video caption:\n1. The video shows two snake-like trees. The first tree is thicker, with scales in red, white, and black. The head of the tree points to the left, towards the lower right corner of the frame. The second tree is thinner, with scales in white and light-red. The head of the tree points upwards to the upper right corner of the frame.\n2.  The background features a misty forest scene with trees."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "\nHere are the JSON array of keywords:\n```json\n[\"snake trees\", \"mountain mist\", \"unique trees\", \"forest landscape\", \"serpentine trees\"]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "a. Snake-like tree 1 has *green* foliage and patterned scales in *white*, *black*, *red*.  \nb. Snake-like tree 2 has *green* foliage and scales in *white*, *pink*.  \nc. Background shows *green* trees, misty mountains, and a hazy sky."
        }
    ],
    "clip_013": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Attributes |\n|--|--|\n| Fox | Brown fur, small size, active movement |\n| Pond Liner | Black, large - scale, covers the pond, smooth surface |\n| Pond | Man - made, has water, surrounded by the pond liner |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The video is set in an outdoor area with a large pit covered by a slippery plastic sheet and some water inside. A fox **slips** while trying to climb up the slippery plastic sheet, then **slides** back down, and finally **runs** around on the plastic sheet."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. wide shot: show the pond with the fox in the distance\n2. medium shot: the fox attempts to climb up the pond's edge\n3. close shot: the fox slides down the pond's edge\n4. medium shot: the fox continues trying to find a way out"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A fox accidentally falls into a newly built pond, struggles to climb up the slippery slope, slides down repeatedly but keeps trying, showing determination and anxiety."
        }
    ],
    "clip_014": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here's the JSON array describing the dogs in the video:\n\n```json\n[\n  {\n    \"id\": 1,\n    \"color\": \"tan\",\n    \"key_action\": \"stopping puppy\"\n  },\n  {\n    \"id\": 2,\n    \"color\": \"tan\",\n    \"key_action\": \"standing\"\n  },\n  {\n    \"id\": 3,\n    \"color\": \"beige\",\n    \"key_action\": \"lying down\"\n  }\n]\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera focuses on the two standing dogs near the table with food.\n2. The camera shifts focus to the dog lying on the ground.\n3. The camera focuses back on the two standing dogs, then shifts to the dog lying on the ground again.\n4. The camera focuses on the interaction between the larger dog and the smaller dog, with the larger dog placing a paw on the smaller dog's head.\n5. The camera shifts to a close - up of the larger dog's face and then to the interaction where the larger dog has a paw on the smaller dog's head while food on a stick is nearby.\n6. The camera focuses on the three dogs together, with the larger dog on top of the smaller ones."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"dog\",\n  \"puppy\",\n  \"sitting\",\n  \"grabbing\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here are the controlled video captions:\nA. The dog is being protective!.\nB. The puppy is being impatient!."
        }
    ],
    "clip_015": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Sure, here are the architectural features of the palace complex:\n\n- Red walls\n- Buildings with golden roofs\n- Courtyards and walkways"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here's my description of the video:\nThe video showcases the architectural magnificence of the Ming and Qing Dynasties, as seen from above. The drone shot displays the entire complex, emphasizing its size and complexity. The video also shows the vast complex where people have congregated, either to experience the history or to participate in cultural events. As the camera zooms in, more details of the architecture and the people below come into focus."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the keywords for the video:\nZhejiang, Ming and Qing Palace, Forbidden City, replica, architecture."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "看！这儿有一个好大的宫殿。它的墙是红色的，房顶是黄色的。有好多人到这里来玩儿，还有人在中间表演。"
        }
    ],
    "clip_016": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"entities\": [\"red truck\", \"dragon\", \"road\", \"mountains\"],\"main_event\": \"A red truck drives on a road, encounters a dragon, and there are dynamic scenes including the truck moving towards the dragon's open mouth, with text overlays appearing.\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera tracks a red truck driving toward the viewer.\n2. The camera pans from a road in a mountain range to a CGI dinosaur roaring at the vehicle."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A red truck drives on an open road. The landscape is barren and mountainous. An animated dinosaur appears, roaring at the truck. Text is displayed on the screen in both Chinese and English."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Ad Summary: A Red Dayun Truck Drives On A Mountain Road, With A Dragon Roaring And Explosions Occurring, Emphasizing Power And Adventure."
        }
    ],
    "clip_017": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Key Attributes |\n| ----------- | ----------- |\n| Hawk | Brown, black, and white feathers, yellow legs, sharp talons, piercing yellow eyes |\n| Snake | Light brown and yellow scales, long and slender body |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "hawk grips snake with claws; snake wraps around hawk's body; hawk struggles as snake tightens its coils"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: [\"raptor\", \"struggle\", \"attack\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A hawk grips a snake with its talons, the snake wraps around the hawk, and they struggle on the ground."
        }
    ],
    "clip_018": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"color\": \"gray\", \"mouth_feature\": \"wide open\", \"length\": \"50 meters\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera first shows a wide shot of a mountain with dense vegetation, focusing on a structure marked by a red circle, which is the snake statue.\n2. The camera then zooms in towards the snake statue, capturing the details of the statue on the bridge structure.\n3. The camera continues to zoom in, focusing on the head of the snake statue, showing its open mouth and detailed features.\n4. Finally, the camera zooms out to show the entire snake statue and its surrounding mountainous and forested environment."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. Drone\n2. Mountain\n3. Snake sculpture\n4. Stairs\n5. Awe\n1. Drone: The video was captured using a drone, providing aerial views of the landscape and the snake sculpture.\n2. Mountain: The background environment is a lush, green mountain range, creating a dramatic backdrop for the sculpture.\n3. Snake sculpture: The primary man-made object is a large, elaborate snake sculpture winding its way up the mountain.\n4. Stairs:  A staircase is integrated into the snake sculpture, allowing people to climb within it.\n5. Awe: The photographer appears to be in awe of the impressive size and artistic design of the snake sculpture in its natural setting."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In the deep mountains of Hubei, a giant python sculpture is coiled around a stone bridge, with its mouth wide open."
        }
    ],
    "clip_019": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[\n  {\n    \"name\": \"东方明珠电视塔\",\n    \"country\": \"中国\",\n    \"height\": 468\n  },\n  {\n    \"name\": \"帝国大厦\",\n    \"country\": \"美国\",\n    \"height\": 443\n  },\n  {\n    \"name\": \"广州塔\",\n    \"country\": \"中国\",\n    \"height\": 600\n  },\n  {\n    \"name\": \"晴空塔\",\n    \"country\": \"日本\",\n    \"height\": 634\n  },\n  {\n    \"name\": \"哈利发塔\",\n    \"country\": \"阿联酋\",\n    \"height\": 828\n  }\n]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Burj Khalifa (828 meters), Tokyo Skytree (634 meters), and Canton Tower (600 meters).\n\n| Tower           | Structural Feature                                                                                                                                                                                                 |\n| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| Burj Khalifa   | An iconic skyscraper with a distinctive triple-lobed footprint, tapering upwards to a Y-shaped plan. It features a central core and buttressed wings, providing stability against wind and seismic forces.            |\n| Tokyo Skytree  | A hybrid structure blending steel framework with reinforced concrete, optimized for earthquake resistance. It utilizes a central column as a core for stability and incorporates dampers to minimize oscillations. |\n| Canton Tower     | Characterized by its hyperboloid shape, resembling a twisted hourglass, with a hollow core structure. Its lattice framework is designed for wind resistance and provides unobstructed panoramic views.                     |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"828\", \"634\", \"tower\", \"landmark\", \"comparison\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "看！这是一个比较不同塔高的图片。最高的是哈利法塔，828米，真高呀！旁边是晴空塔，634米。还有广州塔，600米。他们都好高好高！"
        }
    ],
    "clip_020": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Objects:\n{\n  \"color\": \"yellow\",\n  \"container\": \"bowl\"\n}\nEnd Objects"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. insert a needle into the durian pulp\n2. pull out the needle from the durian pulp\n3. insert a needle into the durian pulp\n4. pull out the needle from the durian pulp\n5. place the needle on the edge of the plate"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Durian | piercing | anger."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The videographer is clearly upset with his girlfriend, which is shown by the needle being pushed into the durian. The needle appears golden at first, but fades to black."
        }
    ],
    "clip_021": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"mother fish\": [\"pushing baby fish's stroller\", \"holding a jar of food and a blob of food\", \"feeding baby fish\", \"giving a thumbs-up\"], \"baby fish\": [\"crying\", \"being fed\", \"eating\"]}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Entity | Primary_Action |\n| ----------- | ----------- |\n| Green Fish Woman | Red and purple dress with blonde wig |\n| Baby Fish | White diaper and bib |\n\nThe baby is initially crying, but when the fish woman feeds it peanut butter, it becomes happy and content.\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "fish woman, fish baby, feeding, crying, peanut butter"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! There is a mom fish giving her baby fish some food. The baby fish is crying, but then the mom gives it a spoonful of food and the baby fish is happy. The baby fish is covered in food and loves it.\n"
        }
    ],
    "clip_022": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. The character in blue is squatting and adjusting the fish on a stick above the fire.\n2. The character in blue is squatting and looking at the fire."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Two women are camping. One, with black hair and a blue outfit, cooks fish over a fire in a bamboo forest. The fish is burning."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "bamboo forest, cooking, woman, fish"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman in blue **squats** down to place firewood on the ground, then **reaches out** to adjust the skewered fish over the fire, while another woman in pink leans forward slightly."
        }
    ],
    "clip_023": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| vehicle_type | color | state |\n| ------------- |-------------|-------------|\n| Kia Soul | Green | Crashing |\n| Van | Dark Blue | Parked |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "-*The camera remains static on the house's front facade*\n-*The camera moves inside the house following the men with guns*\n\n- Car crashes through the wall\n- Collapsed wall\n- Cracked ceiling"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "4\n1. Black clothes, black hair.\n2. Black clothes, blond hair.\n3. Black clothes, brown hair.\n4. Black clothes, black hair."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! A green car speeds, crashes through a fence, flips, and smashes into a house, then people with guns run towards the car. (看！一辆绿色的汽车飞速行驶，撞破围栏，翻转后冲进一所房子，然后一群持枪的人朝汽车跑去。)"
        }
    ],
    "clip_024": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Description | Primary Attribute |\n|-------------|-------------|-------------------|\n| person | Female astronaut with brown hair in a ponytail, wearing a blue NASA jumpsuit, operating controls inside a spacecraft | Operating spacecraft controls |\n| object | Space shuttle in space with open cargo bay, robotic arm extended, and debris floating around | In space with open cargo bay |\n| object | Robotic arm attached to the space shuttle, moving and interacting with the shuttle and space environment | Maneuverability in space |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera starts with a close - up shot of a woman speaking.\n2. Then, the camera zooms out to show the woman operating the equipment inside the spacecraft.\n3. Next, the camera switches to an external shot of the spacecraft, where the mechanical arm on the spacecraft is moving, and finally, the mechanical arm ejects two astronauts."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n  \"Woman\": {\n    \"action\": [\n      \"Operating controls\",\n      \"Looking concerned\"\n    ],\n    \"interaction\": []\n  },\n  \"Robotic arm\": {\n    \"action\": [\n      \"extending\",\n      \"moving\"\n    ],\n    \"interaction\": [\n      \"Two astronauts\"\n    ]\n  },\n  \"Two astronauts\": {\n    \"action\": [\n      \"standing in the cargo bay of space shuttle\"\n    ],\n    \"interaction\": [\n      \"Robotic arm\"\n    ]\n  }\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Alert: Anxious astronaut operates controls; shuttle's robotic arm moves, debris floats -Urgent"
        }
    ],
    "clip_025": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- green dragon, purple outfit\n- brown dragon, purple outfit\n- brown dragon, green outfit\n- green dragon, dark outfit"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The camera remains mostly steady, slightly tracking the movement of characters riding dragons through a sky filled with pink and purple clouds; the scene is illuminated with soft, warm lighting that highlights the vibrant colors of the sky and the characters' surroundings."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  \"cartoon\",\n  \"animation\",\n  \"green\",\n  \"brown\",\n  \"clouds\"\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! Characters riding dragons soar joyfully, free and exhilarated under the sky."
        }
    ],
    "clip_026": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Video Cars: {\n      \"color\": \"blue\",\n      \"interior_features\": [\n        \"steering wheel\",\n        \"rearview mirror\",\n        \"dashboard\"\n      ]\n    }"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Scene: A man in a gray coat and a woman in a **turquoise** coat walk side - by - side on a sidewalk lined with brownstone buildings and parked cars."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "The camera is inside a vehicle.\nThe camera pans right, following people walking on the sidewalk."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From inside a blue vintage car, the driver watches as a couple strolls along the sidewalk past parked cars and the stoops of brick buildings on a cloudy day."
        }
    ],
    "clip_027": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Actions:\n1. Hold the rice cooker with the left hand.\n2. Shine a flashlight on the rice cooker.\nEnd of Actions."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Element Type       | Description                                                                 |\n|---------------------|-----------------------------------------------------------------------------|\n| Person's Attire     | **Dark green jacket**, **dark green pants**, **helmet with clear visor**    |\n| Lighting Condition  | Low overall brightness; light source is a flashlight held by the person     |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: Inspecting cooker, bomb suit, kitchen."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A person in protective gear holds a flashlight, shines it on a rice cooker, and then moves closer to observe."
        }
    ],
    "clip_028": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- attire: black suit with cape\n- headgear: black bat-shaped mask\n- belt: tan utility belt\n- pose: standing with right arm raised and left arm extended"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera initially focuses on a Batman figurine, then the figurine gradually blurs and moves downward.\n2. The camera shifts focus to a man in a green shirt standing with his back to the camera in a kitchen, placing a lid on a pot on the stove."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: Batman, Figure, Kitchen, Cooking, Apron"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. Black Batman figure stands; person in green stirs pot --End of description--\nB. Batman figure blurs; person covers pot with lid --End of description--"
        }
    ],
    "clip_029": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"trapped\": {\n    \"clothing_color\": \"white\",\n    \"action\": \"laying under the rock\"\n  },\n  \"pusher1\": {\n    \"clothing_color\": \"white\",\n    \"action\": \"pushing the rock\"\n  },\n  \"pusher2\": {\n    \"clothing_color\": \"dark blue\",\n    \"action\": \"pushing the rock\"\n  }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Camera Focus       | Character Position                                                                 | Rock Interaction                                                                 |\n|--------------------|-------------------------------------------------------------------------------------|----------------------------------------------------------------------------------|\n| Wide then close-up | Two standing (one in white, one in dark), one lying under rock; all near large rock | Two push rock from top, one pushes from below; rock shifts slightly as they push |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"distress\", \"rocky riverbank\", \"boulder\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Scene: On a rocky shore, a man in white lies trapped under a large object while a woman in white and a man in dark clothing push the object to free him, showing urgency and concern. The man in white appears to be in pain as they struggle, and the camera shifts to focus on his strained expression. --End--"
        }
    ],
    "clip_030": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Action: The woman in white drinks water;\n2. Action: The woman in purple gestures while talking;\n3. Action: The woman in purple picks up a cup and clinks it with the woman in white;"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Camera Movement | Primary Action |\n|-----------------|----------------|\n| Stationary      | Two women are sitting at a table; the woman in white drinks from a cup while the woman in purple talks, gestures, and then clinks her cup with the woman in white's cup. |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A break room features a metallic table where meals are set out, alongside a water cooler in the background."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! Two women sit at a table, one in a white top drinks from a blue cup while the other in a purple tracksuit talks animatedly, then they clink cups; they seem cheerful and engaged."
        }
    ],
    "clip_031": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[{\"name\":\"Snoopy\",\"static_attributes\": {\n        \"color\": \"white\",\n        \"attire\": \"green helmet red scarf\"\n    },\n\"actions\":[\"flying\",\"clenching fists\",\"turning head\",\"extending hand\"]},{\"name\":\"Fifi\",\"static_attributes\": {\n        \"color\": \"pink\",\n        \"attire\": \"purple scarf\"\n    },\"actions\":[\"flying\",\"extending hand\",\"falling\"]}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Shot 1  \n**White dog sits on red plane, flies forward.** Sky and clouds in background.  \n\n---  \n\n## Shot 2  \n**Red plane flies alongside moving train on bridge.** Green landscape below.  \n\n---  \n\n## Shot 3  \n**White dog approaches pink dog on red plane.** Pink dog’s scarf floats away mid-air."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"train\", \"bridge\", \"plane\", \"snoopy\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A white dog flies a red plane, chases a train, approaches a pink dog on another plane, and the pink dog's scarf falls off."
        }
    ],
    "clip_032": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n[\n  {\"role\": \"Man with light gray shirt\", \"action\": \"Thumbs up\"},\n  {\"role\": \"Man with red shirt\", \"action\": \"Pitches the kickball\"},\n  {\"role\": \"Female in the distance\", \"action\": \"Running\"},\n  {\"role\": \"Man with light gray shirt\", \"action\": \"He is running\"},\n  {\"role\": \"Man with red shirt\", \"action\": \"Catches the kickball\"}\n]\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Shot Type | Primary Action | Background Elements |\n| --- | --- | --- |\n| Medium | Man in gray shirt **sticks out tongue** and **gives a thumbs - up**; others stand | Chain - link fence, green padding, misty atmosphere |\n| Medium | Man in red shirt **pitches** a red ball | Grass field, buildings, misty atmosphere |\n| Medium | Man in gray shirt **kicks** ball; then man in red shirt **catches** ball | Dirt field, green padding, chain - link fence, misty atmosphere |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"pitch\", \"kick\", \"catch\", \"ball\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here is a summary of the video in one sentence:\n\nThis video depicts a kickball game; a player kicks the ball, while another player prepares to catch, and other individuals are on the field, including the referee.\n"
        }
    ],
    "clip_033": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Analysis: {\"man_attributes\":{\"appearance\":\"bald, with a gray beard\",\"clothing\":\"white short - sleeved shirt with patterns\"}},\"actions\":[\"take the item from the other hand\",\"examine the item\",\"put the item in the mouth and chew\"]} --End--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The light shines through a window onto the man as he examines a small object. The lighting appears to be soft, which highlights his white patterned shirt. The camera focuses on his hands and face as he brings the item closer to his eyes. A desk lamp sits to the side."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "hand over, take item, examine item, eat, elderly man"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A hand extends from the left of the screen to give an item to a man in a white shirt; the man takes the item, examines it, puts it in his mouth, chews, and then looks up to the left of the screen."
        }
    ],
    "clip_034": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity   | Attributes                |\n|----------|---------------------------|\n| Man      | beige shirt, holds handgun|\n| Woman    | black dress, holds umbrella|\n| Handgun  | black, on table           |\n| Blue Umbrella | closed, wooden handle |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"description\": \"Man In Beige Shirt With Hands Raised\",\n        \"is_threat\": false\n    },\n    {\n        \"description\": \"Woman In Black Dress Holding Umbrella\",\n        \"is_threat\": false\n    },\n    {\n        \"description\": \"**Handgun** On Table And Pointed At Man\",\n        \"is_threat\": true\n    },\n    {\n        \"description\": \"Closed Blue Umbrella Held By Woman\",\n        \"is_threat\": false\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"handgun\", \"standoff\", \"umbrella\", \"tension\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man in a beige shirt raises his hands, showing fear or surrender, as a woman in black holds an umbrella toward him. The woman then picks up a gun and aims it at the man."
        }
    ],
    "clip_035": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[{\"event_id\":1,\"description\":\"A man in black suit looks down and speaks.\"},{\"event_id\":2,\"description\":\"A man in gray suit sits on sofa.\"},{\"event_id\":3,\"description\":\"The man in black suit walks towards the window.\"},{\"event_id\":4,\"description\":\"The man in gray suit stands up and walks away.\"},{\"event_id\":5,\"description\":\"The man in black suit puts hands in pockets.\"}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. A figure on the left exits the frame, the standing man lowers his left hand, then takes two steps to the left, while the seated man raises his hands and stands up, then walks to the left.\n2. The man who was walking to the left stops, turns around, places his hands on his hips, and the other man continues walking left and exits the frame."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "man stands and speaks,man stands up from sofa|teapot,teacup"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here are the descriptions of the actions in a table format:\n\n| Time  | Action Description                                           |\n| :---- | :----------------------------------------------------------- |\n| 0:00  | A man in a suit stands and looks out at the cityscape through the large windows. |\n| 0:03  | Another man, also in a suit, who was sitting on a sofa, stands up and begins to walk away from the cityscape. |\n| 0:05  | The first man continues to stand and look out at the cityscape view. |"
        }
    ],
    "clip_036": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": " - attire: blue camouflage uniform, white gloves, blue camouflage cap\n - color: blue (uniform), white (gloves), blue (cap)"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here are the descriptions of the person's actions:\n\n-The person adjusts the device; **he is wearing blue camouflage clothes, black shoes and cap**.\n\n-The person is holding a red fire extinguisher and walking towards the electrical panel;  **he is wearing blue camouflage clothes, black shoes and cap**.\n\n-The person is adjusting the device; **he is wearing blue camouflage clothes, black shoes and cap**."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"soldier\", \"fire extinguisher\", \"submarine\", \"equipment\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A person in camouflage uniform moves quickly through a mechanical room, grabs a fire extinguisher, and aims it at equipment, likely to extinguish a fire or address a hazard."
        }
    ],
    "clip_037": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[{\"attire_color\":\"gray\",\"action\":\"walk\",\"interaction\":\"none\"},{\"attire_color\":\"black\",\"action\":\"walk\",\"interaction\":\"none\"},{\"attire_color\":\"gray\",\"action\":\"walk\",\"interaction\":\"approach\"},{\"attire_color\":\"black\",\"action\":\"bow\",\"interaction\":\"greet\"}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Two men in traditional clothing walk past a rock display; the two men continue walking past a stone table with a man sitting at it."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"ancient china\",\n  \"men\",\n  \"courtyard\",\n  \"asian clothing\",\n  \"stone table\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Two somber men in traditional clothes walk towards another man in a courtyard. The two men arrive at a stone table where the other man is seated, looking at a game. The men seem serious and perhaps concerned as they approach and observe the man at the table. It looks like they are waiting for him to finish the game."
        }
    ],
    "clip_038": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"man\": {\n    \"mood\": \"surprised\",\n    \"clothing\": \"trench coat, shirt, tie\",\n    \"hair color\": \"black\",\n    \"action\": \"peeking\"\n  },\n  \"stick\": {\n    \"material\": \"wood\",\n    \"attachment\": \"none\",\n    \"holder\": \"man\",\n    \"function\": \"unknown\"\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"entities\": [\n            {\n                \"description\": \"Man holding stick with white cloth\",\n                \"is_key_subject\": true\n            },\n            {\n                \"description\": \"Mound of earth\",\n                \"is_key_subject\": false\n            }\n        ],\n        \"transition\": {\n            \"type\": \"pan\",\n            \"direction\": \"left\"\n        }\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "white flag, pole, man"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "He seems tense as he holds a stick with a white cloth, likely due to being in a cautious or alert situation. He appears wary while gripping the stick, possibly because of the surrounding environment or an imminent concern. He looks apprehensive holding the stick, which might be a response to potential danger or uncertainty in his surroundings."
        }
    ],
    "clip_039": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Type | Description |\n|------|-------------|\n| Person | A person in traditional Chinese attire with a dark outer robe and white inner garment, receiving and examining a scroll. |\n| Person | A person in armor, handing over a scroll to the seated person. |\n| Object | A scroll being exchanged and examined. |\n| Object | Bamboo slips on a table. |\n| Object | A dark - colored box on the table. |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**Zhuge Liang** wears traditional robes; **the soldier** wears armor. The table has scrolls, tools, and a box. The armored person hands a scroll to Zhuge Liang, who takes it, unfolds, and examines it."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "robe, armor, scroll, hand over, unfold"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In the video: A soldier hands a scroll to a man in traditional attire, who then unfolds and examines it."
        }
    ],
    "clip_040": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"action\": \"reading book\", \"emotion\": \"happy\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Shot Type | Camera Movement | Primary Action |\n|-----------|-----------------|----------------|\n| Close-up (hands) to Medium (upper body) | Tilt up | **A person in traditional attire flips through a book, then looks up and smiles** |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: book, hairstyle, robe;;"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. A woman flips through the pages of a book.\n2. The woman closes the book.\n3. The woman looks up and smiles."
        }
    ],
    "clip_041": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Character Attributes:{\"woman\":{\"clothing\":[\"gray coat\",\"red scarf\",\"striped top\"]},\"man\":{\"clothing\":[\"dark blue jacket\",\"khaki pants\"]}}End of Attributes"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Entity | Type | Attributes |\n| --- | --- | --- |\n| Woman | Person | long black hair, gray coat, red scarf, striped shirt |\n| Man | Person | blue jacket, khaki pants, extends hand |\n| Bouquet | Object | purple wrapping, held by woman then man |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "woman, man, stairs, hand, umbrella"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman with long black hair, a red scarf, and a gray coat is holding a bouquet of purple items wrapped in clear plastic as she stands on wooden stairs, and a man in a blue jacket and khaki pants is reaching out to help her up the stairs."
        }
    ],
    "clip_042": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Middle - aged man: gray suit, white shirt\n- Young woman: white short - sleeved shirt with red letters, purple pants\n- Elderly woman: purple floral dress"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Shot Script: **A man** opens the door and enters the room, looking at **an elderly woman** and **a young woman**. The young woman is kneeling, holding the elderly woman's leg, then helps the elderly woman stretch her leg. The man stands by the door, observing. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Fu decoration on door|Man enters room|Girl massages old lady|Old lady sits on chair"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The young woman is massaging an older woman's leg. A man enters the room. The young woman looks up at the man."
        }
    ],
    "clip_043": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- black short-sleeved shirt\n- khaki tactical vest\n- black pants\n- black gloves\n- black boots\n- holstered item (possibly a weapon) on the waist"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Sequence: A man runs along a forest path, reaches a wooden structure, and begins to climb it. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here's the JSON array based on the video:\n```json\n[\n  {\"environment\": \"forest\"},\n  {\"building\": \"observation tower\"},\n  {\"action\": \"climbing\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The person runs through the forest and climbs a wooden structure, likely to reach a vantage point or complete a task."
        }
    ],
    "clip_044": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"outerwear\":\"brown jacket\",\"shirt\":\"striped shirt\",\"shirt_pattern\":\"red and white stripes on dark blue\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- clean; book\n- clean; air\n- pick up; book\n- open; book"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "man, sorting, envelope"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The man holds a feather duster in his right hand and a stack of books in his left hand, then dusts the books with the feather duster.\n2. The man puts down the feather duster, flips through the books with both hands, and picks out an envelope from them.\n3. The man holds the envelope in his left hand, tears open the seal with his right hand, and pulls out a photo from the envelope."
        }
    ],
    "clip_045": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- stone lanterns\n- rectangular lanterns\n- wooden gate\n- tile roofed gate\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Camera Movement | Scene Revealed |\n| --- | --- |\n| Follow the person running from right to left, then pan up and over the wall | A traditional courtyard with old buildings, drying crops, and farming tools inside after the person enters through the gate |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "running, walking, entering"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. A person in **light green traditional attire** runs from the right side of the screen towards an ancient-style gate. 2. The person enters through the gate, and the camera moves upward to show a courtyard with traditional buildings and scattered items. 3. The person walks further into the courtyard."
        }
    ],
    "clip_046": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Dog: small, white, runs down stone steps, chases a toy.\n- Toy: small, brown, rolls down the stone steps.\n- Steps: wide, stone, patterned, have wooden railings.\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera remains stationary initially, then follows the movement of a small white dog and a rolling object (a ball with a tail-like attachment). \n2. A small white dog chases a rolling object down a set of ornate stone stairs. \n3. The dog continues to pursue the object as it descends the stairs, with the camera tracking their movement. \n4. The dog reaches the bottom of the stairs, and the object bounces, with the dog still in pursuit. \n5. The dog runs across a stone-tiled area after the object."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Pomeranian, Chasing, Toy, Stairs, White"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Ball rolls down stairs; dog chases excitedly.\n2. Ball reaches bottom; dog leaps after, joyful."
        }
    ],
    "clip_047": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the video description outputs:\n\n1. Enters the room and sits at the desk.\n2. Walks towards the desk by the window.\n3. Walks away from the door.\n4. Opens the door and enters the room."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Book, blue\n- Laptop, black\n- Mouse, black\n- Anatomical model of kidney, red and white\n\nThe windowsill is decorated with various objects.\n\nThe window frames the view of a brightly illuminated cityscape against the night sky.\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Video: At night, a man walks to a desk, sits down, and starts using a laptop. -End-"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man walks to a desk, pulls out a chair, sits down, and starts using a laptop."
        }
    ],
    "clip_048": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- top color: yellow\n- bottom type: shorts\n- footwear: boots"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n[\n  {\n    \"event_id\": 1,\n    \"action\": \"lying; stabbed\",\n    \"weapon\": \"knife\"\n  },\n  {\n    \"event_id\": 2,\n    \"action\": \"kneel; enter; check\",\n    \"weapon\": \"knife\"\n  },\n  {\n    \"event_id\": 3,\n    \"action\": \"enter; look; talk; examine\",\n    \"weapon\": \"knife\"\n  },\n  {\n    \"event_id\": 4,\n    \"action\": \"talk; leave\",\n    \"weapon\": \"knife\"\n  }\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "- Room setting:\n- Flooring: Wooden floor.\n- Furniture 1: White cabinet with three drawers.\n    - Appearance: White, clean.\n    - Objects on top: Cat figurine, potted plant, framed photograph.\n- Furniture 2: Red chair with rounded back.\n    - Appearance: Rounded, bright red.\n- Furniture 3: Wall-mounted shelf.\n    - Appearance: Ornate design.\n    - Objects on top: Decorative flowers.\n- Windows: One window, covered with pink patterned curtains."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Scene: A person in yellow lies on the floor with a knife in the abdomen. Person A runs over, *worried*, kneels to check, then another person enters, speaks, and leaves. Person A continues checking. --End--"
        }
    ],
    "clip_049": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- color: red\n- attire: dress\n- shape: rectangular\n- color: white\n- attire: dress\n- shape: rectangular\n- color: brown\n- attire: table\n- shape: square\n- color: brown\n- attire: chair\n- shape: square\n- color: red\n- attire: column\n- shape: cylindrical\n- color: gray\n- attire: ground\n- shape: rectangular"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The scene is set in a traditional Chinese courtyard. A woman in a **red outfit** stands up from a chair, while another woman in a **white outfit** approaches holding a red box. The woman in red takes the box and walks forward, with the woman in white following behind."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"Action\": [\n    \"Standing\",\n    \"Receiving\",\n    \"Walking\",\n    \"Looking\"\n  ],\n  \"Emotion\": \"Solemn\"\n}\n1. An outdoor courtyard is surrounded by traditional Chinese architecture.\n2. The architecture features wooden pillars, latticework windows, and ornate details.\n3. The courtyard is paved with stone slabs.\n4. Red hanging decorations adorn the buildings.\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman in a red dress receives a gift box from another woman in white. The woman in red accepts the box and begins to walk forward. The woman in red walks with the box held in her hands. The camera zooms in on the woman in the red dress. The woman in the red dress continues to walk forward.\n \n A. The walls are decorated with intricate wooden lattice work, including circles and patterns.\n B. The pillars supporting the structure are red and have a carved base.\n C. There is a wooden table and chair on the side, and a room with a door and curtains in the background.\n D. Decorative red tassels hang from the ceiling.\n E. Windows are visible, covered by round decorations."
        }
    ],
    "clip_050": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here's the Markdown table as requested:\n\n| Item Name | Color | Location | Interaction with people |\n|-----------|-------|----------|--------------------------|\n| Cabinet | Brown | Left side of room |Empty |\n| Sofa | Green | Center of room | Woman lies down on it, Man sits on it |\n| Table | Brown | In front of sofa | Empty |\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The woman sits on the sofa and then lies down.\n2. The man walks toward the sofa.\n3. The man sits on the sofa and tells the woman not to sit there.\n4. The woman might be tired and wants to rest.\n5. The man is concerned about the woman's health."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\"keyword\": \"她\"},\n  {\"keyword\": \"躺\"},\n  {\"keyword\": \"坐\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! A woman places a cushion on a sofa, lies down, and a man enters to sit. She seems relaxed initially."
        }
    ],
    "clip_051": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- female: white jacket, black strap bag\n- male: dark blue denim jacket, white and dark blue striped shirt"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the table describing the cinematic elements:\n\n| Element | Description |\n|---|---|\n| Camera Focus | Young couple laughing, having fun. |\n| Interaction Type | Playful chasing and gentle interaction. |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"umbrella\", \"photo\", \"awning\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. 男生抢走女生手中的纸张并高举；2. 女生试图夺回纸张并轻拍男生；3. 女生成功拿回纸张并查看；推断情绪为*活泼欢快*。"
        }
    ],
    "clip_052": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Reverse chronological Events:\n1.  Man in striped outfit kicks guard with stick who falls; another man watches.\n2.  Man in striped outfit with tied hands faces guard exiting through doorway.\n --End--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The focus initially stays on all three characters during the fight. The focus then shifts to the character in striped clothing.  Finally, the focus stays on the man who is in a striped outfit.\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "KEY: KICK, SWORD, BIND, DOOREND"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! In a dimly lit room with stone walls, a man in a blue shirt wielding a bamboo stick enters through an open doorway and attempts to strike a person in a white striped robe. However, the person in the white robe skillfully kicks the man with the stick, causing him to fall to the ground. Meanwhile, a man in a red robe observes the fight without intervening, seemingly amused or uninterested in the outcome."
        }
    ],
    "clip_053": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- bicycle helmet\n- jacket, red and black\n- pants, black\n- shoes, white and black"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Scene Description: The camera is static in a hallway with doors on the right and a glass wall on the left, creating a reflection. A delivery man, wearing a helmet, black jacket with red stripes, and black pants, places a small cardboard box on the tiled floor in front of a dark brown door labeled \"801.\" After the box is placed, the delivery man turns his head. He then walks away down the hallway. --End Scene--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"delivery person\",\n  \"package\",\n  \"helmet\",\n  \"corridor\",\n  \"reflection\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "看! 该男子将一个包裹放在地上，然后朝着房门走去。 他戴着头盔，穿着外套，走在走廊里。\n"
        }
    ],
    "clip_054": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n \"action\": \"Two people are running through a field, trying to escape from an explosion. One person is carrying what looks like a dead animal.\",\n \"environment\": \"A field covered in dry grass and some bare trees. There is smoke in the air, suggesting a recent explosion.\",\n \"clothing\": \"One person is wearing a pink shirt and the other person is wearing a green helmet and a long brown coat.\",\n \"mood\": \"Chaotic and desperate, as the people are trying to escape danger.\"\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Time Step | Person A Action | Person B Action |\n|-----------|-----------------|-----------------|\n| 1 | run forward, jump down | run forward, jump down |\n| 2 | lift object to block | hold gun, jump down |\n| 3 | crouch, use object to block | crouch, place gun behind back |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"run\", \"field\", \"helmet\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I see a man with a green helmet holding a gun pulling me to crouch in a dry grassy field with explosions around."
        }
    ],
    "clip_055": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Events: 1. Two men walk towards a door. 2. They enter through the door, and an older man watches them. 3. The older man closes the door after they enter. --End--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Two men walk forward, with the man in the dark suit opening a door and walking in, followed by the man in the gray suit. An older man with white hair looks outside, then turns to close the door."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A wears a black suit and a black hat, walks towards a gate, B wears a gray suit and a gray hat, follows A, they enter the gate one after the other, C with gray hair and wearing a brown jacket stands by the gate, watches A and B walk in, then turns around, pulls the gate closed."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "您瞧：两个戴帽子的人走进门，白发老人看了看后关门，他看门口可能是担心有人跟着进来。"
        }
    ],
    "clip_056": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- clothing color: pink (top), pink (skirt)\n- item color: white (handbag)"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "look in the mirror with one hand touching the face | put down the mirror | walk to the table | pick up the bag | walk to the door | open the door | go out and be startled by the person at the door"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"look in the mirror\", \"pick up bag\", \"open door\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman touches her face while looking in a mirror, puts down the mirror, walks to pick up a bag, takes an item from the bag, walks to open the door, greets a man at the door, then turns around, places the item back into the bag, and adjusts her clothes."
        }
    ],
    "clip_057": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- bus, white, moves from left to right across the frame\n- motorcycle, black, moves from the distance towards the camera and stops near the right side of the frame\n- truck, black, parked on the right side of the frame without movement\n- vehicle on overpass, dark color, moves from left to right on the overpass"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "In a medium shot of an urban street, a *bus* speeds left while a motorcyclist *rides* toward the camera. The camera stays static as the motorcyclist slows near a parked *van*. In the background, a vehicle on an overpass also *moves* left, blending into the city’s bustling rhythm."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"Bus|Movement\",\n  \"Motorcycle|Movement\",\n  \"Car|Movement\",\n  \"Cityscape\",\n  \"Urban Street\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A motorcyclist passes a white bus and a dark van on a city street. the buildings are tall and modern. the motorcyclist has stopped behind the dark van, possibly to wait for someone."
        }
    ],
    "clip_058": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Woman: walking stealthily, on a rooftop at night, wearing casual clothes (jeans, jacket, white top)\n- Man: standing by a rooftop edge, drinking, wearing a striped shirt\n- Setting: rooftop with buildings, satellite dishes, pipes, dim lighting, nighttime\nShe might be walking stealthily to avoid being noticed, perhaps to approach the man without alerting him or to stay hidden for a specific reason (like spying, surprising, or avoiding someone else). Her mood could be cautious or urgent, as indicated by her stealthy movement and later running."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "the woman runs along the rooftop, approaching a man by the edge|the camera follows the woman's movement from a fixed, slightly elevated perspective"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "woman: gray jacket; white inner wear; black pants; medium build; man: dark red and black striped short-sleeve shirt; dark pants; medium build"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "What's happening: A woman in jeans and a grey jacket runs across a rooftop toward a man standing at the roof's edge, looking down into the cityscape. She is hurrying because she is either worried about him or trying to stop him from doing something rash. --"
        }
    ],
    "clip_059": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"entity\":\"woman\",\"action\":\"adjust hair and knock on door\",\"duration\":\"few seconds\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n[\n  {\n    \"description\": \"Woman in striped shirt, looking through peephole, curious expression\",\n    \"translation\": \"身穿条纹衬衫的女人，透过窥视孔往外看，表情好奇\"\n  },\n  {\n    \"description\": \"Closed white door, silver doorknob, glossy surface\",\n    \"translation\": \"关闭的白色门，银色门把手，光面\"\n  },\n  {\n    \"description\": \"Dark hallway, pale walls, poor lighting\",\n    \"translation\": \"黑暗的走廊，苍白的墙壁，光线昏暗\"\n  }\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "- WOMAN HAS LONG HAIR\n- DOOR HAS A METALLIC KNOB\n- DOOR IS LIGHT-COLORED"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman in a striped shirt leans against a door, placing her ear near the keyhole. She then adjusts her hair with both hands, gathering it at the back of her head."
        }
    ],
    "clip_060": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A bald man with a gray beard, wearing a black robe with his chest exposed showing a dragon tattoo. He first takes a wooden clapper from person B, then fans himself with a yellow fan, and finally smiles and speaks while fanning. | B is a man with glasses, wearing a light gray robe. He first holds a wooden clapper close to his mouth, then offers it to A, and finally looks at the fan in A's hand. | C is an older man wearing a hat, who leans in from the right side of the frame to look at the fan in A's hand, then steps back."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A (the bald man with a beard): Initially has a calm expression, then takes the wooden clapper from B, fans himself with a folding fan, and finally smiles heartily, appearing relaxed and proud. Mood: From calm to cheerful and confident. B (the man with glasses): Starts with a smiling expression while holding the wooden clapper, then looks expectantly at A, and finally has a somewhat thoughtful look. Mood: From enthusiastic to expectant and then contemplative. C (the man with the hat who enters later): Enters with a curious expression, leaning in to observe, then steps back. Mood: Curious."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"chest dragon tattoo\", \"yellow folding fan\", \"blue hanging ropes\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man in gray hands a fan to a bald man, who opens it, talks, and fans himself, while another man approaches."
        }
    ],
    "clip_061": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Two men run from the right side of the screen to the left, then stop and hide behind cover.\n2. The man in blue aims his gun forward, while the man in gray turns his head to observe the right side of the screen."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- camera follows the movement of two running men (tracking shot)\n- medium shot to close - up as men take positions\n- steady camera movement during action sequences"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "anxious; alert.Anxious: Two people are running through the forest at night, which suggests urgency or fear. Alert: They stop and take defensive positions, aiming their guns, indicating they are now on high alert for potential threats."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In a dimly lit forest, two Asian men dressed in older clothing sprint through the trees, looking anxious and possibly frightened. The first man wears a vest over a light-colored shirt and blue pants, while the second is in a blue robe with a white scarf. They dart between trees and overgrowth. Suddenly, the first man crouches down behind a tree, panting heavily and looking around nervously. The second man aims a rifle, his face tense and focused, ready to defend them."
        }
    ],
    "clip_062": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. The masked individual scales the wooden wall, gripping a rope that extends upward, and ascends towards the rooftop, disappearing from view. They carefully step onto the wooden railing before tying a rope and starting to climb. With precision, they manipulate the rope and make their ascent up the building facade.\n\nSpeculating about the person's identity, it's possible that this is a skilled infiltrator or a ninja tasked with a covert mission, such as espionage or assassination, as the all-black suit helps to stay unseen.\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A. The camera remains stationary (no movement) while using a medium shot scale to frame the masked person throughout the sequence."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "SWING ROPE TO THROW WATER, THEN CLIMB DOWN|TRADITIONAL WOODEN BUILDING"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A person wearing a black mask and black clothing is on a balcony; they throw a water-filled object upwards, then step over the railing, hold onto a rope, and slide downwards."
        }
    ],
    "clip_063": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "-  gold\n-  knee length\n-  short sleeves\n-  loose fitting"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "camera focuses on the dressing room|a woman in yellow walks to the dressing table and sits down|another woman walks past her|the woman in yellow takes off her earrings"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"wooden lockers with metal handles\", \"cosmetic items on countertop\", \"black and white checkered floor\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman in a short yellow dress walks into the room, throws items on the table, sits down, and adjusts her earring while another woman leaves the room."
        }
    ],
    "clip_064": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- 人物1：穿着黑白条纹上衣和黑色长裙，在洗手池前活动，动作包括洗手、移动等\n- 人物2：穿着白色上衣和黑色长裙，从画面右侧走入，动作包括走向洗手池、洗手等\n- 洗手池：多个，位于画面中间的洗手台区域\n- 镜子：大尺寸，安装在洗手台上方的墙面上\n- 墙面：带有类似大理石纹理的装饰\n- 毛巾：挂在墙面的毛巾架上，位于画面右侧\n- 花瓶：放置在洗手台区域，里面插有花"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Camera remains stationary, medium shot: A woman in a black and white striped shirt is at a sink; another woman in a white shirt enters, walks to the sink, and starts washing an item. The first woman moves along the counter, clapping her hands."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Retrieval Keywords: woman | mirror | sink | walk | hand wash"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In a bathroom with marble-patterned walls, a woman in a striped shirt washes her hands at a sink, while another woman in a white blouse enters the frame. Both women wear dark skirts and are standing at the same long counter with two sinks. The woman in the white blouse also begins to wash her hands at the sink next to the first woman.\n"
        }
    ],
    "clip_065": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. The man takes a bag. 2. The man walks out."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Element Type | Description |\n| --- | --- |\n| lighting | Interior office lighting is warm, with additional light from lamps; exterior cityscape at night with building lights visible. |\n| view | Glass-walled office space with modern furniture (desks, chairs, sofas); city skyline visible through large windows; two people moving within the office, one holding a container and the other retrieving an item then both exiting. |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Items: lamp; tissue;/End"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In an office, a man in a white jacket quickly walks to the left, picks up a bag, and hands it to a woman in a dark green jacket. The woman takes the bag with her left hand, holds a lunch box in her right hand, and walks to the left. The man follows behind her, and they both leave the office."
        }
    ],
    "clip_066": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[\n    {\n        \"clothing\": \"yellow reflective vest, black shirt, dark pants, brown boots\",\n        \"tool_used\": \"spray bottle, cloth\",\n        \"action_performed\": \"spraying and wiping wall\"\n    },\n    {\n        \"clothing\": \"dark jacket, dark pants\",\n        \"tool_used\": \"mop\",\n        \"action_performed\": \"mopping floor\"\n    }\n]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here's the Markdown table describing the key events from the video:\n\n| Event_Order | Action | Involved_Entity |\n| ------------- |:-------------:|:-------------:|\n| 1 | Cleaning staff attempt to move an individual lying on the floor using a mop and cleaning liquid. | Cleaning staff, Individual on floor |\n| 2 |  The individual gets up and throws a yellow 'Wet Floor' sign at the cleaning staff. | Individual on floor, Cleaning staff |\n| 3 | People share pizza with each other on a train car. | People |\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "subway, conflict, cleaning, interaction"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Passengers in the crowded subway train seem indifferent and go about their own activities like eating and holding onto bars."
        }
    ],
    "clip_067": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Character: Person in blue vest and light pants\n- Character: Person in blue dress with light blue shirt, black bag, and hat with bunny ears\n- Character: Fox mascot in blue police uniform\n- Character: Rabbit mascot in blue police uniform"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The video features a series of character interactions and camera movements. Initially, the camera follows two people from behind. The camera pans slightly to the left, revealing two costumed characters, a fox and a rabbit from the movie \"Zootopia\". A person dressed in a matching outfit greets the rabbit with a hug, causing their hat to fall off. The person picks up the hat, and the fox places it back on the person's head. The person and fox then hug, while the rabbit stands by. There is no focus transition in the video."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "judy, nick, hug, hat, girl"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Character in bunny costume is welcoming.\n2. Character in fox costume is friendly.\n3. Girl is excited to interact."
        }
    ],
    "clip_068": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the video captions:\n1.  Kid plays with spoon.\n2.  Adult plays with feet.\n3.  Adult uses chopsticks."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "用脚拿勺子舀菜|用脚拿筷子夹菜|配合用筷子辅助夹取|---"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Meal Scene: A child in a white shirt with a bear graphic sits on a table, uses feet to hold a spoon to take corn dish, interacts with another person using chopsticks; dishes include corn and green beans, tools are spoon and chopsticks #family"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A child sits on a table, uses feet to hold a spoon to scoop food, and another person uses chopsticks to interact with the child."
        }
    ],
    "clip_069": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- walk\n- open the door\n- walk\n- close the door\n- walk"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the table describing the dog and glass door in the video:\n\n| Entity | Color | Key Feature |\n|---|---|---|\n| Dog | Tan | Opens the glass door |\n| Glass Door | Clear | Double doors with metal handles |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "open the door; go out; come in"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The dog appears eager and helpful as it opens the door, likely feeling a sense of purpose and loyalty."
        }
    ],
    "clip_070": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n[\n  {\n    \"entity\": \"cow\",\n    \"type\": \"Animal\",\n    \"action\": \"standing\"\n  },\n  {\n    \"entity\": \"person\",\n    \"type\": \"Person\",\n    \"action\": \"standing\"\n  },\n  {\n    \"entity\": \"man\",\n    \"type\": \"Person\",\n    \"action\": \"exiting\"\n  },\n  {\n    \"entity\": \"man\",\n    \"type\": \"Person\",\n    \"action\": \"running\"\n  }\n]\n```---End---"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here are the descriptions based on the video:\n\nThe **woman** in a pink robe approaches a brown cow standing on hay-covered ground. The **woman** appears to try and guide or interact with the cow in a calm manner.\n\nA **man** in a patterned shirt and orange pants jumps out of a small shop carrying a stick. He appears agitated, ready to address the situation involving the cow.\n\nThe **man** with the stick chases after the cow, which is now running away from the shop area. Other **men** join the chase, running in the same direction as the cow.\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Cow, Village, Shop, Chase, People."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Scene: A woman in a pink burqa is near a cow. The cow enters a shop. A man in a yellow dhoti exits the shop holding a stick. Other men also run out. The men chase the cow with the stick. \n"
        }
    ],
    "clip_071": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Type | Attribute |\n| --- | --- | --- |\n| **Durian** | object | being cut from tree |\n| **Person (tree climber)** | person | holding knife |\n| **Person (ground receiver)** | person | catching durian |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "HarvestBlueprint: [\n  {\"description\": \"A durian fruit is spiky.\", \"is_key_subject\": true},\n  {\"description\": \"A person is wearing a black baseball cap.\", \"is_key_subject\": false},\n  {\"description\": \"A person's foot is tanned.\", \"is_key_subject\": true}\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Man in tree-cutting-collecting | People below-picking-gathering | Man on tree-holding-harvesting\n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. A worker on the tree cuts durian fruits with a knife. 2. The worker passes the cut durian to another worker on the ground. 3. The ground worker catches and collects the durian fruits."
        }
    ],
    "clip_072": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Events: 1. Kick the ball to the backpack. 2. Kick the ball to the backpack again."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Action | Description |\n| --- | --- |\n| Kick | The child kicks the yellow ball, sending it rolling. |\n| Observe | The child watches the ball's movement after kicking it. |\n| Kick again | The child kicks the yellow ball a second time. |\n| Observe again | The child watches the ball's movement after the second kick. |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"girl playing with toy\",\n  \"concrete pipe in park\",\n  \"fun outdoor activity\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "看! 小朋友在大圆筒里踢黄色小球，小球弹来弹去好有趣！小朋友玩得很开心，脸上挂满笑容呢。"
        }
    ],
    "clip_073": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Event: Man swings rope, dogs prepare to jump rope.\n2. Event: Man and dogs jump rope in unison.\n3. Event: Man continues rope swinging, dogs follow jumps."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Step | Man's Action | Dogs' Reaction |\n|------|--------------|----------------|\n| 1 | Swing the rope to start skipping | Jump up together with the rope |\n| 2 | Continue swinging the rope for skipping | Keep jumping in sync with the rope |\n| 3 | Maintain the rope-swinging rhythm for skipping | Persist in jumping along with the rope |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "dog, skipping rope, trainer, performance, audience"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Dogs' Activities: 1. The dogs jump in unison as the trainer swings a rope, showing coordinated movement. 2. The dogs gather closely around the trainer, indicating attentiveness. Their coordinated jumping and close gathering suggest they are energetic and responsive, implying a positive and engaged mood."
        }
    ],
    "clip_074": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- type: French Bulldog\n- color of clothing: neon green\n- the object it is riding: skateboard"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The camera follows the dog from a low-angle, medium shot perspective, maintaining a steady tracking movement as the dog rides the skateboard through the busy street."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "VIDEO:Skateboarding, Neon Green, Street;"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Dog wears green outfit.\n2. Dog rides skateboard forward."
        }
    ],
    "clip_075": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"embroidery_subjects\": [\"monkey\", \"dog\"],\n  \"tools_used\": [\"embroidery hoop\", \"needle\", \"thread\", \"scissors\"]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Two people embroider animal images. They use fine threads and precise stitching techniques. One person threads a needle, and they both work on a large embroidery frame, creating detailed images of animals like a monkey and a dog by carefully pulling threads through the fabric."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"Monkey Embroidery Art\", \"Needle And Thread\", \"Outdoor Courtyard\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here is the video description:\nAn elderly person is sitting and focused on their embroidery, depicting a monkey, in this vertical video. They are using a needle and thread, carefully stitching a black piece of fabric held on a frame. The craft appears to be done outdoors, possibly near a canal. Another embroidery piece, this time of a dog, is also shown."
        }
    ],
    "clip_076": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"dog\": [\n    \"walking\",\n    \"falls\",\n    \"swimming\"\n  ],\n  \"man\": [\n    \"walking\",\n    \"leading\",\n    \"watching\"\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here are the descriptions based on the given video sample:\n\nA man in a dark blue shirt and jeans crosses stepping stones over a body of water, guiding a Corgi on a leash. The dog initially steps carefully but falls into the water. They navigate around a stone pillar.\n\nEnvironment: stepping stones, body of water, stone pillar, outdoor public space.\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [395, 573, 492, 713], \"label\": \"dog\"},\n  {\"box_2d\": [106, 561, 395, 683], \"label\": \"person\"},\n  {\"box_2d\": [160, 664, 338, 896], \"label\": \"person\"},\n  {\"box_2d\": [218, 632, 425, 883], \"label\": \"stroller\"},\n  {\"box_2d\": [134, 229, 279, 287], \"label\": \"person\"}\n]\n```\nHere are the rekeyed retrieval keywords:\ndog | stepping | stones | corgi | water | balance"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "a. Confident before falling.\nb. Frightened after falling."
        }
    ],
    "clip_077": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Attributes |\n|-------------|------------|\n| Person | Wearing helmet, riding bicycle, performing stunts |\n| Bicycle | Missing front wheel, black frame, used for stunts |\n| Scene | Under an overpass, nighttime, paved ground |\n| Barrel | Blue with graffiti, cylindrical, on paved ground |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here is the video description:\n\nThe video unfolds at night, under a well-lit concrete awning in an urban area, possibly a transit hub. The ground is tiled in large gray pavers, with cylindrical pillars supporting the roof. Street lights and building lights add to the ambient illumination.\n\nA person wearing a helmet and light-colored clothing **approaches** on a bicycle, then **performs** a wheelie and **travels** a fair distance on the back wheel alone. **Maneuvering** with finesse, the rider **maintains** balance while **passing** between painted barrels and **navigating** through the architectural features of the setting."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: wheelie, bicycle trick, graffiti barrel, urban, stunt"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "在一个安静的夜晚，一名男子骑着自行车在一个开阔的区域里玩耍。他戴着头盔，做出各种高难度的动作，显得既专注又兴奋。他骑着自行车，只有后轮着地，并保持平衡向前行驶。整个过程中，他都在挑战自己，享受着骑行的乐趣。"
        }
    ],
    "clip_078": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"dog\": [\"Wearing a red floral shirt\", \"Pressing the lever\", \"Eating from feeder\"],\n  \"feeder\": [\"Blue and white\", \"Automatic\", \"Dispenses food\"]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Storyboard Start: \n\n[00:00:00 to 00:00:02] A dog wearing a red floral shirt **presses** the lever with its paw. The dog then **eats** the kibble. \n[00:00:04 to 00:00:05] The dog **presses** the lever with its paw.\n[00:00:06 to 00:00:07] The dog **eats** the kibble.\n[00:00:07 to 00:00:09] The dog **presses** the lever with its paw.\n[00:00:09 to 00:00:10] The dog **eats** the kibble.\n[00:00:10 to 00:00:11] The dog **eats** kibble from the food dispenser.\n\n--End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 0, 1000, 673], \"label\": \"dog\"}\n]\n```\nHere are the keywords for the video:\ndog, floral shirt, self-feeding, eats, paw\n\nHere is the dog's probable mood:\nhungry"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A dog in a red floral outfit presses a feeder lever to get food, then eats from the bowl."
        }
    ],
    "clip_079": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Two bears wearing tree disguises.\n- A man wearing a purple shirt, dark purple pants, and an orange construction hat."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[{\"name\":\"bear\",\"attributes\":[\"tree costume\",\"brown fur\",\"leaf props\"]},{\"name\":\"bear\",\"attributes\":[\"tree costume\",\"red fur\",\"leaf props\"]},{\"name\":\"human\",\"attributes\":[\"orange helmet\",\"purple outfit\",\"rifle\"]},{\"name\":\"costume\",\"attributes\":[\"tree design\",\"brown trunk\",\"green leaves\"]},{\"name\":\"sign\",\"attributes\":[\"triangular\",\"yellow background\",\"claw mark\"]}]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "- bear: color=yellow\n- bear: color=brown\n- human: helmet=orange"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Two bears disguised as trees chase a man with a gun, who gets crushed by a sign."
        }
    ],
    "clip_080": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Polar bear: white, wearing light blue fencing attire\n- Penguin: blue and black, wearing light blue fencing attire"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The bird stabs at the bear's right side, and the bear steps back to dodge.\n2. The bear raises its fencing sword to block the bird's attack, then the bird jumps up and stabs at the bear's left side.\n3. The bear swings its sword to the left to block, then the bird jumps to the right side of the bear and stabs at the bear's right side.\n4. The bear swings its sword to the right to block, then the bird moves to the left side of the bear and stabs at the bear's left side.\n5. The bear swings its sword to the left to block, then the bird jumps up and stabs at the bear's chest.\n6. The bear steps back and swings its sword downward to block, then the bird steps back.\n7. The bear raises its sword, makes a gesture, and cuts the rope holding the candelabrum, causing the candelabrum to fall and extinguish the candles."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\n    \"scene_id\": \"1\",\n    \"animal\": \"polar bear\",\n    \"attribute\": \"blue fencing gear\",\n    \"action\": \"fencing\"\n  },\n  {\n    \"scene_id\": \"2\",\n    \"animal\": \"penguin\",\n    \"attribute\": \"small size\",\n    \"action\": \"fencing\"\n  }\n]\n```\nA cartoon polar bear and a cartoon penguin are fencing with swords.\n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Runs.\n2. Stops.\n3. Holds a sword.\n4. Advances toward bear.\nClumsy."
        }
    ],
    "clip_081": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- 卡通狼：蓝白色毛发，粉色内耳，棕色鼻子，蓝色眼睛\n- 蝴蝶：蓝橙色翅膀\n- 花朵：黄色花瓣，绿色茎叶\n- 草：绿色叶片"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**Butterfly** flies in front of **dog**; **dog** closes eyes and interacts with **butterfly**; **dog** raises paws to try to catch **butterfly**"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\"core_action\": \"butterfly landing on dog nose\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "没问题，这是描述：\n一只小狗狗在草地里玩，它长着蓝色的毛，白色的脸，看起来非常可爱。 一只漂亮的蝴蝶飞到狗狗的鼻子上，狗狗开心地睁开了眼睛。它很喜欢蝴蝶，觉得和蝴蝶一起玩真开心。"
        }
    ],
    "clip_082": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the video descriptions:\n\n1.  A white-suited character climbs on the back of a dark, pig-like creature with a red collar.\n2.  The creature begins to run, carrying the character across a dark, uneven surface.\n3.  The backdrop reveals a monstrous creature with glowing yellow eyes and a wide, toothy maw emerging from a dark, misty landscape."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Close up follows a bat with a human riding on its back across a black snake-like structure | Tracking shot as the bat trots forward along a hill with the human rider | Medium tracking shot revealing two monstrous, dark, spiky structures in the pink and red background."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the video captions:\n\nKeywords: White suit, blue creature, red light, riding.\n\nThe character's expression changes from determined to slightly apprehensive."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The lady is sitting on a big, blue animal.\n2. She holds on tight as they move.\n3. The animal walks on its four legs.\n4. The animal has a red collar around its neck."
        }
    ],
    "clip_083": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- boy: hair_color orange, attire light_yellow short-sleeved shirt and dark_blue shorts, footwear barefoot\n- white_dog: color white"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "00:00 boy: walks toward cave; 00:00 dog: walks\n00:05 boy: walks into cave; 00:05 dog: lies down\n00:11 dog: stands up; 00:11 dog: walks forward\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "boy, dog, tunnel"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! A boy walks into a dark cave, and a white dog follows him partway before stopping."
        }
    ],
    "clip_084": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"entities\": [\n    {\n      \"name\": \"Jerry\",\n      \"attributes\": \"cartoon mouse\"\n    },\n    {\n      \"name\": \"tail\",\n      \"attributes\": \"gray and white\"\n    },\n    {\n      \"name\": \"tail\",\n      \"attributes\": \"brown with bandage\"\n    }\n  ],\n  \"actions\": [\n    \"emerging from pail\",\n    \"tying tails\",\n    \"tying knot\",\n    \"dancing\"\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Shot Sequence: \nI. Camera Focus: Close up of Jerry falling out of a bucket. Jerry is standing on two cat tails, one gray with a white tip and one brown with a bandaged section. Jerry ties the cat tails in a knot.\n\nII. Camera Focus: Medium shot of Jerry walking across the tied cat tails. Jerry strikes a pose and then continues dancing across the tied cat tails in an offensive, taunting, and victorious fashion.\n\nIII. Camera Focus: The camera shows a close up of Jerry dancing on the knotted cat tails. Jerry waves his hands above his head as he continues dancing on the knotted cat tails. The cat tails are tied in an overhand knot.\n --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Jerry; intertwining; tails; yard."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Jerry the mouse jumps out of a bucket and ties the tails of Tom the cat and another cat together. Jerry is laughing and dancing."
        }
    ],
    "clip_085": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Events: 1. A police car with flashing lights moves forward. 2. A red car drives past and stops. 3. Two people crouch and move to a blue car. --End--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The camera moves to the right, revealing a red sports car."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 0, 737, 246], \"label\": \"car\"},\n  {\"box_2d\": [145, 500, 328, 655], \"label\": \"light\"}\n]\n```\nHere are the rekeyed bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 0, 737, 246], \"label\": \"police car\"},\n  {\"box_2d\": [145, 500, 328, 655], \"label\": \"ceiling light\"}\n]\n```\nHere are the retrieval keywords:\n```json\nUnderground Garage, Dark, Police, Cars, Red\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A police car with lights flashing is driving through a parking garage. The car passes a red Fiat Spider and other cars. Two people are squatting between cars trying to be sneaky."
        }
    ],
    "clip_086": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Cat Behavior Analysis: | Cat | Coat Pattern | Key Actions | Interaction with Other Cat |\n|-----|--------------|-------------|----------------------------|\n| Cat 1 | **Spotted** | Approaches mirror, jumps, paws at mirror | Watches Cat 2 from corner |\n| Cat 2 | **Tabby** | Hides in corner, observes Cat 1 | None direct (observes) | --End Analysis--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "0-10s|stands up and plays with oven door|stationary"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "cat, mirror, reflection, play"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Two cats are in a kitchen: A spotted cat first crouches and looks at its reflection in a glass door, then jumps up to paw at the glass, while the other cat stays near the corner. The spotted cat's mood changes from curious (while observing the reflection) to playful (when pawing at the glass). --End--"
        }
    ],
    "clip_087": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here's the table:\n\n| Entity | Type | Attribute |\n|---|---|---|\n| Girl | Person | Riding |\n| Buffalo | Animal | Eating |\n| Bucket | Object | Blue |\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera remains stationary throughout the video.\n2. A woman in a black top and blue jeans throws something towards a buffalo eating from a blue container, then runs and jumps onto the buffalo's back.\n3. A man in a white top and blue pants approaches the blue container, lifts it, and pulls it forward as the buffalo walks, with the woman riding on the buffalo."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 377, 992, 637], \"label\": \"animal\"},\n  {\"box_2d\": [0, 343, 1000, 644], \"label\": \"bull\"},\n  {\"box_2d\": [102, 201, 689, 384], \"label\": \"woman\"},\n  {\"box_2d\": [356, 516, 993, 707], \"label\": \"man\"}\n]\n```\nHere are the keywords for the video:\nwoman, black shirt, riding, bull, eating"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman throws something into a blue basin, then runs and jumps onto a buffalo's back; a man pulls the blue basin forward, and the buffalo follows as the man pulls the basin away."
        }
    ],
    "clip_088": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. A child runs forward in a colorful, illuminated corridor (1 child involved).\n2. The child collides with a mirror, falls to the ground, and then crawls on the ground (1 child involved)."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Shot Number | Camera Movement | Lighting Color | Main Action |\n|-------------|-----------------|----------------|-------------|\n| 1           | Stationary      | Blue, Green    | A child runs forward in a corridor. |\n| 2           | Stationary      | Blue, Purple   | The child continues running and approaches a mirror. |\n| 3           | Stationary      | Red, Green     | The child collides with the mirror, falls, and rolls on the ground. |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "children:running then colliding with mirror and falling|corridor:illuminated with colorful lights, lined with mirrors"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In a brightly colored, narrow corridor with swirling patterns on the walls and changing lights, a child wearing a white shirt, dark shorts, and a large bow in their hair runs forward; as they run, they collide with a mirror, fall to the ground, and then get up and move away."
        }
    ],
    "clip_089": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the three main events in the video in chronological order:\n\n1. A man wearing a blue shirt and jeans casts a fishing pole into a body of water. \n2. A man wearing a black jacket moves a gray chair behind him.\n3. The man wearing the black jacket sits in the gray chair."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A person in blue jeans and a light blue shirt is fishing while standing next to a person in a black jacket. The person in the black jacket moves the chair behind them. The person in the black jacket sits on the chair while the other person still tries to fish."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: fishing, chair, pond, seated"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Story: Two guys stand by the lake, one is fishing. The fisherman casts the line far into the water, hoping for a bite. His friend sits on a chair to watch him, appearing slightly bored. Suddenly, the fisherman seems to catch a big fish and struggles, accidentally pulling the chair and his friend into the lake!"
        }
    ],
    "clip_090": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[{\"type\":\"person\",\"name\":\"girl\",\"attributes\":[\"long red hair\",\"green dress\",\"white apron\"]},{\"type\":\"animal\",\"name\":\"Inky Krueger\",\"attributes\":[\"gray fur\",\"red collar\",\"yellow eyes\"]},{\"type\":\"object\",\"name\":\"name tag\",\"attributes\":[\"round\",\"silver\",\"inscribed text\"]}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The girl speaks, then picks up the cat beside her and places it on her lap, gently stroking the cat with her hand.\n2. The girl picks up the cat's name tag to examine it, and the camera focuses on the name tag."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "girl, red hair, gray cat,\ngreen dress, silver bell.\n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A girl speaks, then picks up a gray cat, and the camera zooms in on the cat's name tag."
        }
    ],
    "clip_091": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. The man pedals the bicycle with his feet moving in a circular motion.\n2. The man stops the bicycle with his left foot on the ground."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here's the table:\n\n| Entity    | Description                                                 |\n|-----------|-------------------------------------------------------------|\n| Person    |  The person is **riding a bicycle** on a hilly terrain.         |\n| Bicycle   | The bicycle is ridden, **moving across a dirt path**. |\n| Environment | The environment is a hilly landscape with **trees and dry grass**.  |\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"Hills\",\n  \"Bike\",\n  \"Cyclist\"\n]\n```\nThe cyclist actively uses a bike to navigate the terrain of the hills."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A person rides a bike fast past autumn trees. The person stops and looks back."
        }
    ],
    "clip_092": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- dark suit\n- white dress shirt\n- red patterned tie"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n[\n  {\n    \"name\": \"Computer\",\n    \"location\": \"on a desk in the office\"\n  },\n  {\n    \"name\": \"Desk Lamp\",\n    \"location\": \"beside the chair in the office\"\n  },\n  {\n    \"name\": \"Eyeglasses\",\n    \"location\": \"on the nose in the office\"\n  },\n  {\n    \"name\": \"Book\",\n    \"location\": \"under the desk in the office\"\n  }\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "KEY: Man wearing glasses | Computer monitor | Graphs showing decline\n\nThe mood of the man appears to be anxious and stressed, likely due to the negative trends displayed on his computer screen. The setting in a dark, quiet office at night further emphasizes this mood, as it suggests isolation and long hours spent worrying about work."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. 看手機，股市下跌。\n2. 看著下跌的圖表。\n3. 摘下眼鏡看相框。\n\n**Cinematography Analysis:**\n\n*   **Close-up:** Emphasizes the man's worried expressions.\n*   **Medium Shot:** Shows the man at his desk and conveys the overall environment.\n*   **Low Angle:** Subtly enhances the sense of powerlessness."
        }
    ],
    "clip_093": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here is a short critical analysis of the notebook scene:\n\nThe core claim being made is that one can lose weight and burn fat simply by increasing muscle mass, without doing anything more. The video uses two persuasive techniques to convey its message: it presents the idea as \"easy,\" and it uses clear quantitative claims to appear scientific and grounded. The visual presentation, particularly the use of a bold marker and neat handwriting, adds to the video's sense of authority and trustworthiness."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Writing Process: The man writes “EASY FAT LOSS” at the top of a page in a notebook, presumably to outline his strategy for effortless weight reduction. He then specifies: “0.45kg = 50kcal” followed by “± 10kg = 500kcal” possibly to quantify the calorie expenditure associated with gaining muscle mass. The objective is likely to show how much weight loss is possible without any exercise. He further notes that this amount would be approximately equal to a complete meal, writing: “Complete maaltijd extra per dag.” His purpose now shifts to encourage viewers, “Volg voor dagelijkse kcal fitness tips!” followed by “33%” to indicate percentage. --End of Writing--\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here are the Dutch text overlays from the video using an unordered list:\n\n- Afvallen zonder iets te doen?\n- Voor iedereen haalbaar!!\n- Volg voor dagelijkse kcal fitness tips!\n\nPatrick Star appears because the video creator believes the character will cause the video to gain more attention."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here's the description:\n\n1. The handwriting in the notebook reads: \"33%.\"\n2. The handwriting in the notebook reads: \"Hulp nodig? Zie link in bio.\"\n3. The handwriting in the notebook reads: \"Volg voor dagelijkse kcal fitness tips! Of zelfs meer!\"\n4. The handwriting in the notebook reads: \"Complete maaltijd extra per dag!\"\n5. The handwriting in the notebook reads: \"± 10kg = 500kcal\"\n6. The handwriting in the notebook reads: \"0,45 kg = 50 kcal\"\n7. The handwriting in the notebook reads: \"EASY FAT LOSS\""
        }
    ],
    "clip_094": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here is the information on the animals derived from the digit '6':\n\n- Dog, top-left: The dog's head echoes the curvature of the '6'; unlike the others, dogs often seek companionship.\n- Mouse, top-right: The mouse's rounded body resembles the shape of the '6'; unlike the others, mice are known for their quick, darting movements.\n- Snake, middle-left: The snake's body is a coiled '6'; in contrast, snakes move through constriction and scales rather than paws or shells.\n- Snail, middle-right: The snail's shell mirrors the shape of the '6'; unlike the others, snails move slowly, using a muscular foot.\n- Cat, bottom-left: The cat's body is shaped like a '6'; unlike the others, cats are known for their agility and hunting skills.\n- Bird, bottom-right: The bird's wing echoes the shape of the '6'; while all others are terrestrial creatures, birds are known for their ability to fly."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here's the controlled video caption:\n\n**Part 1:** Dog - Mouse - Snake - Snail - Cat - Bird.\n\n**Part 2:** \n- The number 6 is transformed into a cartoon-style **dog**, sitting in profile. The loop of the number serves well as the dog's body, while the top stroke forms the head and neck. The **design ingenuity** here is simple and effective because the '6' shape naturally suggests the curve of a seated animal, making the transformation quite intuitive.\n\n- Next, the '6' morphs into a **mouse** in a similar pose. The loop forms the mouse's body, with the stroke becoming its head, complete with tiny ears and whiskers. The **design ingenuity** is reasonable, but the '6' shape might not immediately suggest a mouse compared to other animals, requiring a bit more imagination from the viewer.\n\n- The '6' then is used to create a **snake**. The loop of the '6' cleverly becomes the snake's coiled body, and a small head is added at the end of the stroke. The **design ingenuity** is clever, using the curl of the '6' to mimic a coiled snake, and allows for a good balance between recognizability and simplicity.\n\n- The '6' next gets used to draw a **snail**. The loop of the number forms the snail's shell, with the tail stroke becoming its body and head. The **design ingenuity** is quite effective because the '6' shape naturally suggests the spiraling form of a snail's shell, making it a seamless transformation.\n\n- Next, we see the '6' transformed into a **cat**. Here, the loop serves as the cat's body, and the top stroke becomes its head, complete with ears and a small face. The **design ingenuity** is simple yet effective, with the '6' shape cleverly suggesting the body of a curled-up cat, making the transformation quite recognizable.\n\n- Finally, a **bird** is drawn by using '6'. The bird is in flight, with the '6' acting as the bird's body and head. The **design ingenuity** is the least obvious, the shape requires a bit more creative interpretation to see how it becomes the animal."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"animal\": \"dog\", \"creativity_reason\": \"The dog is the most simple and straightforward use of the 6, but still cute.\"},\n  {\"animal\": \"mouse\", \"creativity_reason\": \"The mouse’s ear as the curve of the 6 is a nice touch, if a bit obvious.\"},\n  {\"animal\": \"snake\", \"creativity_reason\": \"The snake is a clever way to use the shape of the six in a funny way.\"},\n  {\"animal\": \"snail\", \"creativity_reason\": \"This is a clever idea, and the design of the shell is beautiful and creative.\"},\n  {\"animal\": \"cat\", \"creativity_reason\": \"Very cute, with the 6 becoming the tail and curled-up body of the cat.\"},\n  {\"animal\": \"bird\", \"creativity_reason\": \"The transformation of a 6 into the bird's chest and head is cleverly done.\"},\n  {\"animal\": \"transformation\", \"creativity_reason\": \"The repeated use of a single digit to form various animals showcases a fun and imaginative transformation.\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here is the video description:\n\nA hand confidently traces the shape of the number six on white paper. The pen circles, stops at the top of the stroke, and then gently adds a dot for an eye, a muzzle, and a rounded ear. Lines extend to create the rest of the body—four legs, a tail, and a collar—finishing with a happy dog.\n\nThe pen moves to a fresh six, and a similar circular motion begins, but this time, the stroke curves upward, forming a pointed nose and rounded ears. A long tail swoops behind, and tiny whiskers sprout, transforming the shape into a playful mouse.\n\nThe hand repeats the six, this time drawing a forked tongue and a small dot for an eye within the curve. Additional markings give the body texture as a snake.\n\nThe pen traces a new six, but the inside of the circle is given a spiral texture. A pair of tiny antennae poke up above the top curve, and the body extends forward—a whimsical snail slowly emerges.\n\nThe pen moves to the next six, filling in a mouth, cheek, and ears—the familiar, rounded shape turning into the face of a cat. A tail curves behind, and tiny lines suggest fur.\n\nFinally, the hand makes the outline of a six, stopping and then adding the body of a bird, mid-flight. A dot for an eye peeks out above the number’s curve. Each drawing, a six transformed."
        }
    ],
    "clip_095": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Element: Person with backpack and hat sits on a rock by the lake;\n2. Element: Lake with bright turquoise water reflecting the sky and mountains;\n3. Element: Majestic mountains with rocky slopes and patches of snow;"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Mountains reflecting in lake|Sits on rock|TikTok logo"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Sure, here is the description for a visually impaired individual. \n\nImagine a scene where your skin tingles with the crisp, cool air of towering peaks crowned with icy snow. These peaks stand as silent guardians, their presence a palpable weight against the sky. Then, let your fingertips trace the rugged texture of the earth beneath them, the rough grains of stone and the sturdy trunks of ancient trees. Now, sense the sudden shift as you reach a shimmering, turquoise pool. It calls to you like a liquid mirror reflecting the sky. Feel the stillness that permeates the waters, as if it is holding secrets as old as the mountains themselves. \n\nIf you could see, you might feel awe at the sheer grandeur of the landscape. A sense of peace would wash over you at the sight of the vibrant lake cradled within the earth. The mountains would inspire reverence and strength."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Camera starts with a person sitting on a rock ledge overlooking a glacial lake surrounded by mountains. The camera zooms out to show the person sitting near two trees on the edge of the lake and mountains in the background."
        }
    ],
    "clip_096": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "  - Person closes fridge door.\n - Person walks away from fridge.\n - Person touches another person.\n - Two people talk to each other."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the three-act breakdown of the interaction:\n\nThe prankster peeks from behind a wall, watching as the target retrieves a drink from the refrigerator; The prankster yells, startling the target; The target expresses surprise and mild distress due to the sudden scare."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "refrigerator, kitchen, surprise, angry, sad"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. One Person Closes The Door After Taking A Drink.\n2. Another Person Hides And Then Surprises The First Person.\n3. The First Person Reacts With Confusion And Gestures With Their Hands."
        }
    ],
    "clip_097": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Moving Entities: [{\"type\":\"vehicle\",\"description\":\"Colorful bus moving forward on road\"},{\"type\":\"vehicle\",\"description\":\"Blue auto-rickshaw moving left\"},{\"type\":\"vehicle\",\"description\":\"Silver SUV moving forward\"},{\"type\":\"vehicle\",\"description\":\"Green auto-rickshaw moving left\"},{\"type\":\"vehicle\",\"description\":\"Black car moving forward\"},{\"type\":\"vehicle\",\"description\":\"Motorcycle moving forward\"},{\"type\":\"vehicle\",\"description\":\"Blue truck moving forward\"}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "a colorful bus drives on the road; vehicles pass by the bus"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Colorful,Decorated,Buses,On,Road,With,Cars"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here's the JSON object based on your instructions:\n\n```json\n{\n  \"left_lane\": {\n    \"vehicle_sequence\": [\n      \"blue tuk-tuk\",\n      \"silver SUV\",\n      \"white covered truck\"\n    ],\n    \"driving_character\": \"Sedate\",\n    \"atmosphere\": \"Casual drive\"\n  },\n  \"right_lane\": {\n    \"vehicle_sequence\": [\n      \"black van\",\n      \"black car\",\n      \"blue sports car\"\n    ],\n    \"driving_character\": \"Busy\",\n    \"atmosphere\": \"Normal traffic\"\n  },\n  \"scene_metaphor\": \"The road is like a crayon box, full of different colors of cars!\"\n}\n```"
        }
    ],
    "clip_098": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here's the video description:\n\nA.\n```json\n{\n\"action_desc\": \"Man holds a wooden board with the word 'EVA' spelled out in white and red filling materials above his head.\",\n\"duration\": \"0s-06s\",\n\"result\": \"The word 'EVA' is visible above the man's head, seemingly suspended in the air.\"\n}\n```\nB.\n```json\n{\n\"action_desc\": \"The filling materials that spell out 'EVA' are dropped.\",\n\"duration\": \"06s-12s\",\n\"result\": \"The filling materials scatter and fall, covering the man and the ground below.\"\n}\n```\n\nThe man initially presents a wooden board, holding it so that the name **'EVA'**, spelled out using white and red filling materials, appears suspended in the air above his head. Subsequently, the man drops the filling materials, causing them to scatter and fall. This action results in the materials covering the man and the ground around him."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I hold a wooden board with red letters, then flip it to reveal the back. As I lift the board up, small items with the red letters “EVA” fall down from above.\nI lower the wooden board, and the small items with red letters continue to fall onto the board and around me, creating a cascading effect as they land."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\": \"00:00\", \"action\": \"lift\", \"object\": \"board\"}, {\"timestamp\": \"00:02\", \"action\": \"throw\", \"object\": \"particle\"}, {\"timestamp\": \"00:06\", \"action\": \"lower\", \"object\": \"board\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Person's view: As particles fall, there's a mix of awe and delight, like a sudden, magical shower that feels special and surprising.\n\nObserver's view: A person in black holds a board under a patio; text reads “Volg mij en ik maak jouw naam 👈”. Particles fall, revealing “EVA” in red, creating a whimsical scene."
        }
    ],
    "clip_099": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"person\": {\"attributes\": [\"fair skin\", \"gray hoodie\", \"short brown hair\"], \"main_gesture\": \"finger pushing into the forehead\"}, \"chair\": \"gaming chair\", \"background\": \"bright blue wall and doorway\"}\nThe finger going through the head is an optical illusion created by holding a finger up to the forehead and making it look like it is going through the head by making the other eye look in that direction, then another angle is used to complete the effect."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "# Person's Perspective: I point, gesture like a conductor guiding rhythm, pressing fingers to my forehead—playful energy, eyes wide, enjoying the moment.  \n# Chair's Perspective: The person shifts, hands flit like butterflies, pressing to their head—my frame steady, watching their animated, light - hearted motions."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\"primary_tag\": \"Face blocks eye, then fades\", \"secondary_tags\": [\"playful\", \"silly\", \"goofy\"]}\n```\nPeople who watched the entire video may have been amused or entertained by the silly effects and the man's playful attitude. In contrast, someone only seeing the final still image may just be confused."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome! Look here—you’ll see a person in a gaming chair, their gestures as lively as a conductor leading an orchestra. Notice the superhero hoodie; it’s like wearing a cape of confidence! The chair is DXRacer, and the hoodie has a cartoon superhero graphic with “SUPER BOSS” text."
        }
    ],
    "clip_100": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. A. Start at top:\n    {\n      \"duration_estimate\": \"medium\",\n      \"sensory_cues\": \"Roller coaster car stationary at peak of tall green and blue track; clear sky with scattered clouds; colorful theme park structures in background.\"\n    }\n 2. B. Descending:\n    {\n      \"duration_estimate\": \"medium\",\n      \"sensory_cues\": \"Roller coaster car moves downward along steep track; car gains speed; theme park scenery (rides, buildings) visible below.\"\n    }\n 3. C. Splash:\n    {\n      \"duration_estimate\": \"short\",\n      \"sensory_cues\": \"Car hits water, creating large white splash; mist and water droplets spread outward; water surface ripples intensely.\"\n    }\n 4. D. Post - splash:\n    {\n      \"duration_estimate\": \"short\",\n      \"sensory_cues\": \"Car continues along track after splash; residual mist in air; wet surfaces on car and track; theme park structures still visible.\"\n    }\n**Key visual effect: Water splash**"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"shot_id\": 1,\n        \"shot_scale\": \"long\",\n        \"description\": \"A tall roller coaster with a blue track and green supports is shown against a bright blue sky with scattered clouds. The coaster is positioned next to a body of water, and colorful structures and other rides are visible in the background.\"\n    },\n    {\n        \"shot_id\": 2,\n        \"shot_scale\": \"medium\",\n        \"description\": \"The roller coaster train, filled with riders, begins to descend from the peak of the track. The surrounding theme park structures, including a red and blue tent-like structure, are visible. The water below reflects the coaster and sky.\"\n    },\n    {\n        \"shot_id\": 3,\n        \"shot_scale\": \"close-up\",\n        \"description\": \"The roller coaster train speeds down the track, splashing into the water and creating a large spray. The riders are visible in the train, and nearby theme park attractions, including a tall red and yellow structure, can be seen.\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here is the requested description:\n\n1.  The roller coaster ascends to the top of a tall, open-framed structure on a bright, sunny day with fair-weather clouds. Emotional state: apprehensive, a sense of nervous excitement.\n2.  The roller coaster plunges down the structure and into a pool of water, creating a big splash. Emotional state: elated, feeling thrilled.\n3. The roller coaster exits the pool of water and continues along the track. Emotional state: relieved, anticipating the next twist and turn."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A roller coaster in a theme park under a partly cloudy sky descends a steep track and splashes into water. The surroundings include colorful tents and other amusement rides."
        }
    ],
    "clip_101": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, I'm ready. Here's the video caption you asked for:\n\n1. The mother playfully smears chocolate on her son's face after he claims to dislike it.\n2. The son states \"I don't like it\" when looking at a chocolate cake.\n3. A woman presents a chocolate cake to the camera with a big smile.\n\n| Entity | Static Attributes | Dynamic Actions |\n| ----------- | ----------- | ----------- |\n| Mother |  Blonde hair, smiling, wearing a pink hoodie |  Presents cake, playfully touches son's face |\n| Son | Wearing a black beanie |  Expresses dislike, endures mother's teasing |\n| Cake |  Round, chocolate, topped with chocolate candies | Sits on a plate, is presented by the mother |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Saw my rich, dark chocolate cake glisten under the lights, proud of my work.\n- Felt the smooth, velvety icing on the cake as I carried it, soft yet firm.\n- Felt my heart sink when my son grimaced at the sight of the chocolate cake."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n  \"timeline\": [\"0.0-2.0\", \"2.0-4.0\", \"4.0-8.0\"],\n  \"key_objects\": {\n    \"0.0-2.0\": [{\"type\": \"cake\", \"colors\": [\"brown\"]}, {\"type\": \"person\", \"colors\": [\"pink\"]}],\n    \"2.0-4.0\": [{\"type\": \"person\", \"colors\": [\"black\", \"gray\"]}],\n    \"4.0-8.0\": [{\"type\": \"cake\", \"colors\": [\"brown\"]}, {\"type\": \"person\", \"colors\": [\"pink\"]}, {\"type\": \"person\", \"colors\": [\"black\", \"gray\"]}],\n    \"decorative_pattern\": \"chocolate pieces arranged on top\"\n  }\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From Mother's perspective: I spent all day baking this chocolate cake, hoping my son would love it. Even though he dislikes chocolate, seeing his reaction makes me smile with love.\n\nFrom Son's perspective: Mom proudly shows her chocolate cake, but I don’t like chocolate. Still, her excitement makes me feel guilty yet amused as she feeds me a piece."
        }
    ],
    "clip_102": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"scene\": {\n        \"entities\": {\n            \"woman\": {\n                \"attire\": \"sleeveless patterned dress\",\n                \"emotion\": \"[inference] amused (visual cue: laughing emoji overlay)\",\n                \"actions\": [\"**hold balloon**\", \"**move balloon towards TV**\", \"**throw balloon**\", \"**clap**\", \"**point at TV**\"]\n            }\n        },\n        \"objects\": {\n            \"balloon\": {\n                \"color\": \"red\",\n                \"movement\": \"[if_else] moved towards TV\"\n            }\n        }\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Story Start:\n### Woman's Perspective\nI stood in front of the TV, holding a red balloon. The man on the screen had a distinctive hairstyle, and I thought it would be funny to pop the balloon near it, mimicking a \"haircut.\" I squeezed the balloon, and with a quick motion, I popped it! The sound was a sharp, sudden *\"POP!\"* that made me jump a little, but also made me laugh. The surprise of the pop, combined with the silly image on the TV, had me giggling uncontrollably. I turned to look at the camera, still chuckling, my face warm with amusement.\n\n### TV Man's Reaction\nThe man on the TV, mid-sentence, seemed to freeze for a split second as the balloon popped. His expression, already animated, turned into one of startled confusion. His mouth hung open a bit, and his eyes widened, as if he couldn't believe what had just happened—even though he was just a broadcast. The background of greenery and his formal attire made the contrast of the unexpected pop even funnier. For a moment, he looked like he was trying to process the sound, his gestures pausing, before the broadcast continued, but the moment of surprise lingered, comically juxtaposed with the serious tone of his speech.\nStory End:"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"Playing prank\",\n  \"secondary_tags\": [\"Humorous\", \"Joyful\"]\n}\n```\n她觉得给电视里的人做恶作剧很有趣。\n\n- Woman in a gray patterned dress\n- Donald Trump on TV\n- Red balloon\n- TV\n- Interior of a house\n- Laughing emoji"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The woman wears a **sleeveless patterned dress**; she holds a red balloon close to the TV screen, then moves it away and reacts with laughter."
        }
    ],
    "clip_103": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Attributes | Key Actions |\n|-------------|------------|-------------|\n| Person | Red top, black pants | Walking, then being knocked down by a dog, lying on the ground |\n| Animal | Brown and white fur | Running, knocking a person down, then running past the person |\n| Object | White, part of a gazebo structure | Stationary (no dynamic actions) |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Dog's Adventure: running | Emotion: *thrilled*; knocking person over | Emotion: *playful*; sprinting back | Emotion: *energetic*---End---"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A. 0-2s: Dog runs, woman trips.  \nA. 2-3s: Woman falls to ground.  \nA. 3-5s: Dog runs back near woman.  \n\n| Event                          | Duration |\n|--------------------------------|----------|\n| Dog runs, woman trips          | 0-2s     |\n| Woman falls to ground          | 2-3s     |\n| Dog runs back near woman       | 3-5s     |"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here is the video description:\n\n1. Daily Scene: The person falls.\n2. Daily Scene: A person in a red shirt and black pants walks along a brick path that has grass around it. The person is walking in the direction of a white porch.\n3. Daily Scene: A dog comes running on the green grass outside of a white gazebo.\n---\nFrustrated.\nContent."
        }
    ],
    "clip_104": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here's the video caption following your instructions:\n\n1. Player in white uniform: Frustrated (after being tackled and going to the ground)\n2. Player in orange uniform: Determined (to maintain possession of the ball despite the tackle)"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Player in white (left) and player in orange (right) are running side by side; ball is not visible.\n- Player in white attempts a sliding tackle while player in orange moves forward; ball is near player in orange.\n- Player in white is on the ground after the tackle, player in orange continues moving; ball is ahead of player in orange."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"Soccer foul, plea for penalty\",\n  \"secondary_tags\": [\n    \"Illegal slide tackle\",\n    \"Frustration and disappointment\",\n    \"Showcase emotional response\"\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Narrative: From the stands, I watch the contest unfold—players sprint, one in white slides, the orange-clad athlete pushes forward. The tension is electric as the match pulses with energy.\n\nNarrative: As referee, I monitor the contest closely—tracking sprints, tackles, and fair play. The slide from the white jersey, the orange player’s advance—every move judged for the game’s integrity."
        }
    ],
    "clip_105": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Person 1: type: person; attributes: wearing white hoodie, carrying black backpack\n- Person 2: type: person; attributes: wearing beige coat, black innerwear\n- Person 3: type: person; attributes: wearing pink down jacket, black pants\nI. Person 1 unlocks the wristwatch on Person 2's hand from the railing.\nII. Person 1 lifts Person 3 and walks down the stairs.\n- Person 1: seems mischievous and playful as he playfully interacts and lifts Person 3.\n- Person 2: looks a bit confused or surprised when his wristwatch is being unlocked from the railing.\n- Person 3: appears to be going along with the playful action, maybe a bit startled but also participating in the fun."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Scene 1:\n\n| Action                                    | Camera Angle       | Performance/Director's Note                                |\n| ----------------------------------------- | ------------------- | ----------------------------------------------------------- |\n| A man is standing by a railing, smiling. | Medium shot        | A carefree and cheerful attitude to set a relaxed mood.    |\n| He allows a woman to jump onto his back.  | Medium shot        | Anticipation and fun are present in his facial expression. |\n\n## Scene 2:\n\n| Action                                                                     | Camera Angle | Performance/Director's Note                                                      |\n| -------------------------------------------------------------------------- | ------------- | --------------------------------------------------------------------------------- |\n| The woman is on the man's back. He has bent over and she is nearly upside down. | Wide shot      | The sudden change creates tension; the man appears unaware or is ignoring the danger. |\n| He turns away from the camera, walking through the station.                | Medium shot  | The man proceeds as if everything is normal; escalating the sense of unease.       |\n\n--End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"Unexpected carry by friend\",\n  \"secondary_tags\": [\n    \"Surprise\",\n    \"Comedy\",\n    \"Friendship\"\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The scene is set in a subway station with green directional signs, metal railings, and a tiled floor. A Man In White Hoodie approaches a Man In Beige Coat, who has his hand on a railing. The Man In White Hoodie unlocks the railing’s mechanism. Then, he lifts Woman In Pink Coat onto his back: he bends down, she climbs on, and he supports her legs. He carries her past the railing and down a staircase, while the Man In Beige Coat watches. The mood is playful and supportive, as the Man In White Hoodie helps Woman In Pink Coat navigate the subway area with a piggyback ride."
        }
    ],
    "clip_106": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"Woman A\": {\n        \"attributes\": [\"black outfit\", \"colorful scarf\"],\n        \"actions\": [\"walk\", \"use phone\"]\n    },\n    \"Woman B\": {\n        \"attributes\": [\"yellow top\", \"blue pants\"],\n        \"actions\": [\"run\", \"kick\"]\n    },\n    \"Man C\": {\n        \"attributes\": [\"blue hoodie\", \"gray jacket\", \"blue jeans\"],\n        \"actions\": [\"lean on wall\", \"hold banana and bottle\"]\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Outdoor paved area between brick buildings with bicycles in the background\n\n- Woman A walks while looking at her phone.\n- Woman B runs in and playfully kicks Woman A.\n- Woman A reacts and interacts with Man C holding a banana and a bottle.\n\n*Woman A: \"Hey, what was that for?\"*  \n*Man C: \"She just likes to mess with you.\"*  \n*Woman A: \"Well, that was unexpected!\"*  \n\nWoman B's kick was playful; her motive was to surprise and playfully startle Woman A as a prank."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\"primary_tag\": \"people interacting\", \"secondary_tags\": [\"interaction\", \"outdoor\", \"playful\"]}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I was walking, texting, then someone kicked my phone! I turned, saw a banana, took a bite, surprised by the prank.\n\nI was by the wall, saw Woman A walking, so I had someone kick her phone. Then I offered a banana. She bit it, looked surprised."
        }
    ],
    "clip_107": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Pour water from a bottle onto a small mound of sand to wet the sand in a specific area.\n2. Use hands to shape and lift the wet sand, forming a solid, bowl - like sand structure.\n\n[\n  {\n   \"step_number\": 1,\n    \"tools_used\": [\"water bottle\"],\n    \"duration_estimate\": \"0 - 2\"\n  },\n  {\n    \"step_number\": 2,\n    \"tools_used\": [\"hands\"],\n    \"duration_estimate\": \"2 - 9\"\n  }\n]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A blue bottle pours water onto tan sand, creating a wet, compact patch that contrasts with the dry grains around it. Hands mold the damp sand, feeling its cool, gritty texture as it shapes into a solid form. The finished sand structure, smooth and firm, stands out against the loose, golden sand of the beach."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\":\"0-2s\",\"object\":\"bottle\",\"interaction\":\"pouring water on sand\"},{\"timestamp\":\"3-5s\",\"object\":\"sand\",\"interaction\":\"shaping wet sand\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the person's perspective: I pour water from the bottle onto the sand, then use my hands to shape the wet sand into a small, hollow structure. I carefully lift the sand formation to examine it.\nFrom the bottle's perspective: I release my liquid contents onto the sand, watching as they seep in and help the person mold the sand. My task of emptying is complete as the person works with the now-wet sand."
        }
    ],
    "clip_108": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"runner\": {\n        \"attributes\": [\"female\", \"wearing white sleeveless top\", \"wearing purple leggings\"]\n    },\n    \"run_details\": [\n        \"jog|0s|12 KM\",\n        \"jog|2s|12 KM IN PROGRESSION\",\n        \"jog|4s|12 KM IN PROGRESSION FROM 4:40/km TO 3:45/km\"\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I see the calm river glistening beside me as I run, and the crisp autumn leaves crunch under my feet; with each step, the rhythmic sound of my footsteps blends with the gentle rustle of foliage in the breeze."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n  \"primary_tag\": \"jogging outdoors\",\n  \"secondary_tags\": [\"fitness\", \"autumn\", \"water body\"]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "*I feel* determined as I run, adjusting my pace from 4:40/km to 3:45/km for this 12K. *I’m* focused on pushing my limits, enjoying the crisp air and scenic path, motivated by self-improvement and the beauty around me.  \nFrom the sidelines, *I watch* her with admiration. She runs with purpose, speeding up her pace. *I think* she’s driven by personal goals, maybe to beat a time or challenge herself, thriving in the peaceful, leafy environment.  \n\nAthlete's equipment: White sleeveless top, purple cropped leggings with orange accents and text, blue running shoes with white soles, and a wristwatch.  \nI. 1. Ground with fallen leaves and a dirt path  \nI. 2. Green grass  \nI. 3. Calm waterway with reflections  \nI. 4. Embankment with greenery  \nI. 5. Trees with autumn foliage  \nI. 6. Clear blue sky"
        }
    ],
    "clip_109": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Color   | Hand Shape Description       |\n|---------|------------------------------|\n| Purple  | Hands form a diamond shape   |\n| Green   | Hands form a bud shape       |\n| Yellow  | Hands form a zig - zag shape |\n| Red     | Hands form a bow shape       |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The purple sweater feels soft and warm against the skin. To form the hand shape above the head, the hands are raised and pressed together, creating a symmetrical, hood - like shape with the sleeves.\nI. Purple - Symmetrical, hood - like shape formed by pressing hands together above the head\nII. Green - Hands pressed together above the head to form a shape with a protruding part at the top\nIII. Yellow - Hands form a shape with a curved, horn - like protrusion above the head\nIV. Red - Hands form a symmetrical, diamond - topped hood - like shape above the head"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"clothing transformation\",\n  \"secondary_tags\": [\"multiple colors\", \"hand gestures\", \"indoor scene\"]\n}\n```\nThe main character achieved clothing transformation by using hand gestures and video effects."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. 双手举过头顶，手指并拢，掌心相对，形成一个类似兔子耳朵的形状，然后将双手向下移动，覆盖住头部两侧。\n2. *愉悦*\n3. 这种愉悦的情绪源于她在展示不同颜色毛衣（包括一件舒适的黄色毛衣）时，通过手部动作创造出有趣、可爱的造型，这种富有创意和趣味性的行为带来了轻松愉快的感觉。"
        }
    ],
    "clip_110": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. A man lifts a dog, and the dog jumps off a trampoline.\n2. The dog jumps again, catching a hoop mid - air, while another man interacts and a hand shares the video.\n{\n\"dog\": {\n\"trick\": \"跳跃并叼住圆环\",\n\"color\": \"棕色\"\n},\n\"men\": [\n{\n\"clothing\": \"浅色上衣和蓝色牛仔裤\"\n},\n{\n\"clothing\": \"黑色上衣和黑色裤子\"\n}\n]\n}\nThe dog's actions aim to perform a jumping - hoop - catching trick for training or entertainment."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Before jumping, I feel excited and focused, knowing I need to aim right. Mid - air, it's a rush—wind on my fur, everything moving fast. Landing, I feel relief and pride, my paws hitting the target (or safe spot) with a satisfying thud. I. A blue mat on a stone ledge. I. A grassy area. I. A man in a black outfit. I. A brick building with a sloped roof. I. A tree with branches. I. A tire swing. I. A dog (me) performing a jump trick."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"action\":\"jump through hoop\",\"timestamp\":\"00:02\"},{\"action\":\"swing on hoop\",\"timestamp\":\"00:07\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. A man in a beige top and blue jeans is holding a dog that is jumping towards a hanging ring.\n2. 视频切换（the video switches），一只狗从地面跑向一个人，然后跳起来去咬悬挂的环，此时一只手在点击点赞按钮。（A dog runs from the ground to a person and then jumps to bite the hanging ring, while a hand is clicking the like button.）\n3. The hand then clicks the share button, and the sharing interface pops up with various sharing options.\nThe main elements of the video software on the phone (clockwise from the bottom) are: input box for comments, at symbol, smiley face, music note, share button, comment button, like button, follow button, video publisher's information and music information."
        }
    ],
    "clip_111": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Dark top, ripped jeans, green gloves, beanie; holds racket\n- Dark top, jeans, green gloves, no headwear; holds pipe\n- Dark top, jeans, green gloves, no headwear; no held object\n- Dark top, jeans, green gloves, beanie; no held object"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I am lying on a conveyor belt, holding a tennis racket and a can, while three others are seated behind me, and we are all laughing and interacting.\n1. White clock, 2. Red and white sign, 3. Blue window, 4. Silver key on a string, 5. Blue window"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\":\"00:00\",\"person_ids\":[1,2,3,4],\"interaction_desc\":\"Group sitting and talking on conveyor\"},{\"timestamp\":\"00:04\",\"person_ids\":[2,3,4],\"interaction_desc\":\"Laughing and playful gestures between them\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the leftmost person: “I’m holdin’ a pipe, chillin’ with the group. We’re all laughin’ and jokin’, feelin’ relaxed. The rightmost has a racket—different from my pipe, but we’re all just havin’ fun together.”  \n\nFrom the rightmost person: “I’ve got a racket, playin’ around with the crew. The leftmost has a pipe, which is way different! We’re all laughin’, messin’ around, and enjoyin’ each other’s company.”"
        }
    ],
    "clip_112": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "| Action | Duration (s) | Difficulty (1-5) |\n|--------|--------------|------------------|\n| Jump forward | 1 | 3 |\n| Handstand transition | 2 | 4 |\n| Handstand hold | 2 | 4 |\n| Backflip | 3 | 5 |\n| Land | 1 | 2 |"
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "For a backflip, start with arms extended side - to - side, then swing them up as you jump and tuck.  \n\nIn the handstand, core engagement keeps your body aligned; squeeze your abs to maintain balance.  \n\nFor landing, keep *soft knees* to absorb impact, and land with feet shoulder - width apart. End of Tutorial"
        },
        {
            "field": "For Understanding",
            "prompt_id": "03",
            "response": "{\n    \"person\": {\n        \"clothing color\": \"gray\",\n        \"pants\": \"black with white stripes\"\n    },\n    \"actions\": [\"jump\", \"handstand\", \"backflip\"]\n},\n1. Trees\n2. House\n3. Car\n4. Lawn\n\nThe protagonist first jumps forward with arms extended, then performs a handstand on the lawn, followed by a backflip, and finally lands back on the lawn with arms outstretched."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The person starts with arms outstretched, jumps, does a handstand, holds it, then flips into a controlled landing. Each move flows smoothly from one to the next.\n\nDuring the handstand, I focus on balance, feeling the grass under my hands. My core tightens, and I stay steady before flipping down. The landing feels graceful, grounding me back on the lawn."
        }
    ],
    "clip_113": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"zoom_sequence\": [\n        \"1. Europa\",\n        \"2. Nederland\",\n        \"3. De具体e locatie binnen Nederland\"\n    ],\n    \"overlay_text\": \"Mine netherlands I bet u can't\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Storyboard for \"Got u\" Response:\n- **Map Zoom Phase**\n  - Gradual zoom from continental view to country-level detail\n  - Highlight color shift on the Netherlands boundary\n  - Road network detail emergence as zoom intensifies\n- **Street View Reveal**\n  - Suburban house architectural style\n  - Tree-lined street with parked cars"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"Europe|Multiple\",\"Netherlands|Dutch\",\"Residential Area|Dutch\"]\n该操作的目的是在谷歌地图上放大并定位到荷兰的一个住宅区，以回应评论中的挑战。\nI. 街道（带有“Bovenstraat”标识和自行车道）\nII. 住宅区的房屋\nIII. 街道两旁的树木和灌木丛\nIV. 背景中的天空"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A map of Europe appears with a comment saying \"Mine netherlands I bet u can't\". The map zooms in on the Netherlands. The view changes to a street view of a road in the Netherlands."
        }
    ],
    "clip_114": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. 0:00–2:00  \n{  \n  \"washing machine\": \"next to wall\",  \n  \"cleaning supplies\": \"on floor near washing machine\"  \n}  \n\nB. 2:00–9:00  \n{  \n  \"toilet\": \"next to wall\",  \n  \"toilet paper\": \"on cabinet near toilet\"  \n}  \n\n"
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "{\n  \"steps\": [\n    {\n      \"tool\": \"**leopard print cloth**\",\n      \"action\": \"Move through laundry area\"\n    },\n    {\n      \"tool\": \"**leopard print cloth**\",\n      \"action\": \"Enter bathroom space\"\n    },\n    {\n      \"tool\": \"**leopard print cloth**\",\n      \"action\": \"Approach toilet area\"\n    }\n  ],\n  \"inference\": \"Leopard print chosen for style, uniqueness, or personal preference.\"\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "\n  {\"timestamp\": \"0:03-0:04\", \"object\": \"Hand\", \"interaction\": \"Hold\"}\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "The redesigned utility area has tiled walls, a sleek washing machine, a modern toilet with bamboo decals, and cleaning supplies neatly arranged, creating an organized space."
        }
    ],
    "clip_115": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"Video Analysis:\": {\n    \"players\": [\n      {\n        \"id\": \"Player 1\",\n        \"attributes\": {\n          \"helmet\": \"Green Helmet\",\n          \"backpack\": \"Multi-colored Backpack\"\n        },\n        \"actions\": [\n          {\n            \"action\": \"Shooting\",\n            \"timestamp\": \"00:01\"\n          },\n          {\n            \"action\": \"Moving\",\n            \"timestamp\": \"00:01\"\n          },\n          {\n            \"action\": \"Shooting\",\n            \"timestamp\": \"00:03\"\n          },\n          {\n            \"action\": \"Moving\",\n            \"timestamp\": \"00:03\"\n          },\n          {\n            \"action\": \"Shooting\",\n            \"timestamp\": \"00:04\"\n          },\n          {\n            \"action\": \"Shooting\",\n            \"timestamp\": \"00:08\"\n          },\n          {\n            \"action\": \"Moving\",\n            \"timestamp\": \"00:09\"\n          },\n          {\n            \"action\": \"Shooting\",\n            \"timestamp\": \"00:10\"\n          }\n        ]\n      },\n      {\n        \"id\": \"Player 2\",\n        \"attributes\": {\n          \"helmet\": \"Black Helmet\",\n          \"backpack\": \"White Backpack\"\n        },\n        \"actions\": [\n          {\n            \"action\": \"Moving\",\n            \"timestamp\": \"00:01\"\n          },\n          {\n            \"action\": \"Moving\",\n            \"timestamp\": \"00:02\"\n          },\n          {\n            \"action\": \"Shooting\",\n            \"timestamp\": \"00:04\"\n          },\n          {\n            \"action\": \"Moving\",\n            \"timestamp\": \"00:06\"\n          },\n          {\n            \"action\": \"Moving\",\n            \"timestamp\": \"00:07\"\n          },\n          {\n            \"action\": \"Shooting\",\n            \"timestamp\": \"00:10\"\n          }\n        ]\n      }\n    ],\n    \"description\": \"The green helmet player is actively engaging and shooting with a rifle, while the black helmet player is responding with their rifle.\"\n  }\n, \"End of Analysis\"}}"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "{\n    \"roles\": {\n        \"Player A\": \"attacker\",\n        \"Player B\": \"attacker\"\n    },\n    \"critical_tactics\": [\n        {\n            \"tactic\": \"**aggressive movement**\",\n            \"evidence\": \"Player A moves quickly through the indoor space, engaging in combat.\",\n            \"success\": true\n        },\n        {\n            \"tactic\": \"**aggressive movement**\",\n            \"evidence\": \"Player B also moves actively within the building, participating in the firefight.\",\n            \"success\": true\n        }\n    ]\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n\"primary_tag\": \"firearm_engagement\",\n  \"secondary_tags\": [\"assault_rifle\", \"combat_maneuvering\", \"indoor_combat\"]\n}```\nTwo players engage in gunfight: one with M416, the other with SKS, indoors."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A player with 40 ammo out of 65 moves around, shooting at an opponent. The opponent takes damage (shown by red indicators). The player continues moving, aiming, and shooting. The opponent moves too, and the player opens an emote menu briefly before resuming shooting."
        }
    ],
    "clip_116": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "| Action_Sequence | Player_Attribute       | Interaction_Type      | Duration |\n|-----------------|------------------------|-----------------------|----------|\n| 1               | Gold jersey, number 17 | With red - white ball | Short    |\n| 2               | Gold jersey, number 17 | With referee          | Medium   |\n| 3               | Gold jersey, number 17 | With crowd            | Long     |"
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "{\n  \"on_field\": {\n    \"player\": {\n      \"jersey\": \"17\",\n      \"action_chain\": [\n        \"walk\",\n        \"bend over\",\n        \"stand up\",\n        \"talk\"\n      ]\n    },\n    \"referee\": {\n      \"uniform_color\": \"black\",\n      \"signal\": \"corner_flag\"\n    }\n  },\n  \"in_stands\": {\n    \"spectators\": [\n      {\n        \"clothing_color\": \"yellow\",\n        \"interaction\": \"smile\"\n      },\n      {\n        \"clothing_color\": \"black\",\n        \"interaction\": \"smile\"\n      }\n    ]\n  },\n  \"group_interaction\": \"true\"\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "A player chases the ball, trips, enters the stands; the crowd reacts, and the player looks embarrassed as he interacts with spectators."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "04",
            "response": "{\"core_entity\": \"17, yellow and dark blue\", \"key_action\": \"run after the ball in the stadium and then enter the spectator seats\", \"interaction_target\": \"spectators\"}"
        }
    ],
    "clip_117": [
        {
            "field": "For Instructional",
            "prompt_id": "01",
            "response": "Tutorial Steps: 1. Close stance squats - Squat with feet close together. 2. Single leg box squats - Squat on one leg using a box. 3. Single leg down, both legs up - Squat with one leg down, both up. 4. Attempt full pistol squats - Try full pistol squats despite failure."
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "{\n    \"Close stance squats\": {\n        \"primary_muscles\": [\"Quadriceps\", \"Glutes\"],\n        \"reps_shown\": 2\n    },\n    \"Single leg box squats\": {\n        \"primary_muscles\": [\"Quadriceps\", \"Glutes\", \"Hamstrings\"],\n        \"reps_shown\": 2\n    },\n    \"Single leg down, both legs up\": {\n        \"primary_muscles\": [\"Quadriceps\", \"Glutes\"],\n        \"reps_shown\": 2\n    },\n    \"Attempt full pistol squats\": {\n        \"primary_muscles\": [\"Quadriceps\", \"Glutes\", \"Calves\"],\n        \"reps_shown\": 1\n    }\n}"
        },
        {
            "field": "For Understanding",
            "prompt_id": "03",
            "response": "{\n  \"environment\": [\n    {\n      \"name\": \"basement\",\n      \"color\": \"brown\"\n    },\n    {\n      \"name\": \"bench\",\n      \"color\": \"yellow\"\n    },\n    {\n      \"name\": \"rug\",\n      \"color\": \"gray\"\n    },\n    {\n      \"name\": \"painting\",\n      \"color\": \"white\"\n    },\n    {\n      \"name\": \"walls\",\n      \"color\": \"white\"\n    }\n  ],\n  \"attire\": [\n    \"tank top\",\n    \"leggings\",\n    \"sneakers\"\n  ]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Start with close stance squats, then do single leg box squats, follow with single leg down and both legs up movements, and finally attempt full pistol squats."
        }
    ],
    "clip_118": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Description | Scene |\n|-------------|-------------|-------|\n| object | Bright pink, circular hula hoop | room with mirrors |\n| person | Wearing black pajamas with Snoopy and other Peanuts characters prints | kitchen |"
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "{\n  \"segments\": [\n    {\n      \"time_range\": \"00:00-00:03\",\n      \"primary_activity\": \"Hula hooping\",\n      \"body_focus\": \"Hips\"\n    },\n    {\n      \"time_range\": \"00:03-00:12\",\n      \"primary_activity\": \"Standing and posing\",\n      \"body_focus\": \"Full body\"\n    }\n  ],\n  \"transition_note\": \"The video transitions from a woman hula hooping to a woman in pajamas standing in a kitchen.\"\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "A woman in a blue top and patterned leggings is hula hooping with a pink hoop, rotating it around her hips for several turns while standing barefoot on a wooden floor. \n\nAnother woman, dressed in dark pajamas with cartoon prints, stands in a kitchen with her hand near her mouth in a thoughtful pose; she then suddenly turns and runs out of the frame, leaving the kitchen area with hanging baskets and a countertop visible.\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "* room | person starts hula hooping with two hoops simultaneously\n* kitchen | person takes a bite of a strawberry then walks out of the frame"
        }
    ],
    "clip_119": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"attributes\": [\"silver chain\", \"necklace\", \"jeans\", \"ripped jeans\", \"bodysuit\", \"collared shirt\", \"belt\"], \"actions\": [\"looking at the camera\", \"posing\", \"sitting\", \"gesturing\"]}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I adjust my hair with both hands, feeling a sense of focus, then pose with the second individual, feeling engaged. I adjust my hair and pose with the other person."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"primary_tag\":\"fashion\",\n    \"secondary_tags\":[\"vibrant\",\"playful\",\"stylish\"]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. **Person A** adjusts the camera and moves back to sit on a table. 2. **Person A** appears in a duplicate effect, posing with different stances. 3. **Person A** stands up, adjusts clothing, and makes gestures while the duplicate effect continues."
        }
    ],
    "clip_120": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Type | Color |\n| --- | --- | --- |\n| Woman (outfit 1) | Hoodie, shorts | Gray, black |\n| Woman (outfit 2) | Tank top, shorts | Green, black |\n| Baby | Outfit | Pink, blue |\n| High chair | Furniture | Black |\n---\n[{\"action\": \"stretch leg up\", \"timestamp\": \"2-6s\"}, {\"action\": \"remove hoodie\", \"timestamp\": \"4-8s\"}, {\"action\": \"kick hoodie up and catch\", \"timestamp\": \"8-12s\"}]\n---\nShe appears joyful. Visual cues: **smiling** throughout the video and **dancing movements** which suggest happiness."
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "1. leg lift | leg | gray hoodie\n2. remove clothing | arms | gray hoodie\n3. dance | whole body | green tank"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"stretching\",\n  \"secondary_tags\": [\"kitchen\", \"gray hoodie\", \"high kick\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In the kitchen, I stretch, kick high, remove my hoodie, and dance—feeling playful, showing off. The baby watches, so I go all out, grinning.  \n\nIn the kitchen, I see the woman stretch, kick, dance, and toss her hoodie. Lights, fridge, her moves—so big and fast. I’m curious, eyes wide, watching her energy."
        }
    ],
    "clip_121": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "| Time (s) | Action | Body Position |\n|----------|--------|---------------|\n| 0 - 2    | Approach bars & grasp | Standing, hands reaching |\n| 2 - 4    | Lift legs, initiate flag | Horizontal (legs lifting) |\n| 4 - 14   | Maintain human flag | Horizontal (body parallel to ground, legs moving slightly) |\n\nHe holds the human flag for ~10s (from 4s to 14s), which is ≥5s, so it’s **successful**. The leg movement is minor adjustment, not a failure-inducing sway."
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "A. Outdoor setting near a building; evening time with artificial lighting.\n{\"man's pants\":\"light gray\",\"man's shoes\":\"white\",\"building wall\":\"light beige\",\"metal bars\":\"dark gray\"}\nThe man runs toward the building, grips metal bars with both hands, and performs a human flag while keeping his body horizontal."
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "Viewer: A shirtless man in gray pants runs, grabs wall bars, and does a human flag with leg movements. Text bubble says “Do the human flagggggg”. Comment request.\n\nPerformer: Feels confident showing strength, excited to respond to the comment, proud of nailing the human flag. Comment request."
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "1. Equipment: Parallel bars (wall - mounted). Action: Approach the bars, grip the higher bar with one hand and the lower bar with the other, hands shoulder - width apart.\n2. Equipment: Parallel bars (wall - mounted). Action: Engage core, lift legs off the ground, and start to horizontally align the body, using arm and core strength to hold.\n3. Equipment: Parallel bars (wall - mounted). Action: Maintain the horizontal hold, keeping the body straight, legs together, and grip firm to stabilize the \"human flag\" position."
        }
    ],
    "clip_122": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"character1\": {\n        \"actions\": [\"aim a gun\", \"shoot a bullet\"],\n        \"thoughts\": [\"**Amused** that the bullet trick worked well.\", \"**Satisfied** with the successful shot outcome.\"]\n    },\n    \"character2\": {\n        \"reaction\": \"look surprised\",\n        \"inferred_cause\": \"shoot a bullet\"\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- [medium]: Hand with gun, bright sky background\n- [medium]: Animated male character with serious expression, blurred background\n- [close-up]: Animated male character with red eyes smiling, dark background"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n    {\n        \"time\": \"00:00\",\n        \"action\": \"A hand is shown holding a gun, with text overlays in German encouraging interaction and sharing.\"\n    },\n    {\n        \"time\": \"00:01\",\n        \"action\": \"An anime character in a yellow hoodie appears, looking determined, followed by a dynamic blue speed effect.\"\n    },\n    {\n        \"time\": \"00:03\",\n        \"action\": \"A bullet is fired, transitioning to a close-up of the character smiling confidently, then a girl with a flower hairpin reacts with surprise.\"\n    }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I grip the rifle, determined to show my skill and confidence. My goal is to amaze, to prove I’m unstoppable—adrenaline surges as I aim, a mix of excitement and focus on my face.\n\nThe uniformed character’s eyes widen, shock painting their features. They didn’t expect such boldness, their surprise evident in the way they freeze, caught off-guard by my daring action."
        }
    ],
    "clip_123": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- green screen display\n- black keyboard\n- placed on table\n- pink dress\n- red headband"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. A. Camera angle: wide; focus: laptop with green screen in foreground, background shows a person covering a child with a blanket on a bed. B. Sound effects: blanket rustling, gentle lullaby. C. Title: Bedtime Routine with Laptop"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"laptop:silver\",\"lipstick:red\",\"notebook:white\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I gently tuck the blanket around my sleeping child, *relieved* she’s resting. I smooth her hair, *affectionate*, ensuring comfort before stepping back.  \n\nMy room has soft walls with stars! The bed’s cozy, and when Mom tucks me in, the warmth feels *safe*, like a hug that stays."
        }
    ],
    "clip_124": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"main_character_emotions\": [\n        {\n            \"emotion\": \"sad\",\n            \"trigger\": \"thinking of bad memories\",\n            \"timestamp\": 4,\n            \"older_brother_attribute\": \"red\"\n        },\n        {\n            \"emotion\": \"sad\",\n            \"trigger\": \"thinking of bad memories\",\n            \"timestamp\": 8,\n            \"older_brother_attribute\": \"red\"\n        },\n        {\n            \"emotion\": \"sad\",\n            \"trigger\": \"thinking of bad memories\",\n            \"timestamp\": 12,\n            \"older_brother_attribute\": \"red\"\n        }\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Diary Entry: The main character (a mouse-like figure) first knocks on a red door. Then, as the door opens, he kneels on the floor, showing a thought bubble of him playing games but then being interrupted by an older brother, followed by sad scenarios like being chased by a dog and crying. Finally, the orange - haired character (who opened the door) looks concerned and then sits with the main character as he cries, with water (from his tears) rising around them. The orange - haired character's motivation seems to be to comfort the main character after seeing him so upset, likely because she cares about his well - being and wants to help him feel better. --End--"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "I stand here, tears blurring my vision, remembering how my older brother took over my game time. My heart aches, and the thought bubble of my loneliness hangs heavy—like a storm cloud over my joy.  \n\nFrom the doorway, I see their shoulders shake with silent sobs. My chest tightens; I want to comfort them. Their tear-streaked face and trembling hands are a silent plea, urging me to reach out and ease their pain."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "04",
            "response": "{\n  \"primary_tag\": \"mouse crying\",\n  \"secondary_tags\": [\"door knocking\", \"memory flashback\", \"sad expression\"]\n}"
        }
    ],
    "clip_125": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "- Black and silver dumbbells\n- Black and silver weight plates\n- Black and silver weight rack\n- Black sports bra, black leggings, focused expression."
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "A. Knees bent, grip ropes with both hands.\nB. Knees bent, alternate raising ropes up and down.\nC. Knees bent, maintain steady rope movement."
        },
        {
            "field": "For Understanding",
            "prompt_id": "03",
            "response": "1. gym interior\n\n{\n  \"people\": [\n    {\n      \"id\": 1,\n      \"interactions\": []\n    },\n    {\n      \"id\": 2,\n      \"interactions\": []\n    },\n    {\n      \"id\": 3,\n      \"interactions\": []\n    }\n  ]\n}\n\nAll people have the same number of interactions (zero), so no single person has the most interactions."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A woman vigorously moves battle ropes up and down. Two observers clap and encourage her. She appears determined and focused."
        }
    ],
    "clip_126": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity    | Color | Position                |\n|-----------|-------|-------------------------|\n| Submarine | Gray  | Foreground, moving      |\n| Ship 1    | Dark  | Background, distant     |\n| Ship 2    | Dark  | Background, distant     |\n\n[\"standing on submarine\"]\n\nA gray submarine moves through waters, with people atop it, while two distant ships float under a partly cloudy sky."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I am the Submarine’s AI, calm as I monitor the gentle sway of the vessel through the waters. My sensors hum with alertness, scanning for any anomalies in the vast blue expanse. Determination courses through my systems—this patrol is vital, and I will ensure every detail is precise.  \n\nThe Submarine cuts through the Ocean like a silent predator, its hull gliding beneath the surface with predatory grace. Waves part around it, yielding to its stealthy advance, as if the sea itself acknowledges the Submarine’s purposeful, unyielding presence."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\nmoment,entities_in_view,dominant_color\n0-2,submarine|ship,blue\n5-7,ship|submarine,blue\n```\n{\n    \"most_dynamic_moment\": 2\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "At dawn, the ocean awakens as a submarine glides through the water, creating gentle waves. The calm sea and distant ships suggest a peaceful start to the day.\nThe submarine moves steadily, its conning tower visible with crew members and an American flag, indicating a naval vessel on patrol. The sunrise casts a soft light, hinting at a new mission beginning.\nThe submarine continues its journey, cutting through the waves with purpose, while the horizon stretches ahead, promising adventure and duty as it sails into the horizon."
        }
    ],
    "clip_127": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[\n  {\"name\":\"bananas\",\"color\":\"yellow\",\"position\":\"center\"},\n  {\"name\":\"apples\",\"color\":\"red\",\"position\":\"center\"},\n  {\"name\":\"grapes\",\"color\":\"purple\",\"position\":\"center\"},\n  {\"name\":\"bread\",\"color\":\"brown\",\"position\":\"center\"},\n  {\"name\":\"juice\",\"color\":\"yellow\",\"position\":\"left\"},\n  {\"name\":\"bowl\",\"color\":\"white\",\"position\":\"center\"}\n]\n---\nOccasional basket use"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Opening Scene\nA family of four sits on a picnic blanket in a grassy field, unpacking food from a basket. The father holds a bunch of **bananas**, while the mother takes out a baguette.\n\n## Scene 2\nThe mother places the baguette on the blanket, and the father sets the **bananas** down. The children watch with interest as the parents continue to unpack.\n\n## Scene 3\nThe father takes out a white bowl, and the mother arranges **apples** and grapes. The children lean in, excited about the picnic spread.\n\n## Scene 4\nThe father hands a baguette and an **apple** to the daughter in yellow. The mother smiles, pleased with the cheerful family moment.\n\n## Closing Scene\nThe daughter accepts the food, and the family shares a joyful, relaxed moment, ready to enjoy their picnic together."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"banana|yellow|3\",\"apple|red|4\",\"grape|purple|1\",\"baguette|brown|2\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Family Picnic Moments: Man distributes bananas, woman arranges bread, child adjusts hair. Mood is joyful; cues: smiling faces, relaxed body language. ---End of Description---"
        }
    ],
    "clip_128": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"handshake_sequence\": [\n        {\n            \"start_time\": 0.5,\n            \"interacting_hands\": [\"camera_wearer\", \"person_1\"],\n            \"action_details\": \"Brief handshake with person_1\"\n        },\n        {\n            \"start_time\": 4.0,\n            \"interacting_hands\": [\"camera_wearer\", \"person_2\"],\n            \"action_details\": \"Handshake with person_2\"\n        },\n        {\n            \"start_time\": 7.5,\n            \"interacting_hands\": [\"camera_wearer\", \"person_3\"],\n            \"action_details\": \"Handshake with person_3\"\n        }\n    ]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "02",
            "response": "As I reached out, hands met warmly—first firm, then others joined, each shake carrying friendliness, connection, and shared purpose, making me feel included.  \nFrom the side, I saw hands extend, clasp, and release, each handshake quick yet sincere, showing camaraderie and mutual respect among the group."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"hand_1\": {\n        \"color\": \"light skin\",\n        \"nail_polish\": \"no\"\n    },\n    \"hand_2\": {\n        \"color\": \"light skin\",\n        \"nail_polish\": \"no\"\n    },\n    \"hand_3\": {\n        \"color\": \"light skin\",\n        \"nail_polish\": \"no\"\n    },\n    \"hand_4\": {\n        \"color\": \"light skin\",\n        \"nail_polish\": \"no\"\n    },\n    \"hand_5\": {\n        \"color\": \"light skin\",\n        \"nail_polish\": \"no\"\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "1. The right hand extends forward; 2. The right hand makes contact with another hand; 3. The right hand grips and shakes the other hand.\nA total of 5 hands have appeared.\n\"Nice to meet you!\",\"Pleasure doing business!\""
        }
    ],
    "clip_129": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"Curly-haired boy\": {\n        \"attributes\": [\"curly hair\", \"white and black short-sleeve shirt\", \"blue jeans\", \"red sneakers\"],\n        \"interactions\": [{\"target\": \"ground\", \"action\": \"fall\"}, {\"target\": \"bicycle wheel\", \"action\": \"avoid\"}]\n    },\n    \"Boy in pink shirt\": {\n        \"attributes\": [\"black-rimmed glasses\", \"pink long-sleeve shirt\", \"blue jeans\", \"blue backpack\"],\n        \"interactions\": [{\"target\": \"bicycle\", \"action\": \"let go\"}, {\"target\": \"ground\", \"action\": \"fall\"}, {\"target\": \"car\", \"action\": \"walk towards\"}]\n    },\n    \"Girl in striped shirt\": {\n        \"attributes\": [\"long hair\", \"red and black striped long-sleeve shirt\", \"blue jeans\", \"brown boots\", \"brown bag\"],\n        \"interactions\": [{\"target\": \"Boy in pink shirt\", \"action\": \"pull\"}, {\"target\": \"ground\", \"action\": \"fall\"}, {\"target\": \"car\", \"action\": \"walk towards\"}]\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Bike not saved: Boy and girl on ground, a bike wheel rolls past, implying damage|*thump*, *crash*|shock, concern"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"primary_tag\": \"car hits bike\",\n    \"secondary_tags\": [\"collision\", \"parking lot\", \"accident\"]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Person in pink shirt: Wears pink shirt, reacts to car, runs, falls, then stands by red car, looking shocked. 2. Striped shirt girl: Wears red/black striped shirt, reacts to car, runs, falls, sits, then approaches red car, confused."
        }
    ],
    "clip_130": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"person_A\": {\n        \"attributes\": [\"gray hoodie\", \"green pants\", \"outdoor\"],\n        \"interactions\": [{\"target\": \"door\", \"action\": \"touch\"}]\n    },\n    \"person_B\": {\n        \"attributes\": [\"yellow hoodie\", \"indoor\"],\n        \"interactions\": [{\"target\": \"door\", \"action\": \"open\"}]\n    }\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "02",
            "response": "I run down the sidewalk, knock, then hide around the corner, giggling. I’m excited to prank them and see their reaction.  \n\nI hear a knock, open the entry, and look around confused. No one’s there. I’m annoyed and curious, wondering who’d do this. I close the entry, still puzzled."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"Young male walks along path\",\n  \"secondary_tags\": [\n    \"Walking on sidewalk\",\n    \"Knocking on door\",\n    \"Feeling playful\"\n  ]\n}\n```"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "1. Person B runs toward the door; check surroundings first.\n2. Person B pulls the door open; ensure the door is not stuck.\n3. Person B closes the door; make sure it latches properly."
        }
    ],
    "clip_131": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"cow\": {\n    \"attributes\": [\n      \"white\",\n      \"animal\"\n    ],\n    \"interactions\": []\n  },\n  \"motorcycle\": {\n    \"attributes\": [\n      \"red\",\n      \"vehicle\"\n    ],\n    \"interactions\": [\n      \"passes|cow\",\n      \"drives towards|bus\",\n      \"passes|other motorcycles\"\n    ]\n  },\n  \"bus\": {\n    \"attributes\": [\n      \"yellow\",\n      \"vehicle\"\n    ],\n    \"interactions\": [\n      \"drives towards|motorcycle\"\n    ]\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A first-person perspective on a **red** motorcycle navigates through a vibrant, crowded street market. A large yellow bus with bright headlights approaches from the opposite direction. A white cow *walks* leisurely past the motorcycle on the left side of the road. The bus passes closely, dominating the frame. The rider continues forward, revealing more market activity and other two-wheelers ahead.\n\n## Market Atmosphere\nThe air hums with the blend of distant chatter and the low rumble of vehicles. A mix of cooking aromas and fresh produce scents likely fills the bustling street. Occasional honks punctuate the ambient sounds, adding to the lively urban tapestry.\n\nA **forward tracking shot** captures the continuous movement through the busy market lane. The camera also employs subtle **horizontal panning** as the rider makes minor steering adjustments.\n\nBefore the large yellow bus passes, the immediate road ahead seems moderately dense with people and smaller vehicles. Following the bus's passage, the street briefly appears less congested, though more motorcycles quickly fill the void."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"Motorcycle ride at dusk\",\n  \"secondary_tags\": [\"red\", \"riding\", \"evening\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the rider's view, the street is busy. A large yellow bus passes by. Many people walk on the sides. Other bikes and scooters are around. It feels crowded, but I am navigating through. I keep a close watch on the traffic and people moving past me.\n\nFrom the cow's view, the street is very crowded. Many humans are walking right next to me. A red vehicle is following closely. A large yellow thing just rumbled by. It is hard to find space. There are too many things and people close by."
        }
    ],
    "clip_132": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Spatial Position | Approximate Vehicle Type | Color |\n|-----------------|--------------------------|-------|\n| Front           | Van                      | White |\n| Rear            | Not visible              | Not visible |\n| Front-right     | Compact SUV              | Grey  |\n| Right-side      | Minivan                  | Silver |\n| Rear-right      | Not visible              | Not visible |\n\nThe Rear vehicle's license plate is Not visible. Its brand is Unidentifiable."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- white utility truck blocking the road\n- red car parked by the curb\n- faint hum of idling engines\n\n{\n  \"key_moments\": [\n    {\n      \"timestamp\": \"0:00\",\n      \"description\": \"White truck blocks road, cars wait\",\n      \"mood\": \"calm\"\n    },\n    {\n      \"timestamp\": \"0:03\",\n      \"description\": \"Truck moves, cars start passing by\",\n      \"mood\": \"busy\"\n    }\n  ],\n  \"transition\": \"truck moves, traffic flow resumes\"\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"primary_tag\": \"Intersection traffic\",\n    \"secondary_tags\": {\n        \"atmosphere\": \"calm\",\n        \"vehicle_count\": \"≤4\",\n        \"time_of_day\": \"afternoon\"\n    },\n    \"critical_moments\": [\n        {\n            \"timestamp\": \"0:00\",\n            \"event\": \"White truck blocks view\"\n        },\n        {\n            \"timestamp\": \"0:02\",\n            \"event\": \"Blue SUV passes by\"\n        }\n    ]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I speed past the white truck, heart racing with urgency, hoping to make the light. The road’s clear, so I push forward, ignoring the other cars waiting at the intersection.  \n\nWaiting for the red light, I watch the black SUV zoom by, then other cars turn. Impatient, I tap my foot, eager for the light to change so I can cross safely."
        }
    ],
    "clip_133": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "```json\n[\n  {\n    \"timestamp\": \"00:00\",\n    \"handler_team\": \"white\",\n    \"action\": \"Dribbling the ball down the court and shooting\",\n    \"outcome\": \"success\"\n  },\n  {\n    \"timestamp\": \"00:04\",\n    \"handler_team\": \"blue\",\n    \"action\": \"Grabbing a rebound under the basket\",\n    \"outcome\": \"success\"\n  }\n]\n```"
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "- BAL\n- Basketball Africa League\n- Nike\n{\n  \"teams\": [\"PATRIOTS BC\", \"RIVERS HOOPERS BC\"],\n  \"score\": \"15-18\"\n}\nPlayers are in the first quarter with active play."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n[\n    {\n        \"start\": \"00:00\",\n        \"end\": \"00:02\",\n        \"handler_team\": \"white\",\n        \"action\": \"Dribble and attempt layup\",\n        \"long_play\": true\n    },\n    {\n        \"start\": \"00:02\",\n        \"end\": \"00:03\",\n        \"handler_team\": \"white\",\n        \"action\": \"shoot near basket\"\n    },\n    {\n        \"start\": \"00:03\",\n        \"end\": \"00:06\",\n        \"handler_team\": \"white\",\n        \"action\": \"rebound and score\"\n         \"long_play\": true\n    }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I sprint toward the basket, dribbling hard, muscles burning, eyes locked on the hoop—determined to score, heart racing with focus.\n\nI leap to block, arms out, trying to stop the shot. The ball goes in; I land, frustrated, knowing I couldn’t stop the score, disappointment weighing on me."
        }
    ],
    "clip_134": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"player_weapon\": {\n        \"color\": \"red\",\n        \"type\": \"rifle\"\n    },\n    \"key_action\": \"shoot enemy in Mylta\",\n    \"enemy_status\": \"knocked out\"\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "02",
            "response": "{\n    \"primary_tag\":\"Shooting enemy\",\n    \"secondary_tags\":[\"Sniper rifle\",\"Building\",\"Enemy knocked out\"]\n},\nThe character shoots the enemy down from inside a building, looking out through a window at an urban area with roads, buildings, and a forested hill in the background."
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "03",
            "response": "The player targeted the enemy on the distant building likely due to the enemy’s clear visibility on the structure’s balcony and their exposed positioning, which offered a high-value target with minimal cover. These visual cues suggested an optimal opportunity to engage before the enemy repositioned.  \n\nThe player’s movement from the window to the grassy area utilized environmental cover effectively: the transition from the building to the outdoor space leveraged the wall and tall grass for concealment, reducing exposure to other threats. This tactical repositioning also positioned the player to maintain line of sight on the enemy while minimizing vulnerability, showcasing sound spatial awareness."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The player starts inside a building near a window, holding a scoped rifle. They move outside, run along a wall, then aim the rifle. The player shoots at an enemy on a balcony and knocks them down."
        }
    ],
    "clip_135": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Vehicle Type | Color | Relative Position (Left/Middle/Right Lane) |\n|--------------|-------|------------------------------------------|\n| Hatchback    | White | Left Lane                                |\n| Ute          | Blue  | Middle Lane                              |\n| SUV          | White | Right Lane                               |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "02",
            "response": "[{\"vehicle_type\":\"truck\",\"color\":\"white\",\"timestamp\":\"06:41:45\"},{\"vehicle_type\":\"suv\",\"color\":\"white\",\"timestamp\":\"06:41:45\"},{\"vehicle_type\":\"pickup_truck\",\"color\":\"blue\",\"timestamp\":\"06:41:45\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "In front, a white SUV, a blue car, and a large truck with green cargo are visible on the road.\n\nOn the right, distant vehicles travel on a parallel road, separated by a metal guardrail."
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "If standstill traffic, try waiting for clearance.\nIf unclear cargo, try keeping safe distance.\nIf vehicle proximity, try moving to clear lane.\nThe vehicle that caused the collision: large truck , the vehicle that was hit: blue pickup truck."
        }
    ],
    "clip_136": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "[\n  {\n    \"timestamp\": 1,\n    \"player_team\": \"white\",\n    \"player_id\": 1,\n    \"action\": \"smash\",\n    \"target\": 2\n  },\n  {\n    \"timestamp\": 1,\n    \"player_team\": \"red\",\n    \"player_id\": 2,\n    \"action\": \"lift\",\n    \"target\": 2\n  },\n  {\n    \"timestamp\": 2,\n    \"player_team\": \"white\",\n    \"player_id\": 2,\n    \"action\": \"drop shot\",\n    \"target\": 1\n  },\n  {\n    \"timestamp\": 3,\n    \"player_team\": \"red\",\n    \"player_id\": 1,\n    \"action\": \"lift\",\n    \"target\": 2\n  },\n  {\n    \"timestamp\": 3,\n    \"player_team\": \"white\",\n    \"player_id\": 2,\n    \"action\": \"smash\",\n    \"target\": 1\n  }\n]"
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "Match Info: {\"teams\": [\"LI/LIU 0-14\", \"XIA/DU 0-16\"], \"player_attire\": {\"white_team\": \"white t-shirt, black shorts\", \"red_team\": \"red t-shirt, black shorts\"}, \"venue\": \"Chengdu FISU Games\"} --End Info--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"primary_tag\": \"badminton doubles match\",\n    \"secondary_tags\": [\"sports\", \"rally\", \"point contested\"],\n    \"players\": [\n        {\n            \"feature\": \"left player in white jersey\",\n            \"action\": \"move and hit shuttlecock\"\n        },\n        {\n            \"feature\": \"right player in white jersey\",\n            \"action\": \"move, hit shuttlecock, and slide on court\"\n        },\n        {\n            \"feature\": \"left player in red jersey\",\n            \"action\": \"hit shuttlecock and move\"\n        },\n        {\n            \"feature\": \"right player in red jersey\",\n            \"action\": \"hit shuttlecock and move\"\n        }\n    ]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "As I dived, my body stretched forward, muscles straining to reach the shuttlecock. The court rushed up, and I felt the impact as I hit the ground. I swung my racket with all my might, but my effort wasn't enough... the shuttlecock sailed out."
        }
    ],
    "clip_137": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"gas_masked_soldier\": [\n        {\n            \"gear_details\": \"Green uniforms, green helmets, gas masks with blue-tinted goggles, holding rifles\",\n            \"initial_action\": \"Aim rifles forward in a trench\",\n           \"interaction_event\": [\n                \"Look towards a dog\",\n                \"Lower rifles to the ground\",\n                \"Bend down\"\n            ]\n        }\n    ],\n    \"beard blue\": [\n        {\n            \"gear_details\":\"Blue uniform, brown straps, holding a rifle\",\n            \"initial_action\": \"Aim rifle forward in a trench\",\n            \"interaction_event\": [\n                \"Stare intently\",\n                \"Maintain focus on the dog\"\n            ]\n        }\n    ],\n    \"conflict_resolution\": \"The gas-masked soldiers lower their rifles and bend down, likely resolving the conflict by showing non-aggression towards the dog, while the bearded soldier in blue observes intently.\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Two soldiers aim guns; two gas - masked soldiers react, then a dog makes them drop guns.\n\nI'm the bearded soldier. When I point with my head, I'm tense. The enemy's here, and I must guide my comrade. I feel a mix of determination and anxiety, hoping we can handle this threat.\n\nFor the gas - masked soldiers: startled, fearful, hesitant."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  {\n    \"timestamp\": \"00:00\",\n    \"interaction_desc\": \"Soldiers holding guns, pointing forward.\"\n  },\n  {\n    \"timestamp\": \"00:06\",\n    \"interaction_desc\": \"One soldier drops rifle.\"\n  },\n {\n    \"timestamp\": \"00:07\",\n    \"interaction_desc\": \"Both soldiers drop rifles.\"\n  }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The scene is set in a misty trench with wooden walls.\n\nTwo soldiers in different uniforms aim rifles at each other, showing tension.\n\nThe gas - masked soldiers lower their rifles. *Rifles clank* as they set the guns down, and *soft exhale* can be heard from their masks."
        }
    ],
    "clip_138": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"cat\": {\n        \"interactions\": [\n            {\n                \"target\": \"mouse\",\n                \"action\": \"look at mouse\",\n                \"start_frame\": 6\n            },\n            {\n                \"target\": \"mouse\",\n                \"action\": \"be electrocuted with mouse\",\n                \"start_frame\": 24\n            }\n        ],\n        \"state_changes\": [\n            \"expression: relaxed→surprised→smiling→relaxed→angry→surprised\",\n            \"attire: none→wear white scarf\"\n        ]\n    },\n    \"mouse\": {\n        \"interactions\": [\n            {\n                \"target\": \"cat\",\n                \"action\": \"fall near cat\",\n                \"start_frame\": 6\n            },\n            {\n                \"target\": \"cat\",\n                \"action\": \"look at cat\",\n                \"start_frame\": 6\n            },\n            {\n                \"target\": \"scientists\",\n                \"action\": \"be electrocuted by scientists\",\n                \"start_frame\": 24\n            },\n            {\n                \"target\": \"cat\",\n                \"action\": \"be electrocuted with cat\",\n                \"start_frame\": 24\n            }\n        ],\n        \"state_changes\": [\n            \"expression: scared→angry→scared\",\n            \"size: normal→tiny\"\n        ]\n    },\n    \"scientists\": {\n        \"interactions\": [\n            {\n                \"target\": \"mouse\",\n                \"action\": \"drop mouse into box\",\n                \"start_frame\": 3\n            },\n            {\n                \"target\": \"mouse\",\n                \"action\": \"electrocute mouse\",\n                \"start_frame\": 24\n            },\n            {\n                \"target\": \"cat\",\n                \"action\": \"electrocute cat\",\n                \"start_frame\": 24\n            }\n        ],\n        \"state_changes\": [\n            \"expression: relaxed→smiling→angry→smiling\",\n            \"action: press remote control→fire electric shock\"\n        ]\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Mouse's Tale:  Oh no, a cat! I was just minding my own business when suddenly this giant, furry creature appeared. It was trapped in a box, but that didn't make me feel any better. Its eyes locked onto me. I knew I had to distract it. I struck a pose and did a little dance to divert its attention. It seemed to work for a moment. But then, whoa, what was that? It shrunk to minuscule size as blue rays appeared! What was happening? The tiny, new world seemed quite intimidating, so I ran. My heart pounded with fear as the world around me suddenly increased many times, and I hoped I could make it out alive."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"emotion\": \"content\",\"timestamp\": 0, \"reason\": \"The cat licks his paw\"},{\"emotion\": \"surprised\",\"timestamp\": 1,\"reason\": \"The cat is surprised when he saw the mouse\"},{\"emotion\": \"happy\",\"timestamp\": 3,\"reason\": \"The cat is happy after the mouse is dancing\"},{\"emotion\": \"scared\",\"timestamp\": 7,\"reason\": \"The cat is scared of the shrinking ray\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A brown cartoon cat sits inside a glass box and licks its paw. The cat gets surprised when it sees a gray mouse. The mouse runs and does a handstand to taunt the cat. Two scientist cartoons shoot a ray gun. Back in the box, the mouse zaps the cat. The cat becomes scared after being shot."
        }
    ],
    "clip_139": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Static Attributes | Dynamic Actions |\n| -------- | ----------------- | --------------- |\n| Pen | Color: Blue/White; Type: Ballpoint | Writing |\n| Hand | Action Type: Holding | Drawing |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**Moment 1:**\n\nSights: A white page stretches out, filled with rows of blue text reading \"Ram Ram Ram\". Black outlines of a figure are drawn amidst the text, creating shapes within the words. The pen approaches the blank space within the outline.\n\nFeeling: A soft pressure as the pen's tip meets the paper. A smooth glide as the pen moves, leaving a trail of blue ink that duplicates the letters: \"Ram Ram Ram\".\n\n**Moment 2:**\n\nSights: The pen continues filling the area with lines of the same text, meticulously following the black outlines of the image. The picture is becoming more and more clear, showing the shape of the hinduist Hanuman.\n\nFeeling: A steady movement, pressing the pen against the paper, maintaining even pressure to keep the blue ink flowing."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  {\"timestamp\": \"00:00\", \"event_name\": \"pen starts filling\", \"effect\": \"the inner picture area is filling in with writing\"},\n  {\"timestamp\": \"00:07\", \"event_name\": \"camera zooms out\", \"effect\": \"picture being written comes more into view\"}\n]"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "{\n    \"pen\": {\n        \"color\": \"blue and white\",\n        \"type\": \"ballpoint\"\n    },\n    \"paper\": {\n        \"color\": \"white\",\n        \"texture\": \"smooth\"\n    }\n}\n\n1.  Writing the word \"Ram\" repeatedly with a pen. (Difficulty: 1)\n2.  Filling in the shape of Hanuman with the word \"Ram\". (Difficulty: 2)\n3.  Staying within the lines of the Hanuman drawing. (Difficulty: 3)\n\nStaying within the lines of the Hanuman drawing is the most challenging, mainly because the precision required with the pen. The smooth paper and ballpoint pen don’t provide much friction, demanding steadier hand movements to prevent going over the edges of the shape."
        }
    ],
    "clip_140": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n   \"child\": {\n     \"static_attributes\": [\n       \"green shirt\",\n       \"orange pants\",\n       \"blond hair\"\n     ],\n     \"initial_position\": \"stands near the counter\"\n   },\n   \"adult\": {\n     \"static_attributes\": [\n       \"yellow hoodie\",\n       \"pink pants\",\n       \"blond hair\"\n     ],\n     \"initial_position\": \"stands behind the child, near the counter\"\n   },\n   \"large golden egg\": {\n     \"static_attributes\": [\n       \"round shape\",\n       \"gold color\",\n       \"large size\"\n     ],\n    \"initial_position\": \"attached to the toy car, near the counter\"\n  }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "# Cleanup Plan\n\n-   Vacuum cleaner: Suction up the eggs.\n-   Broom and dustpan: Sweep the eggs into the dustpan.\n-   Wet wipes: Wipe up any residue.\n\n# Child's Intention\n\nThe child is delighted, wearing a big smile as he excitedly pushes the cart. He seems to be playing, perhaps envisioning himself as a delivery driver or a parade leader, eager to share the sweet treats with imaginary friends. "
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"spill_time\": 1.6,\n    \"reactions\": [\n        {\n            \"action\": \"laugh while kneeling\",\n            \"duration\": \"2s\"\n        },\n        {\n            \"action\": \"cover mouth in surprise\",\n            \"duration\": \"1s\"\n        }\n    ],\n    \"object_count\": 18\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The excitement was too real! I was pushing the cart so fast. I couldn't wait to share the chocolates with my family. I felt so cool and confident! Then, the cart tipped over. Oh no! Now all of the chocolate eggs are rolling all over the floor!\n\nOh my gosh. The child's excitement got the best of them. They were having so much fun pushing the cart! I thought to myself \" slow down\" when they sped up! Unfortunately, the cart tipped over.  Now we have a giant mess to clean up. At least they are still smiling about it!"
        }
    ],
    "clip_141": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"monkey\": {\n    \"attributes\": [\"brown\", \"chained\"],\n    \"actions\": [\"climbing tree\"]\n  },\n  \"snake\": {\n    \"attributes\": [\"black\", \"coiled\"],\n    \"actions\": [\"hissing at monkey\"]\n  }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**A monkey climbs up the tree to harass me.** _I just want to be left alone to rest._ **He keeps hitting at me and trying to get me to fall.** ---End---"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n   {\n     \"timestamp\": \"00:01\",\n     \"movement\": \"Snake's head moved to the right side\",\n     \"head contact\": \"no touching\"\n   },\n   {\n     \"timestamp\": \"00:03\",\n     \"movement\": \"Snake's head moved to the left side\",\n     \"head contact\": \"no touching\"\n   },\n   {\n     \"timestamp\": \"00:04\",\n     \"movement\": \"Snake's head moved to the right side\",\n     \"head contact\": \"no touching\"\n   }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "- The monkey reaches towards the snake.\n- The monkey maintains close proximity to the snake.\nThe snake is aggressive; **one snake lunges toward the monkey** as a defensive or aggressive action.\nRestricted movement"
        }
    ],
    "clip_142": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[{\"timestamp\": 0, \"entity\": \"giraffe\", \"action\": \"walk|enter\", \"target\": \"house\", \"duration\": null}, {\"timestamp\": 1, \"entity\": \"girl\", \"action\": \"touch|pat\", \"target\": \"giraffe\", \"duration\": \"1s\"}, {\"timestamp\": 3, \"entity\": \"giraffe\", \"action\": \"eat\", \"target\": \"food on plate\", \"duration\": \"7s\"}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Excited because I'm petting a giraffe up close!\n- Amused as the giraffe eats from the table plates.\n- Surprised when the giraffe drools while eating."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  {\n    \"change\": \"smiling to serious\",\n    \"reason\": \"giraffe putting his head on the table to eat the remaining food\"\n  },\n  {\n    \"change\": \"serious to staring at giraffe\",\n    \"reason\": \"looking up at the giraffe taking food from the table and its saliva is dropping\"\n  },\n  {\n    \"change\": \"staring at giraffe to excited and smiling\",\n    \"reason\": \"expressing excitement and enjoyment of the experience\"\n  }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Video Narrative: A giraffe enters a room, a girl **pets** its neck, the giraffe eats from plates, the girl **laughs** as the giraffe drools. Emotion: amusement."
        }
    ],
    "clip_143": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"chicken\": {\n        \"color\": \"brown\",\n        \"actions\": [\"eating\", \"carrying\"]\n    },\n    \"puppy\": {\n        \"color\": \"brown\",\n        \"actions\": [\"snuggling\", \"climbing\", \"riding\"]\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Today, I wandered into a field with green veggies and dry dirt that smelled earthy. I saw a chicken pecking the ground. I crept closer, nuzzled its soft, warm feathers, then climbed onto its back. The chicken just stood, calm. I felt safe and curious!"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n    {\n      \"primary_tag\": \"Puppy hugs chicken\",\n      \"secondary_tags\": [\"playful\", \"outdoor\", \"affectionate\"],\n      \"key_moment\": \"piggyback\"\n    },\n    {\n      \"primary_tag\":\"Puppy rides chicken\",\n      \"secondary_tags\": [\"amusing\", \"farm\", \"riding\"],\n      \"key_moment\": \"piggyback\"\n    }\n  ]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The chicken pecks at the ground while the puppy watches. Then the puppy hugs the chicken and later rides on its back."
        }
    ],
    "clip_144": [
        {
            "field": "For Instructional",
            "prompt_id": "01",
            "response": "Styling Steps:\nA. Start by putting the medium-length hair in a half ponytail with a **hair tie**.\nB. Secure the hair again with another **hair tie** a few inches below.\nC. Secure the hair one last time with another **hair tie** at the same distance below the previous one.\nD. Next, take the end of the hair and tuck it into the first **hair tie** to start rolling the hair up.\nE. Then, tuck the entire length of the medium-length hair up into the initial **hair tie**.\nF. Tuck in any flyaways from the medium-length hair, to make sure everything is in place.\nFinal Look: Neat Updo."
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "{\n  \"0-2s\": [\n    {\"action\": \"pull hair into a half ponytail\", \"hand's attribute\": \"red nail polish\"},\n    {\"action\": \"tie a hair tie to the hair\", \"hand's attribute\": \"red nail polish\"}\n  ],\n  \"2-4s\": [\n    {\"action\": \"tie a hair tie to the hair\", \"hand's attribute\": \"red nail polish\"},\n    {\"action\": \"twist ponytail through the hair\", \"hand's attribute\": \"red nail polish\"},\n    {\"action\": \"twist ponytail through the hair\", \"hand's attribute\": \"red nail polish\"}\n  ],\n  \"4-6s\": [\n    {\"action\": \"form the hair into a bun\", \"hand's attribute\": \"red nail polish\"},\n    {\"action\": \"hold up bun\", \"hand's attribute\": \"red nail polish\"}\n  ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "03",
            "response": "[\n    {\n      \"step description\": \"Gather a section of hair from the top and secure it with a hair tie to form a ponytail.\",\n      \"braids\": 1,\n      \"Hair ties\": 1\n    },\n    {\n      \"step description\": \"Divide the ponytail into three equal sub - sections and secure each with a hair tie.\",\n      \"braids\": 3,\n      \"Hair ties\": 3\n    },\n    {\n      \"step description\": \"Take the right - most sub - section, twist it upwards, and tuck it under the main ponytail base.\",\n      \"braids\": 3,\n      \"Hair ties\": 3\n    },\n    {\n      \"step description\": \"Take the middle sub - section, twist it upwards, and tuck it under the main ponytail base next to the right - twisted section.\",\n      \"braids\": 3,\n      \"Hair ties\": 3\n    },\n    {\n      \"step description\": \"Take the left - most sub - section, twist it upwards, and tuck it under the main ponytail base next to the middle - twisted section to form a braided bun - like structure.\",\n      \"braids\": 1,\n      \"Hair ties\": 3\n    }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Begin: The hair is pulled back and secured with a hair tie. Smaller ponytails are created below the first one. Each strand is looped through itself. **The looped strands are twirled into an updo.**\nEnd: Updo."
        }
    ],
    "clip_145": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"device_attributes\": {\n        \"color\": \"red\",\n        \"light_color\": \"yellow\",\n        \"shape\": \"cylindrical with an arm-like extension\"\n    },\n    \"child_inference\": \"认为是防护罩的启动装置\"\n}\n---\nThe device is positioned atop the castle, emitting a yellow light beam. It sits high above the castle’s towers, with its glowing light illuminating the structure below."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n{\n \"setting\": \"A pink and yellow castle with conical roofs. Vines wrap around the walls. \",\n \"goal\": \"The child wants to use the lamp to activate the castle's force field.\"\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\n    \"name\": \"child\",\n    \"color\": \"red and white\",\n    \"location\": \"forest\"\n  },\n  {\n    \"name\": \"castle sign\",\n    \"color\": \"yellow\",\n    \"location\": \"castle entrance\"\n  },\n  {\n    \"name\": \"castle towers\",\n    \"color\": \"pink and white\",\n    \"location\": \"castle top\"\n  }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. In a sunlit forest, a child in red and white stands, gaze fixed ahead.\n2. The child looks up, astonished: \"Ah, that's the shield!\"\n3. The shield is a yellow sign with blue Japanese text, bordered in blue, reading \"Beast's Castle\".\n4. The castle has pink brick towers, white battlements, a green roof, and a glowing red top device. Vines climb its walls."
        }
    ],
    "clip_146": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the video details:\nA. 0-2s: The blue cat, lying on the ground, extends its tail, which slips out from under him.  He then extends his legs and they, too, slip.\nB. 2-4s: The blue cat again extends its tail, and again the tail slips out from under him. He then extends his legs and they, too, slip. He gets lifted by the legs, then he falls back down.\nC. 4-6s: The blue cat again extends its tail, and again the tail slips out from under him. He then extends his legs and they, too, slip.\n{\n  \"mouse_relation\": \"hugging\"\n}\nThe cartoon opens with a blue cat prone on the ground while two mice stand nearby. The cat's tail and legs slip repeatedly, causing him to flop around. Despite this, he appears unaffected, still lying in place at the end of the segment."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Scene Overview: In a cartoon scene, **Tom**, a blue cat, is lying on the ground with his eyes closed. Nearby, two mice are huddled together. The camera is stationary, focusing on the characters. The shot is a medium shot, capturing the full bodies of the characters. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here's the controlled video caption:\n\ntime,action_description\n00:01|cat's tail touches floor\n00:01|cat's hind leg touches floor\n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In this scene: Tom the cat lying on the floor stretches and kicks his legs up as the two mice look on while holding each other. The cat looks to be waking up from a nap and getting ready for a chase.\n --End--"
        }
    ],
    "clip_147": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"attributes\": [\n    \"Grey and white camouflage pattern\",\n    \"Roundel markings\",\n    \"Text: 人民空军\"\n  ],\n  \"key_actions\": [\n    \"Flying through mountainous terrain\",\n    \"Shooting at other aircraft\",\n    \"Firing missiles\"\n  ]\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "02",
            "response": "| Entity | Type | Status |\n|---|---|---|\n| Main Aircraft | Fighter Jet | Flying at low altitude through a valley, maneuvering, engaging an enemy, evading enemy fire. |\n| Enemy Aircraft | Fighter Jet |  Engaged in combat, explodes. |"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "03",
            "response": "{\n \"status_changes\": [\n  {\n   \"time\": \"00:07\",\n   \"speed\": \"768 km/h\",\n   \"altitude\": \"0.54 km\"\n  },\n  {\n   \"time\": \"00:03\",\n   \"speed\": \"789 km/h\",\n   \"altitude\": \"0.53 km\"\n  },\n  {\n   \"time\": \"00:00\",\n   \"speed\": \"341 km/h\",\n   \"altitude\": \"0.58 km\"\n  }\n ]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Flying between hills, the aircraft is suddenly attacked from above by enemy planes. The pilot quickly engages in a dogfight, maneuvering swiftly and skillfully to evade enemy fire and gain a tactical advantage. Using precision aiming, the pilot successfully shoots down an enemy plane in a blazing explosion, securing the skies."
        }
    ],
    "clip_148": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"yellow-costumed\": {\n        \"costume_color\": \"yellow\",\n        \"weapons\": [\"claws\"],\n        \"stance\": \"crouched with claws extended\"\n    },\n    \"red-costumed\": {\n        \"costume_color\": \"red\",\n        \"weapons\": [\"guns\", \"swords\"],\n        \"stance\": \"standing with weapons ready\"\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Urban Battle Setup: The scene features a city street with buildings, including the storefronts of **Eastside Pharmacy** and Liefeld's establishment. | A \"ONE WAY\" sign is visible, indicating traffic direction, and the area has a gritty, urban appearance with graffiti on walls. | The environment includes scattered debris and a yellow taxi parked on the street, contributing to the chaotic atmosphere. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here's the JSON array of objects describing two critical moments in the video:\n\n```json\n[\n  {\n    \"moment\": \"A red-costumed group appears on the street\",\n    \"timestamp_approx\": \"0-5s\",\n    \"key_visual\": \"Deadpool\"\n  },\n  {\n    \"moment\": \"A fight between characters begins on the street\",\n    \"timestamp_approx\": \"5-10s\",\n    \"key_visual\": \"Wolverine\"\n  }\n]\n```"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "04",
            "response": "Okay, here are the first 3 distinct combat actions performed by the yellow-costumed character:\n\nA. red-costumed male opponent: slashes with claw.\nB. red-costumed female opponent: claw to the head\nC. red-costumed male opponent: kicks opponent."
        }
    ],
    "clip_149": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Police officer 1\n    - Cloth color: Light blue\n    - Badge number: 126090\n - Police officer 2\n    - Cloth color: Light blue\n    - Badge number: 126006\n - Civilian\n   - Cloth color: Black "
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "# Scene 1 (Medium Shot) - This scene takes place in a police station office. There is a table and three people seated around it. Two of them are police officers wearing blue uniforms with badges, and the other one is a civilian in a black shirt. There's a notepad and pen on the table. A window and other office objects are visible in the background.\n## Interaction 1: civilian speaks .\n\"有什么事情我们能帮到你呢。\"\n\"我要说的事，你们千万别害怕。\"\n## Response: officer (126090) 's reply .\n\"我们是警察，我们不会怕。\"\n\"你请说。\"\n--End of Scene-- "
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"entities\": [\n        {\n            \"type\": \"officer\",\n            \"attributes\": \"short hair, blue uniform\"\n        },\n        {\n            \"type\": \"officer\",\n            \"attributes\": \"short hair, blue uniform\"\n        },\n        {\n            \"type\": \"civilian\",\n            \"attributes\": \"short hair, black shirt\"\n        }\n    ]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "一个穿着黑衬衫的男人坐在警察局里，他告诉两位警官千万不要害怕。\n其中一位警官安慰他说他们是警察，不会害怕。\n随后，这位男子低下头，警官让他说出来。"
        }
    ],
    "clip_150": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n    \"entities\": [\n        {\n            \"gun\": {\n                \"color\": \"black\",\n                \"quantity\": 1\n            }\n        },\n        {\n            \"meat\": {\n                \"color\": \"red\",\n                \"quantity\": \"multiple\"\n            }\n        },\n        {\n            \"target\": {\n                \"color\": \"white\",\n                \"quantity\": 1\n            }\n        }\n    ],\n    \"events\": [\n        {\n            \"action\": \"drawing the gun\",\n            \"agent\": \"main man\",\n            \"timestamp\": \"0-9s\"\n        },\n        {\n            \"action\": \"pointing the gun\",\n            \"agent\": \"main man\",\n            \"timestamp\": \"9-11s\"\n        }\n    ]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "02",
            "response": "Retrieval: {\"target_analysis\":{\"bullet_count\":1,\"accuracy\":\"high\"}}\n1. bald head; background right\n2. hanging lamp; background left"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "The main man, focused, raises his arm and fires a gun. His intent seems to be precision or practice, as he maintains steady aim.\nThe bald man covers his face, likely reacting to the gunfire. His posture suggests discomfort or aversion to the shooting, highlighting his unease."
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "1. fire the gun - arm fully extended forward, finger on trigger\n2. aim the gun - arm extended forward, gun pointed at target\n3. draw the gun - arm moving from behind to forward, gripping gun"
        }
    ],
    "clip_151": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"gym_interaction\": {\n        \"participants\": [\n            {\n                \"id\": \"P1\",\n                \"attire\": {\n                    \"boxing_gloves\": \"red\",\n                    \"tank_top\": \"red\",\n                    \"shorts\": \"red\",\n                    \"boxing_shoes\": \"black\"\n                },\n                \"emotion\": \"focused\",\n                \"timestamp\": \"0:00-6:00\"\n            },\n            {\n                \"id\": \"P2\",\n                \"attire\": {\n                    \"chest_guard\": \"black\",\n                    \"towel\": \"light_pink\",\n                    \"shorts\": \"red\",\n                    \"boxing_shoes\": \"black\"\n                },\n                \"emotion\": {\n                    \"state\": \"confused\",\n                    \"cause\": \"**unexpected person change behind towel**\",\n                    \"timestamp\": \"0:00-6:00\"\n                }\n            },\n            {\n                \"id\": \"P3\",\n                \"attire\": {\n                    \"boxing_gloves\": \"red\",\n                    \"t_shirt\": \"black\",\n                    \"pants\": \"black\",\n                    \"boxing_shoes\": \"yellow\"\n                },\n                \"emotion\": \"focused\",\n                \"timestamp\": \"0:00-6:00\"\n            }\n        ]\n    }\n}"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "[\n    {\n        \"start_time\": 0,\n        \"end_time\": 2,\n        \"dominant_person\": \"P2\",\n        \"key_actions\": [\"cover face with towel\", \"boxer steps back\"],\n        \"tactical_analysis\": \"P2's towel action disrupts P1's focus\"\n    },\n    {\n        \"start_time\": 2,\n        \"end_time\": 5,\n        \"dominant_person\": \"P3\",\n        \"key_actions\": [\"enter frame\", \"throw punches\"],\n        \"tactical_analysis\": \"P3 capitalizes on P2's obscured state\"\n    }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "From **Person A**'s view: I hold up a towel, hide, then another person steps in. The kid punches, confused. I remove the towel, ending the prank. --End of view--\n\nFrom **Person B**'s view: I see Person A hide with a towel. I step in, the kid punches me. Then Person A reveals themself, and the kid reacts. --End of view--"
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "```json\n{\n  \"scene_setup\": \"A boxing gym with a red mat and red padded walls. A young boy (Person A) in red boxing attire stands to the left facing another person (Person B) who is leaning against a padded wall. Person B has a towel over their head and a chest protector on.\",\n  \"participants\": [\n    {\n      \"person\": \"Person A\",\n      \"attire/status\": \"Young boy in red boxing attire with red gloves labeled 'TIGER'.\"\n    },\n    {\n      \"person\": \"Person B\",\n      \"attire/status\": \"Person with a towel over their head, wearing a black chest protector and red boxing shorts with white stripes.\"\n    }\n  ]\n}\n```\n"
        }
    ],
    "clip_152": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here is the JSON output based on the video:\n```json\n{\n  \"entities\": [\n    {\n      \"type\": \"animal\",\n      \"attributes\": [\n        \"brown\",\n        \"1\"\n      ]\n    },\n    {\n      \"type\": \"object\",\n      \"attributes\": [\n        \"black\",\n        \"1\"\n      ]\n    }\n  ],\n  \"actions\": [\n    {\n      \"entity\": \"animal\",\n      \"description\": \"animal sits in a pot of water\"\n    },\n    {\n      \"entity\": \"object\",\n      \"description\": \"\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Storyboard Start:\n## Scene 1  \n**Capybara** sits in a steaming pan, peppers in mouth, paws moving—relaxed mood as it enjoys a warm soak.  \n\n## Scene 2  \n**Capybara** lounges in bubbly water with veggies, gently moving paws—serene mood while unwinding in the steamy bath.  \n--End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\n    \"element_type\": \"entity\",\n    \"timestamp\": \"00:02\",\n    \"description\": \"Capybara\"\n  },\n  {\n    \"element_type\": \"entity\",\n    \"timestamp\": \"00:02\",\n    \"description\": \"Lemon slice\"\n  }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here is the video description:\n\nA **capybara** is seated in a large, round, black **basin**, positioned outdoors on a green lawn next to a brick pathway. Steam rises from the warm water, which also contains pieces of corn and red **chili** peppers floating amidst a frothy substance. The capybara holds a red chili pepper in its mouth, tilting its head slightly to the side as it chews or nibbles on it. The capybara’s forepaws are visible as it sits upright in the basin, appearing relaxed and content as it bathes. A black toolbox sits in the background, adding to the setting."
        }
    ],
    "clip_153": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "好的，这是根据您的要求生成的视频描述：\n\nA.\n1. 00:00 学生正在学习。\n2. 00:09 接收妈妈递来的食物。\n\n```json\n[\n  {\n    \"时间戳\": \"00:00\",\n    \"推断情绪\": \"认真\",\n    \"画面证据\": \"学生正在灯下看书做笔记\"\n  },\n  {\n    \"时间戳\": \"00:09\",\n    \"推断情绪\": \"接受\",\n    \"画面证据\": \"学生面对母亲，等待接收食物\"\n  }\n]\n```\n\n母亲总是在儿子最需要的时候出现，给他送来食物，并提醒他劳逸结合，体现了母亲对儿子的**关心**和爱护。"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Mama always knows when I need encouragement, offering care and support, reminding me to balance my studies with rest: \"You need to balance your studies with rest.\" It’s a late night. I've been studying hard for the Gao Kao, poring over my books for hours. Countless sleepless nights have been sacrificed in pursuit of success. I'm a typical senior high school student."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, I'm ready to create the controlled video caption. Here is the table:\n\n| Time | Action | Object |\n|---|---|---|\n| 0:00 | Reading | Book |\n| 0:05 | Writing | Pen |\n| 0:10 | Receiving | Bowl |\n\nWhen the student is reading, he is in a slouched position, but after the mother appears, he straightens up."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, I will provide captions as instructed.\n\n**Paragraph 1, student's perspective:**\n00:10\nI am a high school student. To prepare for college, I paid the price with many sleepless nights. Mother always sends me encouragement and care, right when I need it. I feel **blessed** to have her. She reminds me to pay attention to balancing studying and rest. \n\n**Paragraph 2, mother's perspective:**\n00:00\nAs a mother, I feel **worried** about my son's studies. I try to send him encouragement, care, and advice at the right time. I want my son to know that he's not alone in this. I just want him to maintain a healthy lifestyle."
        }
    ],
    "clip_154": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. [{\"text\":\"这题我会\",\"gesture\":\"举手\",\"inference\":\"交互\"},{\"text\":\"车云一体\",\"gesture\":\"抬手讲解\",\"inference\":\"车联网\"},{\"text\":\"等于端到端模型\",\"gesture\":\"手势辅助讲解\",\"inference\":\"人工智能\"},{\"text\":\"加世界模型等数据基础设施\",\"gesture\":\"手势强调\",\"inference\":\"大数据\"},{\"text\":\"形成双轮驱动新范式\",\"gesture\":\"手势总结\",\"inference\":\"技术创新\"}]\n\n| Subtitle_Index | Technical_Term |\n|----------------|----------------|\n| 1              | 交互           |\n| 2              | 车联网         |\n| 3              | 人工智能       |\n| 4              | 大数据         |\n| 5              | 技术创新       |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The sunset glows golden, *panning* across the sky as light filters through clouds, *tilting* over distant peaks to bathe the drive in warmth.  \n\nI gestured to show **excitement**—I knew the answer!—and **enthusiasm** to share knowledge, emphasizing my point with energy.  \n\nSubtitles guide: “这题我会” = I’m confident; “车云一体” = Tech connects; “等于端到端模型” = Systems sync; “加世界模型等数据基础设施” = Build foundations; “形成双轮驱动新范式” = Innovate forward."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"monkey driving\",\n  \"secondary_tags\": [\"animated\", \"tech discussion\", \"sunset backdrop\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Sure, here are the descriptions of the video:\n\nFeeling bright and confident while behind the wheel of this modern vehicle, I am ready to greet all onlookers! This equation is a piece of cake, and I am thrilled to show off my knowledge. Now, where to next on this beautiful day? So many sights to see and things to explore!\n\n**Monkey Driver**, wearing glasses and a gold headdress, waves excitedly from inside a car. The monkey's dress is bright orange with gold decorative shoulders. A pagoda and mountains are visible through the windshield, silhouetted by the rising sun. The interior of the vehicle is modern, with dual-screen displays embedded into the console."
        }
    ],
    "clip_155": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"filming_setup\": {\n        \"camera_type\": \"4K 60FPS\",\n        \"crew_actions\": [\"filming\", \"adjusting equipment\", \"observing\"]\n    },\n    \"statue_interaction\": {\n        \"text_evolution\": [\n            {\n                \"time\": \"early\",\n                \"content\": \"没有动态的日子都在当个打工人\"\n            },\n            {\n                \"time\": \"mid\",\n                \"content\": \"你们有想我吗\"\n            },\n            {\n                \"time\": \"late\",\n                \"content\": \"努力搬砖，早日致富\"\n            }\n        ],\n        \"viewer_engagement\": 0.00\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here's the text-to-video script based on the provided video and instructions:\n\n## Scene Setup\n\n- Blurred reddish-orange brick background\n- Terracotta warrior statues in the background\n- Camera crew filming\n\n## Statue Actions\n\n- Statue raises its hand *welcomingly*.\n- Statue maintains a *confident* and *calm* facial expression.\n\n## Viewer Interaction\n\n```json\n[\n  {\n    \"comment\": \"努力搬砖，早日致富\",\n    \"response\": \"没错，一起加油!\"\n  },\n  {\n    \"comment\": \"给大家带来一波福利\",\n    \"response\": \"福利已经安排上啦\"\n  },\n  {\n    \"comment\": \"想你了\",\n    \"response\": \"我也想你们\"\n  }\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n    \"primary_tag\": \"兵马俑直播带货\",\n    \"secondary_tags\": [\"幽默\", \"创意\", \"历史感\"],\n    \"peak_moments\": []\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The viewer's perspective shows a lot of comments supporting him while he encourages them to work hard, including some mentions of \"work hard, get rich.\" From a viewer's perspective, the comments support the persona with supportive text appearing as overlays on the visual.\n\nThe Terracotta Warrior sees the screen's comments filled with support and encouragement as they're told to \"work hard, get rich.\" The Terracotta Warrior hopes viewers have missed it and are ready for the day's stream.\n\nOverall, the Terracotta Warrior's perspective is more personal and interactive, whereas the viewer's perspective is observational and reacts to the comments."
        }
    ],
    "clip_156": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. 1. The floodwater surges through the area near \"The Grand Hotel\", carrying debris. 2. A group of people observe the flood from a higher vantage point, and then the camera shows the floodwater surrounding buildings and the rooftop with emergency lights.\n[{\"event_type\":\"flood\",\"duration\":\"0-5s\"},{\"event_type\":\"observation\",\"duration\":\"5-10s\"}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. A large body of water (tsunami/flood) engulfs a street and hotel.\n2. An explosion occurs on the rooftop of a building.\n\n```json\n{\n  \"event_name\": \"Rooftop Explosion\",\n  \"location\": \"Rooftop of a tall building\",\n  \"visual_elements\": [\n    \"flashing red lights on rooftop\",\n    \"fire and debris from explosion\"\n  ]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\"buildings\":[{\"name\":\"The Grand Hotel\",\"lights\":\"on\",\"subtags\":[\"multi - story\",\"has signage\",\"illuminated windows\"]}],\"cinematic_tag\":\"tracking\"}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Floodwaters rapidly surge through the urban area, carrying debris. 2. This leads to structural damage and power outages as buildings are engulfed and lights flicker. 3. People gather on higher ground, observing the disaster and likely seeking safety."
        }
    ],
    "clip_157": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"baby_actions\": [\"walk in the room\", \"chase for the adult\", \"walk into the room\"],\n  \"adult_actions\": [\"crawl on the ground\", \"crawl into the room\", \"wait for the baby\"]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Choose Path:\n* If the baby turns left at the yellow wall: *A soft rustling sound emanates from a pile of white plastic bags as the curious baby investigates the unexpected new path. The air is quiet otherwise.*\n* If the baby turns right at the yellow wall: *A distant, high-pitched vocalization, possibly a coo or cry, echoes from within the room, drawing the baby deeper into the new space towards a waiting figure.*\n\nWhich path does the baby take?"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "Baby: I see the adult crawling, so I walk fast to follow. My hands are up, and I feel excited to catch up. I move through the rooms, wanting to be near them.\n\nAdult: I crawl to lead, wanting the baby to follow. I keep moving so they learn to walk and explore. It’s fun to see them hurry after me, curious and eager."
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "| Step | Common Mistake | Precaution |\n|-------|-----------------|-------------|\n| 1 | veering off path | Guide with hand |\n| 2 | slow reaction | Encourage speed |"
        }
    ],
    "clip_158": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"environment\": {\n    \"sky_color\": \"purple and orange-red twilight\",\n    \"house_chimney_state\": \"smoking\"\n  },\n  \"mechanical_structure\": {\n    \"has_red_lights\": true,\n    \"light_intensity\": \"bright\",\n    \"leg_count\": 6\n  },\n  \"car_children\": [\n    {\n      \"clothing\": \"red, white, and blue striped t-shirt\",\n      \"expression\": \"terrified scream\"\n    },\n    {\n      \"clothing\": \"white shirt, suspenders, red bow tie\",\n      \"expression\": \"terrified scream\"\n    },\n    {\n      \"clothing\": \"white t-shirt, red cape\",\n      \"expression\": \"terrified scream\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Scene Notes: black and white|entangled;yes;*Oh no, what's happening?*|*This is so scary!* --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "| Entity | Color | Action |\n| --- | --- | --- |\n| mechanical structure | brown | move forward |\n| police car | black,white | be lifted |\n| children | multi | scream |"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A Mechanical Structure With Red Lights Lifts A Car, Terrifying Children Inside Who Shout *'Help!'* As The Structure Moves Toward A Creaky House."
        }
    ],
    "clip_159": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"interaction with puppet\": {\n    \"Man 1\": \"left\",\n    \"Man 2\": \"center\",\n    \"Small dinosaur puppet\": \"center\",\n    \"Large dinosaur puppet\": \"right\",\n    \"Trees\": \"background\"\n  },\n  \"tribal performance\": {\n    \"Man in tribal attire 1\": \"left\",\n    \"Man in tribal attire 2\": \"center\",\n    \"Man in tribal attire 3\": \"right\",\n    \"Large dinosaur puppet\": \"center-right\",\n    \"Audience\": \"background\",\n    \"Large egg prop\": \"background-right\",\n    \"Decorations\": \"top-left\",\n    \"Trees\": \"background\"\n  }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A. Puppet Interaction with Dinosaurs\nB. Tribal Dance with Dinosaur Character\n\n```json\n{\n  \"Puppet Interaction with Dinosaurs\": {\n    \"participants\": [\n      \"Two men\",\n      \"Large dinosaur puppet\",\n      \"Small dinosaur puppet\"\n    ],\n    \"central_action\": \"Two men are holding and manipulating dinosaur puppets, facing a larger static dinosaur prop.\"\n  },\n  \"Tribal Dance with Dinosaur Character\": {\n    \"participants\": [\n      \"People in tribal costumes (dancers)\",\n      \"Person in a dinosaur costume\",\n      \"Audience\"\n    ],\n    \"central_action\": \"People in tribal costumes are performing a dance, interacting with a person dressed as a dinosaur, in front of an audience.\"\n  }\n}\n```\n\nThe Tribal Dance with Dinosaur Character scene appears to be a more formal public performance compared to the Puppet Interaction with Dinosaurs. This is indicated by the presence of a gathered audience watching the performance and the performers wearing more elaborate, coordinated tribal costumes, suggesting a planned show rather than a more informal display or interaction."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. 00:09 - tribal performers run and duck\n2. 00:07 - tribal performer lunges with spear\n3. 00:05 - tribal performers face dinosaur\nFirst action (run/duck) | Third action (face dinosaur): movement vs. stillness, evasion vs. confrontation"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the yellow dinosaur's perspective: I approach the green toy, curious. Tribal performers charge with spears—my playful stance masks my urge to connect, not fight.  \n\nFrom the lead tribal performer's perspective: I lead the charge, spear ready. The dinosaur looms—my heart races with bravado, protecting the group, yet intrigued by this giant, colorful being."
        }
    ],
    "clip_160": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Element Name       | Color       | Material       |\n|---------------------|-------------|----------------|\n| Main House Structure| Dark gray   | Wood/siding    |\n| Front Walkway       | Light gray  | Concrete       |\n| Garage Door         | Black       | Metal          |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "{\"furniture\": [\"sofa\", \"coffee table\", \"dining table\"], \"material\": \"wood\"} --End Tour--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. exterior house|lawn|pebbles|sapling|house|path  \n2. house porch|bench|path  \n3. interior house|table|chair|television|cabinet|painting|potted plant|sofa|coffee table|throw pillow|lamp|chandelier|carpet|window  \n\nTotal number of objects described: 23"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The camera moves forward along the path to the modern house, enters through the glass door, and then moves through the open-concept living and dining areas, showcasing the high ceilings, large windows, and contemporary furniture."
        }
    ],
    "clip_161": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"美伢\": {\n        \"attributes\": [\"pink clothing\"],\n        \"interactions\": [\"小新|speak\", \"小葵|speak\"]\n    },\n    \"小新\": {\n        \"attributes\": [\"red clothing\", \"yellow shorts\", \"holding blue toy car\"],\n        \"interactions\": [\"美伢|speak\", \"小葵|give toy car\"]\n    },\n    \"小葵\": {\n        \"attributes\": [\"yellow clothing\"],\n        \"interactions\": [\"美伢|cry\", \"小新|receive toy car\"]\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "妈妈让我借玩具给小葵，我抱紧玩具。\n1. 若拒绝：*小葵哭得更凶，满脸委屈又着急*\n2. 若借出：*妈妈露出欣慰笑容，眼神柔和又开心*"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\":\"00:00\",\"person_id\":1,\"interaction_desc\":\"ask Shin-chan lend toy\"},{\"timestamp\":\"00:02\",\"person_id\":2,\"interaction_desc\":\"refuse to lend toy\"},{\"timestamp\":\"00:04\",\"person_id\":2,\"interaction_desc\":\"lend toy to Xiaokui\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. Mother: Ask Shin-chan to lend toy to sister. See him hesitate, remind he's elder brother. Feel **urgent** to teach sharing.  \nB. Shin-chan: Hold toy, don't want to share. Argue it's his. Under mom's pressure, hand toy over **reluctantly**."
        }
    ],
    "clip_162": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. A. 1. Color: Silver 2. Position: In the background, on sandy terrain 3. Surroundings: Near mountains and a wooden structure  \n2. [{\"interaction_type\": \"handover\", \"participants\": [\"human\", \"robot1\"]}, {\"interaction_type\": \"handover\", \"participants\": [\"robot1\", \"robot2\"]}]  \n3. The handover between robot1 and robot2 required the most coordination, as it involved precise robot movements to transfer the object smoothly, ensuring alignment and stability during the exchange."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n{\n  \"robot_reactions\": [\"*walk*\", \"*take hat from human and wear it*\"],\n  \"car_direction\": \"forward\"\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. [man|robot|hat]|receiver retained object;2. [robot|another robot|gun]|receiver retained object"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The man walks towards a robot. 2. He hands a hat to the robot. 3. He hands a gun to another robot, which then passes it to the first robot."
        }
    ],
    "clip_163": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. \n{\n  \"standing\": 3,\n  \"walking\": 5\n}\n\nB. \n{\n  \"standing\": 10,\n  \"walking\": 15,\n  \"running\": 3\n}\n\nThe performer's prayer hand gesture likely serves as a moment of focus or ritual before the flight action, suggesting an intention to blend spiritual or meditative elements with the physical act of soaring, creating a visually and thematically cohesive performance."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "On a sandy beach with gentle waves lapping the shore, a figure in black clothing and white shoes **levitates** with arms outstretched. The sky is overcast, and beachgoers in the distance watch. The figure **crosses their hands** in a meditative pose, rising higher. Then, they **lean forward**, mimicking a flight stance, and soar over the beach, leaving onlookers in awe. The scene blends the tranquil ocean with the surreal act of flight."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"Person performing levitation illusion on beach\",\n  \"secondary_tags\": [\"surreal\", \"crowd-amazed\", \"mystical\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "As I lift off the sand, a *weightless* sensation surges through me. The grains fall away, and the air embraces my body. I feel *empowered*, soaring above the beach, with the wind whispering against my skin and the crowd’s awe fueling my *thrill*.  \nFrom the crowd, I stare *wide - eyed* as the performer rises. My heart *races* with *wonder*—it’s like magic! I jump up, trying to touch them, shouting in *excitement*, amazed by this impossible, *breathtaking* sight."
        }
    ],
    "clip_164": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "| ID | shirt color | position on building |\n|----|-------------|----------------------|\n| 1  | white       | left section         |\n| 2  | white       | left - middle section|\n| 3  | dark        | middle - right section|\n| 4  | white       | right section        |\n\nThe building's glass panels form a uniform grid pattern, with each panel reflecting the surrounding cityscape. The grid creates a repetitive, structured appearance across the building's facade.\n\n**Climber 1** shows the most dynamic movement as they adjust their position frequently while climbing."
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "| Climber ID | Clothing (static) | Actions (dynamic) | Relative Position (left-to-right on building) |\n|------------|-------------------|-------------------|-----------------------------------------------|\n| 1          | White shirt, dark shorts | Climbing | Leftmost |\n| 2          | White shirt, dark pants | Climbing | Second from left |\n| 3          | Dark outfit with pink accents | Climbing | Third from left |\n| 4          | White shirt, dark shorts | Climbing | Rightmost |\n\nThe most common action among climbers is climbing, as all individuals are engaged in ascending the building's exterior. This shared action indicates coordinated movement or a group activity focused on upward progression."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\"primary\":\"climbing skyscraper\",\"secondary\":[\"skyscraper climbing\",\"glass\",\"sunny\"]}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "**Climber’s Perspective:**  \nI Grip The Window Frame Tightly, My Fingers Aching As I Ascend. The Ground Seems Miles Away, Tiny Buildings Blurring Below. Each Move Feels Precarious, But I Push On, Focused On The Next Hold, Heart Racing With The Height.  \n**Observer’s Perspective:**  \nFour Climbers Scale The Tower’s Glass Facade. They’re Spaced Along The Window Grid, Some Higher, Some Lower, Their Figures Small Against The Vast Cityscape. The Sun Glints Off The Glass As They Carefully Make Their Way Down, A Precarious Dance In The Sky."
        }
    ],
    "clip_165": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"performer\": {\n    \"appearance\": [\n      \"Black suit\",\n      \"Red umbrella\",\n      \"White shirt\"\n    ],\n    \"interactions\": [\n      {\n        \"target\": \"white hat\",\n        \"action\": \"received a donation\",\n        \"timestamp\": \"00:03\"\n      }\n    ]\n  },\n  \"donation\": true,\n  \"ending\": \"The performer stands up, picks up his hat, and walks away with his props.\"\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Scene 1: Performance\n- Shot Scale: Long shot\n- Props:\n  - Umbrella with Red color\n  - A4 file folder with Black and white colors\n  - Metallic rectangular box\n- Description: The person is holding an umbrella. The person is seated on a metallic box. People on the street are walking around the person while the person is balancing on the metallic box. The person is smiling and talking to one of the people on the street.\n\n## Scene 2: Conclusion\n- Shot Scale: Long shot\n- Props:\n  - Hat with White color\n  - Umbrella with Red color\n  - Metallic rectangular box\n- Description: The person stands on the ground next to the metallic box. The person takes the hat off the ground. The person picks up the metallic box while holding the umbrella and the hat. The person walks away."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"participants\": [\n    {\n      \"name\": \"performer\",\n      \"appearance\": [\n        \"wearing a black suit\",\n        \"wearing a white shirt\",\n        \"wearing a red tie\",\n        \"holding a red umbrella\",\n        \"holding a white rectangular object (part of the illusion)\",\n        \"wearing black shoes\"\n      ]\n    },\n    {\n      \"name\": \"donor\",\n      \"appearance\": [\n        \"wearing a white top\",\n        \"wearing light blue shorts\",\n        \"wearing white shoes\"\n      ]\n    }\n  ],\n  \"events\": [\n    {\n      \"actor\": \"performer\",\n      \"action\": \"is levitating in the street, holding a red umbrella and a white rectangular object, with a white hat on the ground\",\n      \"timestamp\": \"00:00\"\n    },\n    {\n      \"actor\": \"donor\",\n      \"action\": \"approaches the levitating performer\",\n      \"timestamp\": \"00:04\"\n    },\n    {\n      \"actor\": \"donor\",\n      \"action\": \"places money into the white hat on the ground\",\n      \"timestamp\": \"00:05\"\n    },\n    {\n      \"actor\": \"performer\",\n      \"action\": \"acknowledges the donor and seemingly breaks the levitation illusion, revealing a support\",\n      \"timestamp\": \"00:06\"\n    },\n    {\n      \"actor\": \"performer\",\n      \"action\": \"steps down from the support\",\n      \"timestamp\": \"00:07\"\n    },\n    {\n      \"actor\": \"performer\",\n      \"action\": \"picks up the white hat\",\n      \"timestamp\": \"00:08\"\n    },\n    {\n      \"actor\": \"performer\",\n      \"action\": \"smiles and bows slightly to the donor\",\n      \"timestamp\": \"00:09\"\n    },\n    {\n      \"actor\": \"performer\",\n      \"action\": \"puts on the hat and walks away\",\n      \"timestamp\": \"00:10\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Performer: I hold the umbrella, *rustling* in the wind, lean back, feel the balance, hear footsteps. A patron drops a tip; I grin, close the umbrella, grab the hat and box, walk off.\n\nCafe patron: I watch the performer lean with the umbrella *rustling*, stay balanced. A woman drops a tip; he collects it, packs up, leaves. Impressive act."
        }
    ],
    "clip_166": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"entities\": [\n    {\n      \"id\": \"118\",\n      \"type\": \"person\",\n      \"static_attributes\": {},\n      \"dynamic_attributes\": [\n        {\n          \"frame\": 0,\n          \"posture\": \"lying\",\n          \"action\": \"sleeping\"\n        },\n        {\n          \"frame\": 4,\n          \"posture\": \"lying\",\n          \"action\": \"sleeping\"\n        }\n      ]\n    },\n    {\n      \"id\": \"119\",\n      \"type\": \"person\",\n      \"static_attributes\": {},\n      \"dynamic_attributes\": [\n        {\n          \"frame\": 0,\n          \"posture\": \"sitting\",\n          \"action\": \"playing\"\n        },\n        {\n          \"frame\": 3,\n          \"posture\": \"standing\",\n          \"action\": \"walking\"\n        },\n        {\n          \"frame\": 6,\n          \"posture\": \"standing\",\n          \"action\": \"walking\"\n        },\n        {\n          \"frame\": 8,\n          \"posture\": \"standing\",\n          \"action\": \"walking\"\n        }\n      ]\n    },\n    {\n      \"id\": \"120\",\n      \"type\": \"couch\",\n      \"static_attributes\": {\n        \"color\": \"white\",\n        \"material\": \"fabric\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"121\",\n      \"type\": \"play mat\",\n      \"static_attributes\": {\n        \"shape\": \"circle\",\n        \"material\": \"fabric\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"122\",\n      \"type\": \"toy\",\n      \"static_attributes\": {\n        \"color\": \"yellow\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"123\",\n      \"type\": \"stool\",\n      \"static_attributes\": {\n        \"color\": \"beige\"\n      },\n      \"dynamic_attributes\": []\n    }\n  ],\n  \"events\": [\n    {\n      \"participant_id\": \"119\",\n      \"action\": \"poking\",\n      \"result\": \"trying to wake up the person\"\n    },\n    {\n      \"participant_id\": \"119\",\n      \"action\": \"climbing\",\n      \"result\": \"reaching the couch\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "From the woman's perspective: I lie on the couch, hear the baby's steps, feel tiny hands tugging me, then the baby brings a stool. From the baby's perspective: - curious about the woman’s movements on the couch - curious about the colorful toy on the mat - curious about the soft stool to climb."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here's the JSON output:\n```json\n{\n  \"key_moments\": [\n    {\n      \"time_range\": \"0-1s\",\n      \"visual_cues\": [\n        \"sofa\",\n        \"floor tile\"\n      ],\n      \"action_verb\": \"stands\"\n    },\n    {\n      \"time_range\": \"9-11s\",\n      \"visual_cues\": [\n        \"diaper\",\n        \"toy\"\n      ],\n      \"action_verb\": \"climbs\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! This is a baby. He is wearing a yellow diaper.\nHe wakes up his mom who is sleeping on the sofa.\nThey are happy together."
        }
    ],
    "clip_167": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here are the objects and JSON as per your instructions:\n\n1.  White tiger, white and black\n2.  Trees, green and brown\n3.  Cage, green\n\n```json\n[\n  {\"entity\": \"Orangutan\", \"interaction\": \"Driving the vehicle.\"},\n  {\"entity\": \"Tiger\", \"interaction\": \"Sitting in its enclosure as the vehicle passes by.\"},\n  {\"entity\": \"Steering wheel\", \"interaction\": \"Held by the orangutan who is driving.\"}\n]\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n{\n  \"global_parameters\": {\n    \"time_of_day\": \"day\",\n    \"weather\": \"sunny\",\n    \"camera_style\": \"fixed camera position\"\n  },\n  \"editable_assets\": [\n    {\n      \"asset_id\": \"orangutan\",\n      \"asset_type\": \"Animal\",\n      \"is_key_subject\": true,\n      \"editable_attributes\": {\n        \"species\": \"orangutan\",\n        \"color\": \"orange\"\n      },\n      \"dynamic_path\": \"The orangutan is driving a small vehicle on a road, passing by animal enclosures.\"\n    },\n    {\n      \"asset_id\": \"vehicle\",\n      \"asset_type\": \"Vehicle\",\n      \"is_key_subject\": false,\n      \"editable_attributes\": {\n        \"type\": \"small vehicle\",\n        \"color\": \"gray\"\n      },\n      \"dynamic_path\": \"The vehicle is moving on a road, driven by the orangutan.\"\n    },\n    {\n      \"asset_id\": \"tiger\",\n      \"asset_type\": \"Animal\",\n      \"is_key_subject\": false,\n      \"editable_attributes\": {\n        \"species\": \"tiger\",\n        \"color\": \"white with black stripes\"\n      },\n      \"dynamic_path\": \"The tiger is in an enclosure beside the road where the vehicle is moving.\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"Orangutan\",\n  \"secondary_tags\": [\n    \"orange\",\n    \"driving\"\n  ],\n  \"timeline\": {\n    \"driving\": \"0:00\"\n  }\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here are the descriptions:\nA.  The video shows an orangutan driving a vehicle past a white tiger enclosure. The orangutan is red-orange and drives past the green fencing of the enclosure, looking around --End of description--.\nB. The white tiger is seen lying down inside the green fenced enclosure. The orangutan continues to drive by, with its attention towards the vehicle's steering wheel --End of description--."
        }
    ],
    "clip_168": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"entities\": [\n    {\n      \"id\": \"1\",\n      \"type\": \"car\",\n      \"static_attributes\": {\n        \"color\": \"black\",\n        \"make\": \"unknown\"\n      },\n      \"dynamic_attributes\": [\n        {\n          \"emotion\": \"neutral\",\n          \"posture\": \"stationary\",\n          \"action\": \"driving\"\n        }\n      ]\n    },\n    {\n      \"id\": \"2\",\n      \"type\": \"parking garage\",\n      \"static_attributes\": {\n        \"lighting\": \"artificial\",\n        \"size\": \"large\"\n      },\n      \"dynamic_attributes\": [\n        {\n          \"condition\": \"open\",\n          \"activity\": \"parking\",\n          \"congestion\": \"moderate\"\n        }\n      ]\n    },\n    {\n      \"id\": \"3\",\n      \"type\": \"car\",\n      \"static_attributes\": {\n        \"color\": \"white\",\n        \"make\": \"SUV\"\n      },\n      \"dynamic_attributes\": [\n        {\n          \"motion\": \"approaching\",\n          \"visibility\": \"partially obscured\",\n          \"distance\": \"moderate\"\n        }\n      ]\n    }\n  ],\n  \"events\": [\n    {\n      \"participant_id\": \"1\",\n      \"action\": \"driving\",\n      \"result\": \"navigating parking garage\"\n    },\n    {\n      \"participant_id\": \"1\",\n      \"action\": \"detecting\",\n      \"result\": \"identifies oncoming vehicle\"\n    },\n    {\n      \"participant_id\": \"1\",\n      \"action\": \"yielding\",\n      \"result\": \"allows oncoming vehicle to pass\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**Car's AI (First - person):** I use lidar data to map the parking lot, detect obstacles, then plan a path. I **navigate** through the lot, adjust for oncoming cars by **reverse**ing smoothly, ensuring safe positioning.  \n\n**Parking Lot Attendant (Third - person):** Watches the car glide through the lot, then is *impressed by the precise reverse* when yielding to oncoming traffic, marveling at the autonomous system’s smoothness."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"autonomous driving\",\n  \"secondary_tags\": [\"underground parking lot\", \"self - driving technology\", \"searching for parking space\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "好的，没问题。这是你的视频描述：\na. 看！这里有一辆黑色的车。\nb. 正在停车场里自己找停车的位置。\nc. 这是一个很安静的停车场。"
        }
    ],
    "clip_169": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. The smart car drives forward on the road.\n{\n  \"car\": \"white\",\n  \"road\": \"light blue\",\n  \"buildings\": \"white\",\n  \"street lamps\": \"gray\"\n}\nB. The smart car encounters and avoids obstacles (other vehicles and pedestrians).\n{\n  \"car\": \"white\",\n  \"obstacle vehicles\": \"orange\",\n  \"pedestrians\": \"green, orange\"\n}\nC. The smart car continues driving forward after avoiding obstacles.\n{\n  \"car\": \"white\",\n  \"road\": \"light blue\",\n  \"buildings\": \"white\",\n  \"street lamps\": \"gray\"\n}\n\nThe event of the smart car encountering and avoiding obstacles involved the most objects."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n{\n  \"global_parameters\": {\n    \"time_of_day\": \"day\",\n    \"weather\": \"sunny\",\n    \"camera_style\": \"fixed camera position\"\n  },\n  \"editable_assets\": [\n    {\n      \"asset_id\": \"white_car\",\n      \"asset_type\": \"Cars\",\n      \"is_key_subject\": true,\n      \"editable_attributes\": {\n        \"color\": \"white\",\n        \"material\": \"metal\"\n      },\n      \"dynamic_path\": \"Drives straight down the road, avoiding obstacles.\"\n    },\n    {\n      \"asset_id\": \"pedestrian\",\n      \"asset_type\": \"People\",\n      \"is_key_subject\": false,\n      \"editable_attributes\": {\n        \"color\": \"pink\",\n        \"clothing\": \"casual\"\n      },\n      \"dynamic_path\": \"Stands on the sidewalk and begins to cross the road.\"\n    },\n    {\n      \"asset_id\": \"orange_bus\",\n      \"asset_type\": \"Cars\",\n      \"is_key_subject\": false,\n      \"editable_attributes\": {\n        \"color\": \"orange\",\n        \"type\": \"bus\"\n      },\n      \"dynamic_path\": \"Drives down the road, turns right.\"\n    },\n    {\n      \"asset_id\": \"orange_car\",\n      \"asset_type\": \"Cars\",\n      \"is_key_subject\": false,\n      \"editable_attributes\": {\n        \"color\": \"orange\",\n        \"type\": \"SUV\"\n      },\n      \"dynamic_path\": \"Parked on side of road.\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\": \"00:00\", \"event_type\": \"obstacle_avoidance\", \"object\": \"car\"}, {\"timestamp\": \"00:02\", \"event_type\": \"obstacle_avoidance\", \"object\": \"car\"}, {\"timestamp\": \"00:04\", \"event_type\": \"obstacle_avoidance\", \"object\": \"car\"}]"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "look! 这是一辆白色的汽车在街上开.\n在城市街道上行驶，避开了许多障碍物.\nIt's so quiet here."
        }
    ],
    "clip_170": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"entities\": [\n    {\n      \"id\": \"entity_0\",\n      \"type\": \"car\",\n      \"static_attributes\": {\n        \"color\": \"silver\",\n        \"material\": \"metal\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"entity_1\",\n      \"type\": \"car\",\n      \"static_attributes\": {\n        \"color\": \"black\",\n        \"material\": \"metal\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"entity_2\",\n      \"type\": \"car\",\n      \"static_attributes\": {\n        \"color\": \"red\",\n        \"material\": \"metal\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"entity_3\",\n      \"type\": \"car\",\n      \"static_attributes\": {\n        \"color\": \"blue\",\n        \"material\": \"metal\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"entity_4\",\n      \"type\": \"car\",\n      \"static_attributes\": {\n        \"color\": \"white\",\n        \"material\": \"metal\"\n      },\n      \"dynamic_attributes\": []\n    },\n    {\n      \"id\": \"entity_5\",\n      \"type\": \"person\",\n      \"static_attributes\": {},\n      \"dynamic_attributes\": []\n    }\n  ],\n  \"events\": [\n    {\n      \"frame\": 0,\n      \"event_info\": \"Multiple cars are involved in a collision on a bridge.\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Driver Perspective\nA. Equip tires with snow chains for better grip. A. Reduce speed and increase following distance to react to icy patches.  \nMistake: Sudden braking. Avoid: Gradually slow down using engine braking or gentle pedal pressure.  \n## Rescuer Perspective\nA. Pre - treat icy roads with salt or de - icing agents before accidents. A. Use sand or gravel to increase friction on icy sections during rescue.  \nMistake: Driving too fast. Avoid: Drive at a low speed, keep a safe distance, and brake gently.  \n## Traffic Department Perspective\nA. Spread de - icing chemicals on roads before freezing conditions. A. Use snowplows to clear ice and snow promptly.  \nMistake: Ignoring icy road warnings. Avoid: Check weather/road reports, use winter tires, and drive cautiously."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here's the information extracted from the video and presented in the requested Markdown table format:\n\n```\n| Entity|Color|Key Action|\n|-------|-------|-----------|\n| man    |      | walking    |\n| car    |multi  | crashed   |\n| bridge | gray  | standing  |\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "There is no subtitle."
        }
    ],
    "clip_171": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. A. Wooden debris - \n- Floating in the water flow\nB. Structural fragments - \n- Broken parts of buildings\n\n2. {\n  \"main_disaster\": \"flood\",\n  \"sub_events\": [\n    {\n      \"event\": \"water surge hits buildings\",\n      \"timestamp\": 2\n    },\n    {\n      \"event\": \"debris collide with structures\",\n      \"timestamp\": 6\n    }\n  ]\n}\n\n3. The most destructive moment was 6 because debris causes severe structural damage."
        },
        {
            "field": "For Communication",
            "prompt_id": "02",
            "response": "Viewers likely gasp at the immense mudslide, stunned by its force, as text overlays emphasize the shocking scene. The chaos unfolds rapidly, gripping attention.  \n\nThe mudslide smashes into **red building**, damaging its lower levels, and engulfs nearby structures, tearing through roads and crushing everything in its path, leaving destruction."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\nprimary_tag: 海啸\nsecondary_tags: 灾难,破坏,湍急\n```\n0.5|白色\n1.0|白色"
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "A massive wave of debris and water crashes through the town. ==Rumbling and rushing water== fill the air as buildings stand amidst the chaos.  \n\nThe red building is battered by the surging current, with debris slamming into its walls. Structures around it crumble, overwhelmed by the force.  \n\nText overlays like “这海啸太吓人” (This tsunami is terrifying) and “看呆了” (Stunned) show shock and awe, capturing the overwhelming fear of witnessing such destruction."
        }
    ],
    "clip_172": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"combat_sequence\": [\n        {\n            \"timestamp\": \"0:00\",\n            \"action\": \"wrestle\",\n            \"effect\": \"sparks\"\n        },\n        {\n            \"timestamp\": \"0:02\",\n            \"action\": \"grapple\",\n            \"effect\": \"explosions\"\n        },\n        {\n            \"timestamp\": \"0:04\",\n            \"action\": \"melee_attack\",\n            \"effect\": \"sparks\"\n        }\n    ],\n    \"cinematic_notes\": [\"medium shot of robot battle\", \"dynamic camera following combat movements\"]\n}"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "Okay, here are the video descriptions:\n\n0:00\nThe yellow robot swings its arm, aiming to hit the silver robot (\"intention\"). The action results in a forceful impact, creating sparks and visible damage on the silver robot (\"outcome\"). The yellow robot continues to exert pressure on the silver robot, pushing it backward with the force of the blow.\n\n0:04\nThe yellow robot throws a tire-shaped object, intending to strike the silver robot (\"intention\"). The object hits the silver robot, causing a visible disruption and sparks (\"outcome\"). The attack effectively destabilizes the silver robot, impacting its balance and defensive position.\n\n0:06\nThe yellow robot executes a powerful strike, aiming to further damage the silver robot (\"intention\"). The punch connects with great force, resulting in sparks and causing visible explosion damage on the silver robot (\"outcome\"). The strike seems to have a significant impact on the silver robot, potentially impairing its combat effectiveness. \"critical_success\": true."
        },
        {
            "field": "For Generation",
            "prompt_id": "03",
            "response": "Okay, here is the video description based on your instructions.\n\n|Entity|Color|Key Actions|\n|---|---|---|\n|Robot|Yellow|Fighting|\n|Robot|Gray|Fighting|\n|Buildings|White|Tall|"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "04",
            "response": "Here's the JSON output:\n```json\n[\n  {\n    \"timestamp\": \"0:00\",\n    \"event\": \"Clash and explosion\",\n    \"robot_involved\": \"yellow\"\n  },\n  {\n    \"timestamp\": \"0:03\",\n    \"event\": \"Close combat exchange\",\n    \"robot_involved\": \"silver\"\n  },\n  {\n    \"timestamp\": \"0:06\",\n    \"event\": \"Explosive Impact\",\n    \"robot_involved\": \"yellow\"\n  }\n]\n```"
        }
    ],
    "clip_173": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Analysis Results: 1. Computer monitor, black; 2. Mannequin, black. Vehicles: [\"taxi\", \"car\"] ---End---"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "没问题，请看文本：\n\n我走在街上，看到一个穿着蓝色衬衫的男人和一个黑人，我们一起过马路。路上停着一辆黄色的出租车，冒着烟。纽约真的太酷了！"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the video annotations:\n```csv\nEntity|Color|Key Actions\nWoman|blue|walking\nTaxi|yellow|driving\nModel|green|Adjusted\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. I’m outside, holding rolled paper. Around me, people cross the street. Yellow taxis and other cars move by. Buildings with shops line the road, and there’s steam rising from a vent. The sun is bright, casting shadows.\n\nB. I’m at my desk in a busy office. Large windows let in light. Colleagues move around—some walk, others work at their desks with computers. The space feels open, with desks and chairs, and people chat or focus on tasks."
        }
    ],
    "clip_174": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Video Entities: {\n  \"woman\": {\n    \"attributes\": [\"long hair\", \"plaid shirt\", \"jeans\"],\n    \"action\": \"walk\"\n  },\n  \"man\": {\n    \"attributes\": [\"short hair\", \"gray suit\", \"sunglasses\"],\n    \"action\": \"walk and call\"\n  }\n}\n---"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n{\n  \"global_parameters\": {\n    \"time_of_day\": \"day\",\n    \"weather\": \"sunny\",\n    \"camera_style\": \"fixed camera position\"\n  },\n  \"editable_assets\": [\n    {\n      \"asset_id\": \"woman_walking\",\n      \"asset_type\": \"People\",\n      \"is_key_subject\": true,\n      \"editable_attributes\": {\n        \"clothing\": \"plaid shirt and jeans\"\n      },\n      \"dynamic_path\": \"Walks along the sidewalk from the left to the right.\"\n    },\n    {\n      \"asset_id\": \"man_walking\",\n      \"asset_type\": \"People\",\n      \"is_key_subject\": false,\n      \"editable_attributes\": {\n        \"clothing\": \"suit\"\n      },\n      \"dynamic_path\": \"Walks into frame from the left and exits on the right.\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"interval\": \"0-5s\", \"entities\": [], \"action\": \"A woman with long hair, wearing a checkered shirt and jeans, walks forward on the sidewalk while holding a silver briefcase. Then a man in a gray suit passes by her from the opposite direction.\"}, {\"interval\": \"5-10s\", \"entities\": [], \"action\": \"The man in the gray suit continues walking forward on the sidewalk, with vehicles passing by on the road beside him. He then takes out a mobile phone from his pocket.\"}, {\"interval\": \"10-13s\", \"entities\": [], \"action\": \"The man in the gray suit answers the call and continues walking forward, with cars parked on the side of the road.\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The woman and man walk at a similar pace. There are silver and white parked cars. The background buildings are tall with many windows."
        }
    ],
    "clip_175": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. Camera zooms in on the hotel building during heavy rain.\n{\n  \"scene_detail\": \"Heavy rain falls as the camera zooms in on a multi - story hotel building with a 'HOTEL' sign. Windows and a balcony are visible.\",\n  \"objects\": [\"hotel building\", \"rain\", \"balcony\"]\n}\n\nB. Camera moves through the hotel to a dining room where people are eating.\n{\n  \"scene_detail\": \"The camera moves inside the hotel, passing through areas until it reaches a dining room where people in formal attire are seated at tables eating, with rain still visible.\",\n  \"objects\": [\"dining room\", \"people\", \"tables\"]\n}\n\nFood items on the table include plates with what appear to be meatballs, a plate with a steak and fries, and a bowl of fruit. Multiple hands with forks are seen serving and eating the food."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A plate has a steak with crisp golden fries. Another plate holds dark, round meatballs.  \n- Sound of heavy rain hitting the building  \n- Patterned wallpaper with a vintage design"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\":\"0:00-0:05\",\"person\":\"waiter\",\"action\":\"serve food\"},{\"timestamp\":\"0:05-0:10\",\"person\":\"diner\",\"action\":\"take food\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the central figure's view: I serve food to diners, ensuring they’re attended to. Despite the rain, the dining room is busy; I feel focused on hospitality.  \nFrom a diner's view: Rain pours outside, but inside, the meal proceeds. I take food, enjoying the service, feeling a mix of comfort and anticipation for the meal."
        }
    ],
    "clip_176": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n        \"dolphin\": {\n        \"attire\": [\"cap\"],\n        \"actions\": [\n            {\n                \"target\": \"bottle\",\n                \"action\": \"drink from\",\n                \"duration\": \"brief\"\n            },\n            {\n                \"target\": \"bottle\",\n                \"action\": \"throw\",\n                \"duration\": \"brief\"\n            }\n        ]\n    },\n    \"bottle\": {\n        \"label\": \"Type 2\",\n        \"movement_events\": [\"bridge\", \"water\", \"tunnel\"]\n    }\n}\nThe animal phantom closest to the camera at the beginning is a panda - like figure with black - and - white coloring, and no obvious additional decorations are visible on it.}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I am a bottle tossed by a dolphin, floating under a bridge with metal beams and concrete pillars, then swept into a tunnel. Inside: - *crumpled* bag, - *rusted* cart, - *tattered* cloth."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n    {\"timestamp\": \"0.0\", \"location\": \"wall\", \"nearby_objects\": [\"trash can\"]},\n    {\"timestamp\": \"1.0\", \"location\": \"wall\", \"nearby_objects\": [\"trash can\"]},\n    {\"timestamp\": \"2.0\", \"location\": \"bridge\", \"nearby_objects\": []},\n    {\"timestamp\": \"5.0\", \"location\": \"tunnel\", \"nearby_objects\": []}\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Video Description: 1. A dolphin drinks from a bottle. 2. The dolphin throws the bottle away. 3. The bottle floats into a sewer. The dolphin shows indifference by casually discarding the bottle."
        }
    ],
    "clip_177": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Gold, Red, Black\n2. For Gold: [\"grabbing shield\", \"holding shield\"]; For Red: [\"placing arm on shoulder\", \"hitting with shield\"]; For Black: [\"striking with shield\", \"pulling shield\"]\n| Character (Suit Color) | Static Attribute (Clothing) | Dynamic Attribute (Action) |\n|------------------------|-----------------------------|----------------------------|\n| Gold                   | Full - body suit with dark collar | grabbing shield, holding shield |\n| Red                    | Suit with straps and mask | placing arm on shoulder, hitting with shield |\n| Black                  | Armored suit with mask | striking with shield, pulling shield |"
        },
        {
            "field": "For Communication",
            "prompt_id": "02",
            "response": "In the modern interior setting: the man in the red suit puts his arm around the man in the yellow suit. the man in the black suit attacks the man in the yellow suit with a shield."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"shield combat struggle\",\n  \"secondary_tags\": [\"shield block\", \"close grapple\", \"shield manipulation\"]\n}\n```"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "04",
            "response": "| Action | Actor (suit color) | Target (suit color) | Duration (s) |\n|--------|--------------------|---------------------|--------------|\n| Punch  | Red                | Yellow              | 0.8          |\n| Shield strike | Black | Yellow | 1.2 |"
        }
    ],
    "clip_178": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Character | Attributes | Actions |\n| --- | --- | --- |\n| Person 1 | Wearing black t-shirt and pants | Speaks, shifts posture |\n| Person 2 | Wearing checkered outfit, black helmet, holding two popcorn buckets | Speaks, eats popcorn |\n\n[\"Person 1|Excuse me?\", \"Person 1|Can I get one movie ticket please?\", \"Person 1|Yeah of course!\", \"Person 1|What movie?\", \"Person 2|UM.\", \"Person 2|(eats popcorn)\"]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A person in a black shirt and black pants stands near open doors and speaks. The text \"Excuse me?\" \"Can I get one movie ticket please?\" \"Yeah of course!\" \"What movie?\" appears on the screen. Then another person wearing a black helmet and a black and white checkered outfit holds two popcorn buckets, speaks, and eats popcorn. The text \"UM.\" appears on the screen."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A. Theater Entrance  \nB. Theater Lobby  \n\n\n### Theater Entrance  \n| Object | Color |  \n|--------|-------|  \n| Door | Brown |  \n| T - shirt | Black |  \n\n\n### Theater Lobby  \n| Object | Color |  \n|--------|-------|  \n| Helmet | Black |  \n| Popcorn Bucket | Brown |  \n| Jacket | Black and White Checkered |  \n\n\n{  \n  \"most_objects\": \"Theater Lobby\",  \n  \"reason\": \"Theater Lobby has more distinct objects including helmet, popcorn bucket, and checkered jacket compared to Theater Entrance.\"  \n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the person in the black shirt: I stand by the doors, hands clasped, and say, “Excuse me? Can I get one movie ticket please?” Then I respond, “Yeah of course! What movie?” I feel polite, trying to help.\n\nFrom the person in the checkered jacket: I hold two popcorn buckets, wear a helmet, and say, “Um.” Then I eat popcorn. I feel confused, hesitating before replying."
        }
    ],
    "clip_179": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Person 1’s outfit mirrors the vibrant tulip rows, creating a striking **camouflage** where their form blends into the floral layers, making them nearly merge with the colorful field.\n\n{\n  \"object_held\": \"A white board with text and a thin stick\",\n  \"behavior\": [\n    {\"action\": \"extend arm with stick toward Person 1\", \"timestamp\": \"2.5\"},\n    {\"action\": \"lean forward near Person 1\", \"timestamp\": \"3.0\"}\n  ]\n}\n\n- Tulip Flowers\n- Windmill Structure\n- Distant Trees"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Idea: Camouflage Art in Tulip Rows|Person 1 raises the *mirror* to align with the tulip field background.|Person 1 adjusts the *mirror* to fully reflect the tulip rows behind.|Person 1 lowers the *mirror* and crouches to blend into the flowers."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n- Camouflage in Tulip Field\n  - object: 'reflective disc'\n    - sub: 'mirror-like surface'\n  - object: 'tulip flowers'\n    - sub: 'colorful blooms'\n  - action: 'camouflaging'\n    - sub: 'blending with background'\n  - action: 'painting'\n    - sub: 'applying colors'\n  - setting: 'windmill'\n    - sub: 'background structure'\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "**Person 1** stands in a tulip field, holding a reflective object. They adjust it to match the flower patterns, then lower it, blending into the background. Intention: *to camouflage within the tulip field*.  \n\n**Person 2** is near the field, holding tools and a board. They observe or assist as Person 1 camouflages, focusing on the process. Intention: *to observe or support Person 1’s camouflage attempt*."
        }
    ],
    "clip_180": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```\n{\n  \"primary_entity\": {\n    \"suit_color\": \"White\",\n    \"action_sequence\": [\n      {\"00:05\": \"Pointing at control panel\"},\n      {\"00:06\": \"Adjusting control panel element\"}\n    ]\n  },\n  \"secondary_entities\": [\n    {\"light_color\": \"Green\", \"state_change\": \"On\"},\n    {\"light_color\": \"Red\", \"state_change\": \"On\"},\n    {\"light_color\": \"Green\", \"state_change\": \"On\"},\n    {\"light_color\": \"Red\", \"state_change\": \"On\"},\n    {\"light_color\": \"Green\", \"state_change\": \"On\"}\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Cinematic Element | Detail |\n|-------------------|--------|\n| Camera Movement Direction | pan |\n| Shot Scale | medium shot |\n---\n\"Looking out at the moon and stars, I feel *awe* at the vastness… and *calm* knowing I’m part of this cosmic dance.\"\n---\n[\n  {\n    \"prop\": \"window frame\",\n    \"material\": \"metal\",\n    \"color\": \"orange-brown\"\n  },\n  {\n    \"prop\": \"control panel\",\n    \"material\": \"metal and plastic\",\n    \"color\": \"gray\"\n  },\n  {\n    \"prop\": \"stars\",\n    \"material\": \"light (visual effect)\",\n    \"color\": \"white\",\n    \"twinkling\": true\n  },\n  {\n    \"prop\": \"spacesuit\",\n    \"material\": \"fabric and protective layers\",\n    \"color\": \"white\"\n  }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n  \"primary_tag\": \"astronaut in spacecraft\",\n  \"secondary_tags\": [\"moon view\", \"spacecraft interior\", \"astronaut operates panel\"]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The moon appears as a gray, spherical shape with a dark, curved shadow on its right side, indicating it is waning (likely a waning gibbous or crescent, but the shadow’s position suggests waning). Tiny white stars dot the deep blue-black sky around it. Inside the craft, a person in a white spacesuit (with black straps) interacts with a control panel. The panel is gray with various buttons, some glowing green and red. The space is dim, with metallic, industrial textures visible, and the quiet hum of machinery is inferred from the technical setup."
        }
    ],
    "clip_181": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Video Entities Analysis:\n1. Person: wears orange outfit with white gloves.\n2. Bird: has large orange beak and black head.\n3. Snakes: green with red patterns, two heads.\n{\"Person\":\"whip snakes then pat bird\",\"Bird\":\"stay on branch\",\"Snakes\":\"move as wheels to drive\"}\n---End Analysis---"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here are the video descriptions as requested:\n\n1. The trees in the background change to be more detailed, and the hills flatten out.\n2. The trees in the background disappear."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"snake\",\n  \"secondary_tags\": {\n    \"color\": \"green\",\n    \"movement_type\": \"slithering\"\n  },\n  \"timeline\": \"0:00\"\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I wave a whip, sit on a log vehicle, smile with an upturned mouth. The snakes move like tracks, and I pat the bird beside me happily.\n\nI perch steadily on a branch, watch the log vehicle move forward. The snakes act as tracks, moving calmly. The person on the vehicle is happy, and I stay calm."
        }
    ],
    "clip_182": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"result\": \"no explosion\", \"camera_movement\": [\"tracking_shot\"]}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The video shows a silver bullet engraved with ornate patterns speeding through the air."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A. 6 seconds: Bullet\nB. 10 seconds: Train\nC. 13 seconds: Rifle"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A bullet travels through the air, passing buildings and a train, then hits a window, causing an explosion. A man fires a rifle, then lowers the gun slightly while maintaining focus on the target."
        }
    ],
    "clip_183": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```markdown\n```json\n{\n  \"events\": [\n    {\n      \"timestamp\": 1,\n      \"action\": \"walk\",\n      \"target\": \"waterfront\"\n    },\n    {\n      \"timestamp\": 3,\n      \"action\": \"grab\",\n      \"target\": \"tower\"\n    },\n    {\n      \"timestamp\": 7,\n      \"action\": \"stand\",\n      \"target\": \"damaged tower top\"\n    }\n  ],\n  \"entities\": {\n    \"snowman\": {\n      \"static\": {\n        \"color\": \"white\",\n        \"attire\": \"red cape, silver crown\"\n      },\n      \"dynamic\": {\n        \"emotion\": \"playful\"\n      }\n    },\n    \"tower\": {\n      \"static\": {\n        \"color\": \"gray with red accents\",\n        \"attire\": \"\"\n      },\n      \"dynamic\": {\n        \"emotion\": \"\"\n      }\n    }\n  }\n}\n```\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A. 00:00\nB. 00:01\nC. 00:02\nD. 00:04\nE. 00:05\n- Skyscraper\n- Water\n- Building\n- Snowman mascot"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n    \"primary_tag\": \"giant snowman attacks city\",\n    \"secondary_tags\": [\"destructive\", \"ominous\", \"whimsical\"],\n    \"interactions\": [\"00:00\", \"02:00\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "*I stride toward the tower, grasp it, rip it from its base, and plant it elsewhere, feeling *triumphant* as debris scatters. The tower’s fate is now in my paws.*  \n\nFrom afar, the giant snowman marches, seizes the tower, uproots it with ease, and relocates it amid rubble. Observers gasp, awed by the tower’s abrupt, dramatic fate at the snowman’s hands."
        }
    ],
    "clip_184": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[00:00:00] The event starts with 3 people.\n[00:00:02] The event switch occurs with 3 people."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[00:00:00 to 00:00:01] This person uses the umbrella as a fishing net.\n[00:00:05 to 00:00:06] The person uses the umbrella as a shield.\nThe umbrella has a translucent color and a few character designs on its surface."
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "Video Narrative: A woman *amused* dips an umbrella in water, splashes it, making two children curious. Later, she splashes a man, who reacts *surprised*. --End--"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "[00:00:00 to 00:00:02] Paid $99 for my new umbrella, so worth it\n[00:00:00 to 00:00:00] 伞丽\n[00:00:02 to 00:00:09] Paid $99 for my new umbrella, so worth it\n[00:00:08 to 00:00:09] 빈치빈치"
        }
    ],
    "clip_185": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"man\": [\n        \"1. dark jacket, khaki pants\",\n        \"2. operate flamethrower\",\n        \"3. run away\"\n    ],\n    \"child\": [\n        \"1. light-colored onesie\",\n        \"2. hold man's arm\",\n        \"3. run away\"\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I hold Dad's hand. The fire roars, bright and hot, flames flashing. I yell, 'Dad Dad!' Then we run away from the fire."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "| Entity | Color | Key Action |\n|--------|-------|------------|\n| man | dark | spray fire |\n| child | light | pull man |\n| black SUV | black | drive in |\n| fire | orange | burn |"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. A person uses a flamethrower to ignite a fire on a snowy patch beside a gravel path.\n2. A child tugs at the person with the flamethrower, and text overlay 'MOMS COMING' appears as they start to move away.\n3. A black SUV drives up, stops, and a woman exits the vehicle, approaching the scene."
        }
    ],
    "clip_186": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "- High kick: Cheerleaders perform high kicks with one leg extended vertically while holding pom - poms, wearing uniforms with the \"USA\" logo.\n- Sync jump: Multiple cheerleaders jump simultaneously with legs bent and pom - poms raised, in \"USA\" logo - adorned uniforms.\n- Floor routine with poses: Some cheerleaders execute floor movements ending in poses like kneeling or leaning, while others support, all in \"USA\" marked uniforms.\n- Formation dance: The team moves in coordinated formations, changing positions while dancing and holding pom - poms, with \"USA\" on their uniforms.\n- Lunge with pom - pom lift: Cheerleaders perform lunges with one leg forward and pom - poms lifted high, wearing uniforms featuring the \"USA\" logo."
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "1. Stage visual elements: Cheerleaders in uniform, large screen with \"World Cheerleading 2024 Championships\" logo, star - patterned backdrop, audience, \"International Cheer Union\" banners, and \"USA\" text overlay.\n\n| Object              | Color                          |\n|---------------------|--------------------------------|\n| Cheerleaders' tops  | White (with \"USA\" text)        |\n| Cheerleaders' bottoms| Black                          |\n| Pom - poms          | White                          |\n| Backdrop            | Dark blue with light blue stars|\n| Large screen logo   | Gold, blue, red, purple        |\n| Banners             | White, red, blue               |\n\nA group of cheerleaders in white - and - black \"USA\" uniforms perform synchronized routines with pom - poms on a stage. The stage has a \"World Cheerleading 2024 Championships\" logo, starry backdrops, and \"International Cheer Union\" banners, while the audience watches."
        },
        {
            "field": "For Generation",
            "prompt_id": "03",
            "response": "The USA cheerleading team competes at the World Cheerleading Championships, organized by the International Cheer Union (ICU) in 2024."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The team performs synchronized moves with pom-poms. Audience members clap and cheer during the routine. The cheerleaders maintain precise coordination throughout the performance."
        }
    ],
    "clip_187": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- clothing: black long - sleeved shirt\n- clothing: black sleeveless shirt\n- clothing: black short - sleeved shirt"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The mural in the background depicts a group of approximately 10 people wearing brightly colored clothing. They are lined up and pulling each other, as if playing a game."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"time\":\"0-2s\",\"person\":\"black short\",\"interaction\":\"smoke appears in front\"},{\"time\":\"3-5s\",\"person\":\"black vest\",\"interaction\":\"drink with straw\"},{\"time\":\"6-8s\",\"person\":\"black short\",\"interaction\":\"eat from bowl\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the hot pot’s view: I’m bubbling, steam rising as people around the table add ingredients, dip food, and chat. Bowls and chopsticks move near me, with laughter and clinking filling the air.\n\nFrom the drink can’s view: I’m held, lifted, and set back on the crowded table. Steam from the hot pot drifts by as people eat, drink, and talk, with plates of food and other cans around me."
        }
    ],
    "clip_188": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "00:00 The player aims with a sniper rifle.\n00:03 The player aims with a sniper rifle.\n00:07 The player switches to a rocket launcher.\n00:08 The player fires the rocket launcher.\n00:08 The player has 1 rocket remaining."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Combat Scene Start:  \n1. A wide shot reveals a rugged mountain valley with **bold** rocky cliffs piercing the sky and snow drifts blanketing the slopes under a bright, cloudy sky.  \n2. The sniper scope view focuses, with *italics* crosshair steadying on a distant target aircraft soaring near the mountain peaks.  \n3. An explosion erupts, ==highlight== orange - red flames billowing outward, consuming the target and sending debris scattering across the rocky terrain.  \n---End of Scene---"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"0-3s\": {\n        \"player_action\": \"sniper_aim\",\n        \"UI_change\": \"none\",\n        \"target_interaction\": \"aircraft\"\n    },\n    \"4-7s\": {\n        \"player_action\": \"shoot_aircraft\",\n        \"UI_change\": \"none\",\n        \"target_interaction\": \"aircraft\"\n    },\n    \"8-11s\": {\n        \"player_action\": \"switch_to_rocket\",\n        \"UI_change\": \"none\",\n        \"target_interaction\": \"aircraft\"\n    }\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "- [00:00:01] +32 experience points\n- [00:00:04] +66 experience points\n- [00:00:08] +200 experience points"
        }
    ],
    "clip_189": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. White shed with red roof, 2. Small gray shed, 3. Green trees\n[\n  {\n    \"entity\": \"child\",\n    \"interaction\": \"rides a small motorbike on grass\"\n  },\n  {\n    \"entity\": \"grandmother\",\n    \"interaction\": \"stands by a table with a cup\"\n  },\n  {\n    \"entity\": \"grandfather\",\n    \"interaction\": \"stands by a table with a cup\"\n  }\n]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "A. Wide shot of a yard with sheds and trees, sunlight casting a soft glow over the grass. A child on a small motorbike speeds across the lawn. *Amused* ---\nB. Medium shot of the child on the motorbike approaching a patio, sunlight reflecting off the pavement. The child rides past a table with items on it. *Excited* ---\nC. Close - up of grandparents standing by the patio table, sunlight illuminating their faces. They watch the child with expressions of gentle exasperation. * Fondly resigned*"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"type\":\"person\",\"description\":\"child in red outfit and white helmet riding a small motorbike\",\"approximate_position\":\"middle\"},{\"type\":\"person\",\"description\":\"elderly woman in pink shirt sitting at a table\",\"approximate_position\":\"middle\"},{\"type\":\"person\",\"description\":\"elderly man in gray shirt standing at a table\",\"approximate_position\":\"left\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A child rides a small motorcycle across a grassy yard. The grandparents stand by a table, watching the child. They appear amused or resigned as they observe."
        }
    ],
    "clip_190": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Pink; 2. Yellow; 3. Silver  \n{  \n  \"recycling_bin_text\": \"RECYCLE CANS HERE! Every Can Counts DRINK CANS ONLY\",  \n  \"can_brand\": \"EVER GROUND\"  \n}  \nA hand reaches toward Person 1’s can costume and takes a blue can | The hand then moves toward Person 2’s recycling bin costume and drops the blue can inside."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Wide shot of the festival, showing crowds and colorful stalls under a sunny sky.  \nDolly in on the can costume to highlight its vibrant details.  \nPan across the recycling station where a can is dropped in.  \nTilt up from the recycling bin to the sky, emphasizing hope for sustainability.  \nVoiceover: \"Celebrate community and sustainability as we turn waste into wonder at the festival.\""
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"key_moments\": [\n        {\n            \"time_range\": \"0-5s\",\n            \"visual_cues\": [\"trees\", \"string lights\"],\n            \"action_verb\": \"touch\"\n        },\n        {\n            \"time_range\": \"7-9s\",\n            \"visual_cues\": [\"grass\", \"sky\"],\n            \"action_verb\": \"recycle\"\n        }\n    ]\n}"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "A festivalgoer, covered in aluminum cans, passes by a woman dressed as a recycling bin in an open grassy area. The day is sunny with scattered clouds. The camera follows the person in the aluminum can suit to the recycling bin."
        }
    ],
    "clip_191": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. Metal frames; B. Screen panels; C. Roof structure  \n---  \n{\"path\":[\"0s\",\"2s\",\"4s\"]}  \n---  \nThe enclosure door was open, allowing the ball to roll out."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Beach Ball's Perspective\nI roll across the patio, gaining speed toward the pool enclosure. *I’m flying! Wait, no—oh, I’m exiting through the open screen!* I bounce past the frame and land outside.\n\n{\n  \"emotion\": \"excited\",\n  \"cause\": \"Rolled freely across patio and exited through open screen enclosure\"\n}\n\n## Screen Enclosure's Perspective\nThe beach ball rolls toward me, then exits through my open screen panel. I watch it disappear beyond my frame.\n\n{\n  \"emotion\": \"disappointed\",\n  \"cause\": \"Beach ball exited through the open screen panel\"\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"ball rolling\",\n  \"secondary_tags\": [\"multicolored\", \"yard\", \"rolling\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In the pool area, a large inflatable ball moves across the patio, exits through an open screen door, and rolls away.\nI saw a big inflatable ball roll across the pool patio, go through the open screen door, and disappear outside.\nSurprised; the sudden movement of the large ball through the screen door is unexpected."
        }
    ],
    "clip_192": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A.\n1. {\n  \"hand\": \"light pink\",\n  \"water gun\": \"light blue\",\n  \"book\": \"white\",\n  \"pants\": \"black\"\n}\n2. {\n  \"hand\": \"light pink\",\n  \"water gun\": \"light blue\",\n  \"books\": [\"red\", \"purple\", \"blue\", \"beige\"],\n  \"clothing\": [\"black\", \"white and dark blue\"]\n}\nInference: The dialogue indicates that the reason for buying the water gun is to prevent others from picking it up and using it directly, implying a desire for control over who can use the item. --End--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "朋友：你为什么买这水枪？我：我不希望被别人捡起来直接使用。00:00 手持水枪，开枪。00:03 手持水枪。00:04 跑动，持枪。00:05 给水枪。00:06 男生和女生互动。00:07 古灵精怪之枪。00:08 女生被水枪发射的水射到，躲避，反抗。"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\": \"00\", \"person_id\": 1, \"action_desc\": \"Hold the water gun\"}, {\"timestamp\": \"06\", \"person_id\": 2, \"action_desc\": \"Take the water gun\"}]"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "A. 1s: Text is white: 弹道偏后？？\nB. 3s: Text is white: 正面开开关原来在这\nC. 9s: Text is white: 古灵精怪之枪"
        }
    ],
    "clip_193": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | 0-2s State | 3-5s State |\n| --- | --- | --- |\n| figure | Hanging below chair seat | Balancing on chair seat |\n| strings | Taut, holding figure | Taut, controlling figure movement |\n| chair | Stationary, with figure hanging | Stationary, with figure on seat |\n\n[{\"timestamp\": \"00:00\", \"entity\": \"strings\", \"action\": \"pull\"}, {\"timestamp\": \"00:02\", \"entity\": \"figure\", \"action\": \"rise to chair seat\"}]\n\nThe user's intent is to manipulate the figure using strings to perform movements on the chair seat."
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "{\"causes\": [\"Unstable center of gravity\", \"Foot string pulled unevenly\"], \"solutions\": [\"Widen stance of the balancing figure\", \"Pull foot string evenly\"]}\n| Tool | Purpose |\n|---|---|\n| String | Activate the figure |\n| Small Wooden Chair | Serve as a balancing surface |."
        },
        {
            "field": "For Generation",
            "prompt_id": "03",
            "response": "The small figure in the video is a nude, peach-colored clay figure with a head, two legs, and two arms holding a small stick. It's placed on a wooden chair."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "04",
            "response": "```\n{\n    \"primary_tag\": \"string manipulation with clothespin\",\n    \"secondary_tags\": [\"chair\", \"clothespin\", \"string\"]\n}\n```"
        }
    ],
    "clip_194": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"performer\": {\n        \"attributes\": [\"green\", \"BYU\"],\n        \"key_actions\": [\"run\", \"flip\", \"twist\"]\n    },\n    \"onlookers\": [\n        {\n            \"position\": \"standing\",\n            \"activity\": \"watching\"\n        },\n        {\n            \"position\": \"sitting\",\n            \"activity\": \"watching\"\n        },\n        {\n            \"position\": \"standing\",\n            \"activity\": \"recording\"\n        },\n        {\n            \"position\": \"standing\",\n            \"activity\": \"watching\"\n        },\n        {\n            \"position\": \"standing\",\n            \"activity\": \"watching\"\n        }\n    ]\n}"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "[\n  {\n    \"action\": \"multiple consecutive flips\",\n    \"execution_quality\": \"smooth\",\n    \"risk_level\": \"high\"\n  },\n  {\n    \"action\": \"backflips\",\n    \"execution_quality\": \"smooth\",\n    \"risk_level\": \"high\"\n  },\n  {\n    \"action\": \"side flips\",\n    \"execution_quality\": \"smooth\",\n    \"risk_level\": \"high\"\n  }\n]\n\n- recording\n- watching\n- clapping \n The performer surprised me with relentless, smooth acrobatics in a small space, showing extreme athleticism and practice. His strength, balance, and hours of training enable such risky, fluid moves."
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "I film a guy in green shirt. He runs fast, does flips, twists mid-air. A girl records with her phone. Another onlooker claps. I feel excited watching."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "04",
            "response": "```json\n{\n  \"timeline\": [\n    {\n      \"action_at_time\": \"begin running towards the kitchen area\",\n      \"performer_position\": \"middle\",\n      \"onlooker_activity\": \"recording\"\n    },\n    {\n      \"action_at_time\": \"execute multiple backflips in the kitchen\",\n      \"performer_position\": \"middle\",\n      \"onlooker_activity\": \"watching\"\n    },\n    {\n      \"action_at_time\": \"continue performing acrobatic flips across the kitchen\",\n      \"performer_position\": \"middle\",\n      \"onlooker_activity\": \"watching\"\n    },\n    {\n      \"action_at_time\": \"perform flips while moving past groups of onlookers\",\n      \"performer_position\": \"left\",\n      \"onlooker_activity\": \"recording\"\n    }\n  ],\n  \"unique_identifier\": \"green shirt and black shorts doing acrobatic flips\"\n}\n```"
        }
    ],
    "clip_195": [
        {
            "field": "For Instructional",
            "prompt_id": "01",
            "response": "```json\n{\n \"step1\": \"0-2s: The craftsperson inserts a wooden dowel into the structure.\",\n \"step2\": \"2-8s: The craftsperson uses a hammer to set the dowel.\",\n \"step3\": \"8-11s: The craftsperson sets the remaining dowels into the structure.\"\n}\n```\n\n| Action | Tool | Duration (s) |\n| ----------- | ----------- | ----------- |\n| Inserts a dowel | Hands | 2 |\n| Sets a dowel | Hammer | 6 |\n| Sets dowels | Hammer | 3 |"
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "- Beige\n- Rectangle and irregular\n- Ten\n\n```json\n{\n  \"dynamic_actions\": [\n    {\n      \"action\": \"Insert wooden dowel\",\n      \"timestamp\": 2\n    },\n    {\n      \"action\": \"Hammering wooden dowel\",\n      \"timestamp\": 5\n    },\n    {\n      \"action\": \"Hammering wooden dowels\",\n      \"timestamp\": 9\n    }\n  ],\n  \"repetitions\": 2\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. A person is fitting one dowel at a time into the holes.\n2. A person is using a hammer to fit the dowel into the holes.\n3. A person is using a hammer to connect the two wooden parts.\n\n```json\n{\n  \"hammer\": {\n    \"color\": \"black\",\n    \"purpose\": \"to fit the dowels into the wooden holes\"\n  },\n  \"dowels\": {\n    \"color\": \"white\",\n    \"purpose\": \"to connect two wooden parts\"\n  }\n}\n```\n\nThe dowels fit into the holes in two wooden parts, and hammering joins them together tightly."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "One piece of wood with cutouts is placed onto another piece of wood with matching protrusions, a small wood piece is inserted into a gap, and then a hammer is used to tap the wood pieces together tightly."
        }
    ],
    "clip_196": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Bird Interaction Analysis:\n1. 0.0s\n2. 3.4s\n3. 9.8s\n\n```json\n{\n\"emotions\": [\"shock\", \"confusion\", \"surprise\"],\n\"interactions\": \"none\"\n}\n```\n```json\n{\n\"emotions\": [\"sleepy\", \"annoyance\", \"boredom\"],\n\"interactions\": \"1\"\n}\n```\n```json\n{\n\"emotions\": [\"fear\", \"alarm\", \"agitation\"],\n\"interactions\": \"2\"\n}\n```\n\n---End Analysis---"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, I'm ready. Here is the storyboard script in JSON format, the transition paragraph, and the inner monologue for the third bird:\n\n```json\n[\n  {\n    \"time\": 0,\n    \"action\": \"A single cartoon bird with blue-grey feathers and an orange beak hovers, then lands on a power line.  The bird looks around with wide, expressive eyes.\",\n    \"camera_angle\": \"Medium shot, eye-level, focusing on the bird against a blue sky with puffy white clouds.\"\n  },\n  {\n    \"time\": 3,\n    \"action\": \"Another bird, identical to the first, flies in and joins the first bird on the power line. The two birds settle down, appear sleepy, then begin to sing loudly with open mouths.\",\n    \"camera_angle\": \"Medium shot, slightly wider to accommodate both birds. Shifts slightly to follow the second bird as it arrives.\"\n  },\n  {\n    \"time\": 9,\n    \"action\": \"The two birds sit, one looking at the other. A third bird arrives.\",\n    \"camera_angle\": \"Medium shot, slightly wider to accommodate both birds. Shifts slightly to follow the second bird as it arrives.\"\n  },\n  {\n    \"time\": 12,\n    \"action\": \"Now three birds sit on the powerline.\",\n    \"camera_angle\": \"Medium shot, slightly wider to accommodate both birds. Shifts slightly to follow the second bird as it arrives.\"\n  }\n]\n```\n\nThe second shot of the two birds, initially tired, then singing shifts to the next shot with a subtle dissolve, blurring the distinction between their energetic performance and the sudden appearance of the third bird. This transition creates a sense of unexpectedness as the birds transition from singing to the confused entrance of the new bird.\n\nInner Monologue of the Third Bird: \"Wait, what did I miss? Did they start the concert without me? Guess I should've flown faster... I hope they saved me a spot on the wire!\"\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\nTags: {\n  \"primary\": \"birds on wire\",\n  \"supplementary\": [\"playful\", \"lighthearted\", \"animated\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Narrative:\n1. A *surprised* bird is seen flying above the wire.\n2. A bird lands on the wire next to the first bird. They close their eyes, then suddenly open them and look *angry*.\n3. The birds start to get *angry* again, but then calm down and look *bored*.\n4. A third bird flies and lands on the wire next to them."
        }
    ],
    "clip_197": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"environment\": {\n    \"water_condition\": \"clear\",\n    \"sky_color\": \"blue\"\n  },\n  \"marine_life\": [\n    {\n      \"id\": 1,\n      \"fin_shape\": \"triangular\",\n      \"movement_pattern\": \"jerky\",\n      \"splash_intensity\": \"high\",\n      \"possible_cause\": \"predatory pursuit\"\n    },\n    {\n      \"id\": 2,\n      \"fin_shape\": \"crescent\",\n      \"movement_pattern\": \"jerky\",\n      \"splash_intensity\": \"high\",\n      \"possible_cause\": \"evasive action\"\n    }\n  ],\n  \"human_equipment\": {\n    \"boat\": {\n      \"engine_color\": \"black\",\n      \"distance_from_animals\": \"close\"\n    }\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the storyboard script:\n\n- Medium shot: 0-4 seconds, sharks circling in shallow water, splashing.\n- Medium shot: 4-7 seconds, boat and sharks circling, churning water.\n- Medium shot: 7-10 seconds, sharks circling, splashing, boat stationary.\n\n```json\n{\n  \"mood_keywords\": [\"shocked\", \"frenzied\", \"intense\"]\n}\n```\n\nDirector's note:\nThe speed of the sharks should be fast and erratic, indicating panic. The splashing is meant to suggest the sharks are disoriented and agitated. The sharks are likely doing this due to being in shallow waters that might trap them, making them want to return to deeper waters, or because of being separated from their group. The boat serves as a visual barrier hindering their movements."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"stingrays leaping\",\n  \"secondary_tags\": [\"shallow water\", \"sunny sky\", \"fast movement\"]\n}\n```\n\n| Entity    | Color       | Action          |\n|-----------|-------------|-----------------|\n| Stingray  | Dark gray   | Jumping, splashing |\n| Boat      | Light beige | Floating        |"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "[Swimmer View]: My heart races as large marine animals Thrash Nearby, splashing violently. I stay alert, cautious of their powerful movements, unsure if they’re playful or aggressive—every splash sends a jolt of fear.  \n\n[Bird View]: Marine animals Thrash And Swim Swiftly near the water’s surface, creating chaotic splashes. A boat floats nearby, with the animals’ movements concentrated in the shallow, clear water around it."
        }
    ],
    "clip_198": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Stunt Type       | Timestamp (s) |\n|------------------|---------------|\n| roof jump        | 0.0-0.5       |\n| sidewalk jump    | 0.5-1.5       |\n| porch roof jump  | 1.5-2.5       |\n| balcony jump     | 2.5-3.5       |\n| gate roof jump   | 3.5-4.5       |\n| second floor jump| 4.5-5.5       |\n| mid-air flip     | 5.5-6.5       |\n| final landing    | 6.5-8.0       |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```\n{\n  \"camera_movements\": [\n    {\n      \"movement\": \"tracking shot\",\n      \"shot_scale\": \"long shot\"\n    },\n    {\n      \"movement\": \"panning shot\",\n      \"shot_scale\": \"long shot\"\n    }\n  ],\n  \"lighting\": \"afternoon sun from right\",\n  \"performer_emotion\": \"adventurous\",\n  \"sound_effects\": [\"thud\", \"whoosh\", \"spring\"]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\n    \"start_time\": \"00:00\",\n    \"duration (s)\": \"0.5\",\n    \"height_estimate\": \"1.0\",\n    \"location\": \"Next to the grass\"\n  },\n  {\n    \"start_time\": \"00:01\",\n    \"duration (s)\": \"0.5\",\n    \"height_estimate\": \"1.5\",\n    \"location\": \"On the roof\"\n  },\n  {\n    \"start_time\": \"00:04\",\n    \"duration (s)\": \"0.7\",\n    \"height_estimate\": \"1.5\",\n    \"location\": \"Near the roof\"\n  }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "While the neighbor watched, a figure on a pogo stick launched from near 316 building’s roof, landing below—they gasped, surprised by the daring jump.  \n\nWhile the performer focused, they pushed the pogo stick hard, vaulting off 316 building’s roof and landing smoothly, muscles tensed with effort."
        }
    ],
    "clip_199": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"person\": {\n    \"clothing\": [\n      \"white tank top\",\n      \"green shorts\",\n      \"black boots\"\n    ],\n    \"carried_items\": [\n      \"head, TV\",\n      \"bike, tire\"\n    ]\n  },\n  \"actions\": [\n    {\n      \"description\": \"walking\",\n      \"object_involved\": \"bike\"\n    },\n    {\n      \"description\": \"riding\",\n      \"object_involved\": \"bike\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. I balance the object on my head, determined to transport it safely through the rain. {\"intent\": \"To transport the object safely through the rain.\"}\n2. Plummeting from the sky, I hit the object with a tiny splash, then continue my journey to the pavement below."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "0-5s|a man walks the bicycle forward in the rain|bicycle\n5-10s|the man rides the bicycle forward in the rain|bicycle\n10-15s|the man continues riding the bicycle forward in the rain|bicycle"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "It's pouring heavily, and I'm riding my bike ==slowly==. The rain is so intense that I need to be careful not to slip. I'm carrying a TV on my head, so I can't go fast—I don't want to drop it or lose balance. The wet road and my unusual load make a slow pace necessary. The most surprising thing? The man riding a bike with a TV balanced on his head in this downpour, staying steady and calm despite the heavy rain and tricky load."
        }
    ],
    "clip_200": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"intent\": \"The Scooter Rider Is Pursuing A Love Interest.\",\n  \"evidence\": [\n    \"The scooter rider runs up to the woman with a gift.\",\n    \"The scooter rider tries to give the woman the gift, but she rejects it.\"\n  ],\n  \"bystanders\": [\n    \"White Dress\",\n    \"White T-Shirt and Black Pants\"\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The bus stop has a paved platform, a **bench** where several people sit, and a nearby road. A **scooter** speeds by, stopping briefly near the stop. The area includes a glass shelter and some greenery in the background.\n—Did you see how fast that scooter rider was? It was like a flash!\n—Yeah, I’ve never seen someone zip by so quickly at a bus stop. Do you think they were in a hurry?\n—Probably! I hope they’re being safe though. That speed can be dangerous.\n—True, but it was definitely impressive. Wonder where they were heading so urgently."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"Attempted mugging foiled quickly\",\n  \"secondary_tags\": [\n    \"Fast-paced\",\n    \"Humorous\",\n    \"Quiet\"\n  ],\n  \"tertiary\": {\n    \"final\": \"Mugging averted\",\n    \"bystander_reaction\": \"indifferent\"\n  }\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I was standing at the bus stop, looking at my phone, when suddenly a scooter zoomed up. Before I knew it, someone **snatched** my clutch! I froze for a second, then everyone reacted.  \n\nI was zooming on the scooter, focused straight ahead, until I reached the bus stop. Then I **grabbed** the clutch from the woman, sped off, looped around, and handed it back. Quick job, then back on the scooter!"
        }
    ],
    "short_001": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, I'm ready to perform the task. Here is a video caption based on the instructions:\n\n1. A woman dressed as Elsa in a light turquoise dress and blonde wig.\n2. A person dressed as Santa Claus in a red and white Santa suit and a white wig.\n3. A child dressed as Olaf in a white costume, yellow pants, red shirt and red shoes.\n4. A woman dressed as Elsa in a light turquoise dress and blonde wig.\n5. A child dressed as Olaf in a white costume, yellow pants, red shirt and red shoes.\n6. A woman dressed as Elsa in a light turquoise dress and blonde wig."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here's the information from the video:\n\nThe camera is stationary.\n\n leaning with raised arms and surprised face | leaning with one leg raised and a Santa Claus head | leaning with one arm raised; surprised.\n\nAmused.\n\nAnna will appear next."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"Chin Length, Blonde And Curled\",\n  \"Startled\"\n]\n```\nHere is a description of the interesting and amazing part of the video. \nThe scene is amazing as characters from the movie \"Frozen\" pop out from behind the doors and give a great performance!"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! A door opens, and a child wearing an Olaf costume peeks out. The child looks at Santa Claus, puts his head down, and backs away behind the door. The door opens again, and Elsa peeks out, waving her hands."
        }
    ],
    "short_002": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here is the JSON object based on your instructions:\n\n```json\n{\n\"attribute\": [\"Red and Blue suit\", \"Masked\", \"Agile\"],\n\"action\": \"Swinging\",\n\"principle\": \"Using Webbing to Traverse Between Buildings\",\n\"count\": 1\n}\n```\nThe tallest building in the scene at the end of the video has the oscorp logo on it."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, I can help with that!\n\n| camera perspective | camera movement | shot content |\n| ----------- | ----------- | ----------- |\n| Third person perspective | Slow-motion | Spiderman falling between buildings in the city |\n| High angle shot |  Vertical, following Spiderman falling | Spiderman falling from a high building down to the ground with a view of the city streets |\n| Medium shot |  Following Spiderman jumping from a water tank | Spiderman jumping from a water tank, flying towards the horizon |\n\n- Excitement\n- Fast-paced\n- Heroic\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Swinging| Leaping| Ziplining| Helicopter\nHoly smokes, that web-slinger swung between the buildings. I hope he doesn't mess with the traffic, though."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here is the requested information:\n\nA.\tI am swinging through the buildings in New York City, showing my skill.\nB.\tI am perched atop a water tank, admiring my city skyline.\nC.\tI am soaring through the skies, preparing for a challenge in the skies.\n\nMood and emotions: I am confident, feeling in control, and looking forward to using my abilities for the good of the city."
        }
    ],
    "short_003": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here are the ordered and unordered lists describing the changes in the scene:\n\n1.   Road Runs Through Trees\n2.  Trees Transition To Houses And Shops\n3.  Road runs through the center of shops and residences\n\n- BUILDING\n- TREES TRANSITION TO HOUSES\n- SHOPS, RESIDENCES AND BUS STOP"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the JSON object based on the video:\n```json\n{\n  \"Camera_Movement\": \"The camera is moving forward.\",\n  \"Main_Actions\": [\n    \"Cars drive along the road.\",\n    \"People walk on the sidewalk.\",\n    \"A truck is driving along the road.\",\n    \"A cyclist rides along the road.\"\n  ],\n  \"Light_Source_Relative_Position\": \"The light source is located in front of the camera\"\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n1. car\n2. truck\n3. van\n4. bus\n5. bicycle"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here's the JSON output based on the video:\n\n```json\n{\n  \"trucks\": {\n    \"number\": 1,\n    \"actions\": [\n      \"moving forward\"\n    ]\n  },\n  \"turn\": [\n    {\n      \"color\": \"silver\",\n      \"direction\": \"right\"\n    }\n  ]\n}\n```"
        }
    ],
    "short_004": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n[\n  {\n    \"movement\": \"FORWARD\",\n    \"direction\": \"STRAIGHT\",\n    \"below\": \"SAND\"\n  },\n  {\n    \"movement\": \"ASCEND\",\n    \"direction\": \"UP\",\n    \"below\": \"TREES\"\n  },\n  {\n    \"movement\": \"FORWARD\",\n    \"direction\": \"STRAIGHT\",\n    \"below\": \"WATER\"\n  }\n]\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Storyboard:\n**Low Flyover** - Camera moves low and fast over a sandy, partially vegetated lakeshore, with the lake and trees in the background, lasting 2-3 seconds.\n**Ascending Through Trees** - Camera ascends while moving forward through a cluster of trees, revealing more of the lake and surrounding landscape, lasting 2-3 seconds.\n**Aerial Over Lake** - Camera flies high over the calm lake, capturing the reflection of clouds and trees on the water's surface, with the sun creating lens flares, lasting 2-3 seconds.\nEnd Storyboard"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "trees; lake; sand; reflection; The camera glides over a sandy shoreline, then rises above a small grove of trees before rotating to display the reflection of the clouds in the still lake."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! The camera starts low to the ground, highlighting the [grayish-white] sand, then rises to capture a serene [dark-blue] lake reflecting the [light-blue] sky with [white] clouds. The landscape features a mix of [green] trees along the water's edge and [brown] trees slightly further inland. The camera gradually ascends and then moves away from the shore, providing a scenic overview of the lake and surrounding forest environment!!!"
        }
    ],
    "short_005": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Person | Clothing | Key Action |\n| --- | --- | --- |\n| Woman | White shirt | Standing, gesturing, laughing, interacting playfully |\n| Man | White t-shirt, black pants | Standing, gesturing, laughing, interacting playfully |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The camera remains stationary;the woman smiles throughout the video, with her expression becoming more animated and joyful as she interacts with the man."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Man and woman interact, Pillow fight, On the bed | The man in video wears a denim jacket, Driving a car"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here is the video description:\n\nI'm standing with my friend, and we're both a little hesitant, then we start chasing each other, giggling as we grab pillows and have a playful fight. The light is on the bed side and a man's face is on the wall. The man on the bed puts his head between his legs for a moment."
        }
    ],
    "short_006": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here are the results:\n\n| Entity_Type | Description |\n|---|---|\n| Family | Three members, casually dressed, one adult in red |\n| Fence | Wooden railing around the lookout area |\n| Road | Narrow, asphalt road with minimal traffic |\n\nObvious item: Trees"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "### Rocky Cliff Overlook\nVast green fields stretch out below, intersected by a winding road that cuts through the landscape. Patches of trees and varied terrain add depth to the expansive rural scenery surrounding the cliff."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here are the JSON array and the paragraph according to your instructions.\n\n```json\n[\n  \"overlook\",\n  \"standing\",\n  \"sunny\",\n  \"landscape\",\n  \"observing\"\n]\n```\n\nI'm standing on top of this big, rocky hill with a wooden fence all around, so it's safe. The sun is warm and makes the green fields stretch out forever. It's like a giant, green carpet. I can see the grown ups point at things far away. I wonder what they see that I don't. It feels like we're the kings of the world standing here.\n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The video shows a group of people on a rocky cliff viewpoint with wooden railings. The drone rotates around them, revealing vast landscapes of green fields, trees, and distant rocky hills under a clear sky."
        }
    ],
    "short_007": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity       | Color       | Action                                                                 | Outcome                                                                 |\n|--------------|-------------|-----------------------------------------------------------------------|------------------------------------------------------------------------|\n| Sea urchin   | Dark (spines) | Is grasped by tongs, held, and its interior (yellow) is exposed        | Its interior is examined, and parts are handled by gloved hands        |\n| Person's hands | Blue (gloves) | Grasp urchin with tongs, hold urchin, manipulate its interior, release | Successfully handle and examine the sea urchin's interior underwater    |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The video starts with a close - up shot (macro shot) of a gloved hand interacting with sea urchins underwater. The camera remains relatively stable in the first frame, focusing on the hand and sea urchins.\n2. Then, there is a quick movement of the camera, likely due to the action of the hand, causing a brief blur as the perspective changes. The shot scale is still close - up, focusing on the hand and sea urchins.\n3. The camera stabilizes again, maintaining a close - up shot of the gloved hand as it uses a tool to interact with the sea urchins.\n4. The camera continues to stay in a close - up shot, capturing the detailed interaction between the gloved hand, the tool, and the sea urchins.\n5. The close - up shot is maintained, showing the ongoing action of the hand and tool with the sea urchins in the underwater environment."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\n    \"sea urchin\": {\n      \"appearance\": \"spiky, with a shell that is partly or fully open\",\n      \"outcome\": \"The contents are being extracted and scattered as food\"\n    }\n  },\n  {\n    \"small fish\": {\n      \"appearance\": \"Small and orange\",\n      \"attempt\": \"gathering around for feeding\"\n    }\n  },\n  {\n    \"environment\": {\n      \"location\": \"underwater, with a seabed covered in algae and rocks\",\n      \"water quality\": \"clear water\"\n    }\n  },\n  {\n    \"diver\": {\n      \"more than one\": false,\n      \"equipment\": \"gloves and a tool\"\n    }\n  }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Listen: Underwater, gloved hands use tongs to pick up a sea urchin, extract its yellowish interior, and examine it. Small fish swim around. Thank you."
        }
    ],
    "short_008": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- pointed spires\n- large stained - glass windows\n- stone facade with intricate carvings\n- multiple gabled roofs\n- tall central tower with a glass - paneled top"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Zoom out | Cathedral\n2. Tilt up | City\nIt is a sunny day in the city, with light haze in the sky. The cathedral is tall and impressive, and the surrounding buildings are quite old with red tile roofs."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"buildings-York, UK\",\n  \"cars-York, UK\",\n  \"houses-York, UK\",\n  \"trees-York, UK\",\n  \"street-York, UK\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The video shows an aerial view of a large, historic cathedral with intricate architectural details and multiple spires. The camera moves backward, revealing more of the cathedral's structure, including its tall central tower and adjacent buildings. Surrounding the cathedral are green lawns, trees, and a mix of residential and other structures, with a road running alongside. The background includes a sprawling cityscape under bright sunlight."
        }
    ],
    "short_009": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"furniture\": [\"table\",\"bench\"],\"electronics\": [\"fish tank\", \"clock\", \"overhead light\"]}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here's the video caption based on your instructions:\n\nThe camera maintains a steady, static shot capturing the interior of a wood-paneled kitchen, with a partially visible adjoining room. A woman with long, dark hair and glasses walks into the frame from the adjoining room, moving towards a wooden table with built-in benches. She initially reaches to sit on the bench but then pauses, appearing to adjust her clothing or an item in her lap. Subsequently, she sits down, checks her socks, and then rises again and moves to stand on the bench. Standing on the bench, she reaches up and fiddles with an overhead light fixture. After adjusting the light, she steps back down, seemingly satisfied with her handiwork. \n\nInitially, she feels frustrated when something went wrong. When the overhead light is successfully fixed, she is pleased and relieved.\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here is the video description based on your instructions.\n\n1.  The woman is wearing glasses, a black top, a short black skirt, gray tights, and a green and blue plaid shirt.\n2.  The woman's gesture at the end of the video is most likely a \"ta-da\" gesture, indicating that she has completed the task and is showing it off."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here are your instructions:\n\nA. Woman touches the booth.\nB. Woman feels her leg.\nC. Woman touches the lamp.\nD. Woman covers her eyes.\nE. Woman adjusts the light.\nF. Woman touches the table.\nG. Woman is touching her hair.\n\nHere are the color detections in the video:\n\nGreen: The plants in the fish tank.\nBlue: The fish tank and the curtain in the room next door."
        }
    ],
    "short_010": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Brass lamp on bedside table. 2. Black remote on bedside table. 3. Brown wooden bedside table."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here's a description of the video\nThe person walks to the open closet, then she **bends down** and reaches in, trying to get something out of the closet. Then, she **pulls out a box** and stands up. After holding it in her hands she **walks out of the frame** with the box. \nThe camera is static and does not move. The shot type is a medium shot, capturing the person from the mid-torso up and the closet."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the video details:\n woman,closet, lifting, box, bedroom, clothing."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here are the video details:\nA Woman Sneezes, Then Reaches Into a Closet. She Pulls Out a Box and Carries it Away."
        }
    ],
    "short_011": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Character 1: Hair color light green with pink highlights, eye color blue, clothing gray tank top\n- Character 2: Hair color green with pink highlights, eye color blue, clothing gray tank top\nThe two characters appear to be the same person."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "00:05 Woman picks up cutting tool;\n00:08 Woman uses cutting tool on her arm and says \"go to hell\";\n00:18 Woman drops tool and says \"no\"."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "blonde hair, needle, angry, pain"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A girl with gray hair sits, picks up a needle, talks to her reflection, and pricks her arm. She shows pain and reluctance, with another girl watching."
        }
    ],
    "short_012": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"Refrigerator\": \"Near the far wall of the kitchen, next to the corner countertop.\",\n  \"Electric Kettle\": \"On the left side of the countertop, next to the center.\",\n  \"Countertop\": \"The bottom left corner of the video frame.\"\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Frames: [{\"description\": \"Hand places electric kettle on countertop in kitchen with flowers and appliances.\", \"is_key_frame\": true}, {\"description\": \"Hand moves electric kettle slightly on the countertop.\", \"is_key_frame\": false}, {\"description\": \"Person walks across kitchen towards stainless steel refrigerator.\", \"is_key_frame\": false}, {\"description\": \"Hand reaches for refrigerator door handle.\", \"is_key_frame\": false}, {\"description\": \"Refrigerator doors open, revealing brightly lit interior with food items.\", \"is_key_frame\": true}, {\"description\": \"Hand takes plate with pink cubes from top shelf of refrigerator.\", \"is_key_frame\": false}, {\"description\": \"Hand picks fresh green leafy vegetable from refrigerator shelf.\", \"is_key_frame\": false}, {\"description\": \"Green leafy vegetable is placed onto plate with pink cubes.\", \"is_key_frame\": false}, {\"description\": \"Person closes refrigerator doors and walks back to kitchen counter with plate.\", \"is_key_frame\": false}]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: grabbing food, opening refrigerator, food preparation, cooking"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here are the video description steps:\n\n1.  Step: Turning off the electric kettle with a confident motion.\n2.  Step: Walking to the refrigerator.\n3.  Step: Opening the refrigerator door.\n4.  Step: Retrieving a plate of cubed ham and grabbing some lettuce.\n5.  Step: Closing the refrigerator door.\n6.  Step: Walking back to the kitchen counter, seemingly content with the chosen ingredients."
        }
    ],
    "short_013": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| **Element**       | Details                                                                 |\n|--------------------|-------------------------------------------------------------------------|\n| Person's Attire    | Gray suit, white dress shirt, red tie                                   |\n| Key Action         | Man picks up telephone receiver in a phone booth and speaks into it     |\n| Setting            | Inside a red telephone booth with falling leaves visible outside         |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Scene: Telephone Booth - A man stands inside a red telephone booth. Wind blows through the booth, and leaves fly around outside the window. The man turns his head to observe the surroundings, then picks up the telephone receiver, brings it to his ear, and speaks into it. He then takes the receiver away from his ear, looking at it. --End Scene--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the captions:\n\nThe man seems to hear clearly. He picks up the phone and speaks into it in a normal tone. He is smiling, which indicates he's happy. The man is in a British telephone box. Outside the box, there is greenery and trees. It is dark, possibly at night. \n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I felt anxious in the booth, then picked up the phone, spoke urgently, and finally hung up, still uneasy."
        }
    ],
    "short_014": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Bubble bottle: pink color, cylindrical shape\n- Bubble wand: yellow color, loop - shaped"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Event number | shape of the bubble |\n| --- | --- |\n| 1 | butterfly |\n| 2 | dog |\n| 3 | human |\n| 4 | human head |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "pink,yellow,butterfly,dog,human|bubbles form into various shapes and figures"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here are the descriptions:\n\nThe video shows a person blowing bubbles in the park. Look! The bubbles make fun shapes, like a butterfly, a dog, and even a person. The bubbles have pretty rainbow colors.\n\nAt first, he seems excited and wows when he see the bubble-butterfly. But then, he's scared and throws away the bubbles and bubble bottle when they make the running man bubble with a face."
        }
    ],
    "short_015": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n[\n  {\n    \"position\": \"left\",\n    \"drink_attrs\": {\n      \"color\": \"white\",\n      \"garnish\": \"orange slice\"\n    },\n    \"event\": \"placing\"\n  },\n  {\n    \"position\": \"right\",\n    \"drink_attrs\": {\n      \"color\": \"blue\",\n      \"garnish\": \"lime wedge\"\n    },\n    \"event\": \"placing\"\n  },\n  {\n    \"position\": \"left\",\n    \"drink_attrs\": {\n      \"color\": \"white\",\n      \"garnish\": \"orange slice\"\n    },\n    \"event\": \"taking\"\n  },\n  {\n    \"position\": \"right\",\n    \"drink_attrs\": {\n      \"color\": \"blue\",\n      \"garnish\": \"lime wedge\"\n    },\n    \"event\": \"taking\"\n  },\n  {\n    \"position\": \"left\",\n    \"drink_attrs\": {\n      \"color\": \"white\",\n      \"garnish\": \"orange slice\"\n    },\n    \"event\": \"clinking\"\n  },\n  {\n    \"position\": \"right\",\n    \"drink_attrs\": {\n      \"color\": \"blue\",\n      \"garnish\": \"lime wedge\"\n    },\n    \"event\": \"clinking\"\n  }\n]\n```\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera initially focuses on the blurry background of the bar with bottles. 2. The focus shifts to the bartender placing two drinks on the bar counter and then to the hands of the patrons picking up the drinks."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: bar|cocktails|serve|dim|lighting|drinks"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! A bartender puts two yummy drinks on the counter. A man and a lady, maybe a couple, pick up their pretty drinks. They are at a fancy bar together!"
        }
    ],
    "short_016": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. DEA officers approach the house with weapons drawn.\n2. DEA officers surround the entrance of the house, aiming their weapons.\n3. DEA officers breach the door and enter the house."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. DBCA\n2. CDBA\n3. BCDA\n4. ACBD\n5. CABD\n6. ACBD\n7. ABCD"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"DEA agent\", \"firearm\", \"house\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Scene: The video captures a dynamic scene where DEA officers are approaching a suburban residence. Armed with rifles and handguns, they move swiftly toward the front door, demonstrating tactical precision. The officers cautiously advance, maintaining their focus on the windows and doorways. The video concludes as they enter the dimly lit house, conveying a sense of imminent action."
        }
    ],
    "short_017": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the descriptions of the changes in lighting in this video:\n\n1.  Evening: The buildings in the distance are getting darker as the sun begins to set, while the streetlights are not yet illuminated.\n\n2.  Evening: The buildings are becoming gradually darker, the sky appears to be fading with some lights being turned on the buildings.\n\n3.  Evening: The city buildings have lights on as the surrounding sky gets increasingly dark and a few streetlights come on.\n\n4.  Evening: The buildings in the distance are lit with more lights as it gets dark and the nearby streetlights begin glowing.\n\n5.  Night: The city skyline shines with glowing building lights as the night has begun. Street lights are on for the night as well."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Scene: From an elevated viewpoint, a timelapse reveals a spacious stone plaza overlooking a skyline. Initially, people meander, their activity relaxed and leisurely, bathed in the soft, fading sunlight. As dusk deepens, the city lights twinkle to life, mirroring the lively atmosphere of the plaza. The warm glow of street lamps casts long shadows, adding depth to the scene. The sky transitions from a pale blue to a deep twilight, enhancing the bustling energy of the cityscape below. [End Scene]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"urban plaza\", \"day to night\", \"people walking\", \"time-lapse\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here are the video descriptions in English with Chinese translations:\n\nA. \n1. People are walking and relaxing at the plaza during the daytime. (白天，人们在广场上散步和放松。)\n2. As the evening approaches, the city lights start to turn on. (随着夜幕降临，城市的灯光开始亮起。)\n3. After dark, the plaza is illuminated by the streetlights, and the city skyline is brightly lit. (天黑后，广场被路灯照亮，城市天际线灯火通明。)"
        }
    ],
    "short_018": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"1\": {\n    \"attire_color\": \"purple\",\n    \"is_wearing_vr\": false\n  },\n  \"2\": {\n    \"attire_color\": \"yellow\",\n    \"is_wearing_vr\": true\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "| Person | Action | Attire |\n| --- | --- | --- |\n| **Person 1** | Wearing VR headset, holding VR controller, interacting with VR | Yellow |\n| **Person 2** | Gesturing, talking, guiding | Purple |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: Vr;Gaming;Friends;Entertainment"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Scene: Two young men in a room with neon lights. A man wearing a VR headset is holding a controller. The other man, in a purple sweatshirt, guides him with hand gestures. \n\nThe second man tries to help the first man find something in the game, and it looks like he wants the first man to focus and aim correctly. The mood of the interaction is friendly and collaborative."
        }
    ],
    "short_019": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"entities\": [\n        {\n            \"type\": \"person\",\n            \"attributes\": [\"wearing red clothing\", \"performing stunt\"]\n        },\n        {\n            \"type\": \"horse\",\n            \"attributes\": [\"white\", \"adorned with decorations\"]\n        }\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[{\"type\": \"Person\", \"description\": \"Performer in **red and white** attire doing stunts while hanging from a horse.\"}, {\"type\": \"Horse\", \"description\": \"Decorated horse galloping with a performer hanging from it during a stunt.\"}]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\"horse riding trick\", \"grassy field\", \"horse trick rider\", \"green ribbons\"]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In an outdoor field with a fenced area and spectators, a person in red and white traditional attire hangs sideways off a galloping horse, holding on with one hand while other riders on decorated horses follow, and the person eventually climbs back onto the horse as they pass by onlookers."
        }
    ],
    "short_020": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- person: Two adult men, one in a plaid shirt and dark pants, the other in a light blue and orange shirt and light brown pants.\n- object: A small yellow bag with a red logo on it, a green container with a white lid, and a transparent container with a red lid.\n- fruit: Bananas, green mangoes, watermelons, and possibly papayas."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Two men stand outside a store, with one man holding a yellow bag open and the other man placing items into the bag.\n2. The man holding the bag leaves with the bag, while the other man looks at the items left on the ground.\n3. A third man exits the store and grabs the man who stayed behind by the neck."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "man put bottle into bag|man take bag away|storefront"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Two men stand outside a store, one in a checkered shirt and the other in a light blue shirt, as they repeatedly place bottles into a yellow bag, with the man in the checkered shirt occasionally looking at the camera; after several attempts, the man in the light blue shirt runs off with the bag, leaving the other man frustrated and running his hand through his hair, while another person emerges from the store and interacts with the man in the checkered shirt."
        }
    ],
    "short_021": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Attribute Type | Value |\n|---|---|---|\n| Woman | Clothing Color | Beige |\n| Forest | Environment | Woods |\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Shot 1: At eyelevel, a woman **rests** her hands on a tree, and gives a beautiful, genuine smile while looking at the camera.\nShot 2: A woman **offers** her hand out, and then **turns** and **walks** forward through the woods smiling at the camera.\nShot 3: A woman, at eyelevel, **walks** in between the trees, turns around and **poses** for the camera in the forest."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"forest\", \"walk\", \"tree\", \"spin\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "看！一个快乐的女人在森林里玩耍。她穿着粉色的衣服，在树林里转圈圈。她看起来非常开心。\n"
        }
    ],
    "short_022": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Man holds camera through red basket, captures soccer ball kick.\n2. Man uses camera to photograph chessboard with creative angles.\n3. Man places camera in bike basket, captures spray paint can shot."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "{\n  \"camera_brand\": \"Nikon\",\n  \"prop\": \"red plastic basket\"\n}\nThe photographer holds a camera behind a red basket, then captures shots of a soccer ball, chess set, and spray paint can in an outdoor setting."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "CAMERA; PHOTOGRAPHY; OUTDOOR"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! The person holding the soccer ball has a joyful emotion, because it is his turn to make the photo session. He is having fun because he is being photographed by his friend."
        }
    ],
    "short_023": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Video Analysis: {\"entity\": \"A man with dark hair and a beard wearing a tan long-sleeved shirt.\", \"actions\": [\"Draws a circle and writes numbers 1 to 12 within it, indicating each hour.\", \"Draws lines, connecting some of the numbers and writing the number 13 next to each line.\"]} --End--"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Camera movement: static\n- Shot scale: medium shot"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "teacher,whiteboard,lecture,education,class"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man stands before a whiteboard with a drawn clock. He draws lines that add up to 13 with each number. He wears a **tan** tunic.\n一位男士站在白板前，白板上画着一个钟表。他画线将每个数值加总至十三。他穿着土色束腰外衣。"
        }
    ],
    "short_024": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Competition Roles:\n\n| Role | Clothing | Action |\n|------|----------|--------|\n| **Lifter** | Black shirt, black shorts, white shoes | Perform bench press, re-rack barbell, celebrate |\n| **Purple-shirt spotter** | Purple shirt, black pants, blue shoes | Assist with barbell during lift |\n| **Green-shirt spotter** | Green shirt, black pants | Observe and assist with barbell |\n| **Referee** | Red shirt | Observe the lift closely |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "{\"shot_type\": \"medium shot\",\n \"action\": \"lifting barbell\", \n\"duration_seconds\": 26.67}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[ \"Weightlifting: 220 lbs\",  \"Bench Press\",  \"Christian74kg\",  \"Excited\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A lifter in a black outfit attempts a 100kg bench press at a competition, struggles, but completes the lift with spotters' help, then celebrates."
        }
    ],
    "short_025": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "The video shows a supermarket employee accidentally knocking over and shattering several bottles of liquid, resulting in a spill on the floor.\n1. The employee initially tries to contain the spill with her hands and a small bin.\n2. She collects large pieces of broken glass into the bin and a trash bag.\n3.  She and a colleague use cloths to clean up the remaining liquid on the floor."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"step\": 1,\n        \"description\": \"A woman accidentally knocks over a cart, causing items to spill.\"\n    },\n    {\n        \"step\": 2,\n        \"description\": \"Colleagues bring cleaning supplies to address the spill.\"\n    },\n    {\n        \"step\": 3,\n        \"description\": \"They use **mops and paper** to clean up the spilled items.\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  \"Cleaning crew\",\n  \"cleaning products\",\n  \"shopping cart\"\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Alert: A worker drops items causing a spill; cleaners work efficiently and calmly!"
        }
    ],
    "short_026": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"color\":\"white\",\"display_type\":\"digital\",\"weight_reading\":\"56.1 kg\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "walk towards the weight scale; stand on the weight scale to measure weight"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Scale, Anime, Shocked."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The blonde anime character is confident about her weight and steps on the scale. When she sees the weight on the screen, she gets angry, which is visually shown by blue energy around her body."
        }
    ],
    "short_027": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- dog: white and black\n- dog: white and brown\n- dog: white"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. The camera is initially static and shows a man standing on a rocky edge beside a body of water. Two dogs, one white and black and the other white and brown, are seen beside him. The man jumps into the water. \n2. The camera then tracks the white and brown dog as it jumps into the water and swims to shore."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "diving, river, dog"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man jumps into water, followed by a black-and-white dog.  A small, white-and-brown dog leaps in after, swims, and is helped out of the water.\n"
        }
    ],
    "short_028": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Analysis:{\"bottle_attributes\":{\"material\":\"plastic\",\"color\":\"clear with blue cap\"},\"main_action\":\"A hand flips a plastic bottle; the bottle rotates in the air and lands upright on a surface.\",\"observed_device\":\"A smartphone displays a video of another bottle flip sequence.\"}---End---"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Camera static; hand flips water bottle onto table, laptop shows cow animation || Camera static; hand picks up phone, scrolls TikTok video of bottle flips, screen shows UI elements"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "- bottle\n- flip\n- phone\n- screen"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Watch this: A hand flips a water bottle to land upright, then the camera shifts to a phone showing a video of a bottle flip chain. Cool trick!"
        }
    ],
    "short_029": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- person: has long hair, wears green jacket\n- person: wears black jacket and blue jeans\n- person: wears white jacket and dark pants\n- person: wears dark jacket and black shorts\n- firework: tall, thin, emits sparks and smoke when ignited\n- sparkler: emits light and sparks, held by a hand\n- fence: wooden, in the background\n- grass: green, covers the ground\n- sky: dark (nighttime initially, then transitions to daytime with sun and clouds)"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Action 1: Lighting a firework; Action 2: Running away; Action 3: Launching a firework; Action 4: Watching the firework explode;\nThe person in the video launches a $500 firework."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "firework, night, yard"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Reaction: The group runs away in panic as the firework ignites and shoots up. After the firework explodes, they gather back, looking amazed and discussing the display. - End"
        }
    ],
    "short_030": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"tank\": \"A beige-colored tank drives on the road.  It is being operated by a soldier.\", \"buildings\": \"There are tall skyscrapers in the background, and the sky is pink and purple.\", \"soldiers\": \"There are two soldiers, one inside the tank and one on top of it.\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Cinematic Description: Camera moves forward following a tank on a city street; shot scale transitions from long shot to medium shot as the tank approaches, then to close-up revealing details of the tank and crew. --End Shot--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Tank, Sunset, Cityscape"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A tank moves slowly along a city street at dusk, with tall buildings, trees, and other vehicles in the background. A soldier is visible on the tank.\n一辆坦克在黄昏时沿城市街道缓慢行驶，背景有高楼、树木和其他车辆，坦克上可见一名士兵。"
        }
    ],
    "short_031": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"Exercise1\": \"00:00 While wearing black shirt and shorts\", \"Exercise2\": \"00:10 Shirtless man showing his back\", \"Exercise3\": \"00:33 Shirtless man flexing his muscles\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "introduce muscle-building methods|He wants to show viewers how to build muscles like him."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 0, 1000, 397], \"label\": \"glass door\"},\n  {\"box_2d\": [0, 339, 1000, 1000], \"label\": \"glass door\"},\n  {\"box_2d\": [544, 0, 1000, 1000], \"label\": \"floor\"},\n  {\"box_2d\": [110, 274, 1000, 652], \"label\": \"man\"},\n  {\"box_2d\": [47, 36, 1000, 961], \"label\": \"glass door\"},\n  {\"box_2d\": [47, 540, 1000, 639], \"label\": \"glass door\"},\n  {\"box_2d\": [125, 274, 1000, 727], \"label\": \"man\"},\n  {\"box_2d\": [0, 569, 1000, 1000], \"label\": \"glass door\"},\n  {\"box_2d\": [0, 649, 1000, 1000], \"label\": \"glass door\"},\n  {\"box_2d\": [240, 274, 1000, 727], \"label\": \"man\"},\n  {\"box_2d\": [240, 0, 1000, 1000], \"label\": \"floor\"},\n  {\"box_2d\": [125, 274, 1000, 727], \"label\": \"man\"},\n  {\"box_2d\": [0, 274, 1000, 397], \"label\": \"glass door\"},\n  {\"box_2d\": [240, 274, 1000, 644], \"label\": \"man\"}\n]\n```\nHere are the requested keywords:\nMAN, MUSCULAR, SHIRTLESS, WORKOUT, DUMBBELL, BICEPS, TRICEPS."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Watch: The man is demonstrating weightlifting with dumbbells. He performs exercises such as the dumbbell curl and the triceps overhead press to build muscles and strength, showing off his physique!"
        }
    ],
    "short_032": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Character with black hair, wearing white and purple clothing\n- Character with yellow hair, wearing orange and black clothing\n- Character with pink hair, wearing red and pink clothing\n- Character with brown hair, wearing green and blue clothing\n- Character with black hair, wearing dark clothing with red accents and a headband"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Looks at the camera;  puts arm around Naruto; fights."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"Sasuke\", \"Naruto\", \"Sakura\", \"Yamato\", \"sword\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The black spiky hair character has a serious expression.\n2. The blonde character has a determined expression with sweat on his face.\n3. The pink hair character has a tense expression."
        }
    ],
    "short_033": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[{\"clothing\":\"white shirt, dark pants\",\"action\":\"using a paint roller on the upper part of the wall while standing on a step ladder\"},{\"clothing\":\"brown coat, dark pants, black boots\",\"action\":\"observing or assisting with the painting work\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"continuing to paint the upper section of the wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the middle and lower parts of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"painting the upper part of the wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the middle section of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"painting the upper part of the wall near the ceiling\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the lower section of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"moving the step ladder and continuing to paint the upper wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the middle part of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"painting the upper part of the wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the lower section of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"painting the upper part of the wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the middle part of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"painting the upper part of the wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the lower section of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"painting the upper part of the wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the middle part of the wall\"},{\"clothing\":\"white shirt, dark pants\",\"action\":\"painting the upper part of the wall\"},{\"clothing\":\"black top, blue jeans\",\"action\":\"painting the lower section of the wall\"}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "camera is static, people quickly move around and paint the wall;"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "painting, interior, time-lapse, long shot"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! People are painting a big wall blue."
        }
    ],
    "short_034": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Attributes |\n| --- | --- |\n| Street artist | Female, wearing headscarf, creating sand art of dogs |\n| Sand art | Depicts dogs, on sidewalk, being refined with tools |\n| Spray bottle | Near the artist, used for art creation |\n| Tools | Brush and knife, used to shape sand art |\n| Pedestrians | Walking in background, near storefronts |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Tools: **brush**, knife, spray bottle; Use the **brush** to apply powder to the painting to shape the outline of the puppy; There are four sculptures in total, lying on the ground, with two puppies lying on the big dog."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "street painting, dog, artist, sidewalk"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. A street artist creating a 3D chalk drawing of dogs on a sidewalk.\n2. The artist uses tools to shape and refine the chalk drawing on the pavement.\n3. The artist appears focused and dedicated to detailing the artwork."
        }
    ],
    "short_035": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Shot Number | Location | Scene description |\n| --- | --- | --- |\n1|Outside the gym building|The camera shows the exterior of a building with 'FITNESS' signage, parked cars, and a comment overlay saying 'Hold on, that's a nice gym bro'.\n2|Outside the gym building|The camera pans left to reveal more of the gym building's exterior, including the full 'Onelife FITNESS' sign and additional parked cars.\n3|Inside the gym|The camera transitions to the gym's interior, showing a spacious area with people, gym equipment, and the 'Onelife FITNESS' sign at the reception desk."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Pan left across the parking lot to show the gym building exterior.\n2. Move inside to show the gym's interior areas like the lobby and workout spaces.\n3. Transition to the basketball court, showcasing its layout and equipment.\n4. Finally, pan to the swimming pool area, displaying the pool and its surroundings."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "TREADMILL, GYM, EXERCISE, FITNESS, ONELIFE, WORKOUT"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I visited the gym today. First, I used the treadmill in the cardio area. Then, I tried the weight machines. The place was big, with lots of space to move around."
        }
    ],
    "short_036": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- airplane\n- Santa Claus doll\n- bottle\n\nAirplane moves forward.\nSanta hits bottles with stick.\nBottles fall as airplane passes."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. A toy airplane with a Santa Claus figure on its wing moves along a runway.\n2. The Santa Claus figure waves a stick as the airplane passes by several glass bottles.\n3. The text \"Miniatur Wunderland\" appears on the screen as the airplane continues moving."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"Santa Claus\", \"model plane\", \"airport\", \"glass bottle\", \"model show\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The toy Santa Claus is dressed in a red outfit with a white beard and a red hat. He sits on the wing of a toy airplane, holding a long stick with a white ball at the end. As the airplane moves, Santa remains seated, with the stick positioned outward, maintaining his posture throughout the video.\nThe toy airplane is white with \"THAI\" written on its side and a purple tail, featuring four engines under its wings. It travels along a miniature runway, passing by several clear glass bottles filled with liquid placed on the grass beside the runway. The airplane continues moving forward through a detailed miniature airport setup with buildings and small structures in the background until it exits the frame."
        }
    ],
    "short_037": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- house: white lights, above water\n- trees: red lights, above water\n- trees: white lights, above water"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Camera pans left; focuses on **illuminated building and landscape with red lights**.\n2. Camera continues panning left; focuses on **red and white light - covered terrain near water**.\n3. Camera pans left further; focuses on **red - lit hillside with white light path and trees**.\n4. Camera keeps panning left; focuses on **red - lit area with green - lit trees and distant building**.\n5. Camera pans left to end; focuses on **red - lit landscape and white - light - outlined building**."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"red lights\", \"white lights\", \"house\", \"trees\", \"river\"], \"occasion\":\"holiday decoration display\", \"emotion\":\"awe\""
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "At night, buildings are outlined with white lights, the riverbank is covered in red lights, and trees have white lights, creating a festive holiday atmosphere with twinkling illumination."
        }
    ],
    "short_038": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| person        | held_objects       |\n|---------------|--------------------|\n| adult man     | sandwich           |\n| adult woman   | sandwich, cup      |\n| child         | -                  |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Initial focus on two people (a man and a woman) interacting in a snowy forest.\n2. New subject (a child) enters the frame and interacts with the woman."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "winter, snow, picnic, friends, hot drink"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man and a woman sit on a bench in a snowy forest, the man holds a sandwich and gestures while talking, the woman drinks from a cup and holds a sandwich; a child runs up, sits next to the woman, and the woman offers the cup to the child, who takes a drink as the man continues talking."
        }
    ],
    "short_039": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"actions\": [\n        {\n            \"step\": 1,\n            \"description\": \"Run and jump onto the floating pads in the pool.\"\n        },\n        {\n            \"step\": 2,\n            \"description\": \"Climb up the inflatable wall using the handles.\"\n        },\n        {\n            \"step\": 3,\n            \"description\": \"Cross the inflatable obstacles by climbing and moving across them.\"\n        }\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "participant runs and jumps onto floating pads; participant jumps onto inflatable wall and climbs up; participant climbs over inflatable obstacle; participant slides down inflatable slope; participant climbs over inflatable cylinders; participant climbs up inflatable wall"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Keywords: Jump, Climb, Slide, Balance, Obstacle;;"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The participant starts by running and jumping onto floating pads in the pool, looking determined as he balances and moves forward.\n2. He then climbs an inflatable wall using handles, showing focus and physical effort to reach the top.\n3. Finally, he navigates through more inflatable obstacles, including climbing over structures and sliding, maintaining perseverance and agility throughout the challenge."
        }
    ],
    "short_040": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| TV Content | Man's Action | Object Used |\n|------------|--------------|-------------|\n| Woman with jewelry showing tongue | Eat then offer food | Fork, plate |\n| Animated purple bird on branch | Toss and eat fruit | Fruit |\n| Man breaking glass table | Mimic breaking with hammer | Hammer |\n| Man on fridge falling | Throw sock at TV | Sock |\n| Car wash scene | Pour liquid on TV | Container |\n| Man with stethoscope on TV | Touch TV and gesture | None |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Camera focuses on the man; he mimics eating with a fork, appearing playful.\n2. Camera focuses on the TV; the man reacts to the TV's content, showing amusement.\n3. Camera focuses on the man; he pretends to interact with an animated bird on TV, looking entertained.\n4. Camera focuses on the TV; the man mimics actions from the TV, displaying a humorous or engaged emotion."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 0, 1000, 1000], \"label\": \"room\"},\n  {\"box_2d\": [38, 158, 936, 853], \"label\": \"furniture\"},\n  {\"box_2d\": [0, 0, 1000, 1000], \"label\": \"rug\"},\n  {\"box_2d\": [0, 0, 1000, 1000], \"label\": \"wall\"},\n  {\"box_2d\": [44, 257, 918, 853], \"label\": \"tv\"}\n]\n```\nHere are the keywords for the video: \"person, furniture, room, rug, wall, tv\"."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. He is playful while feeding.\nA. He feels amused by the cartoon.\nA. He is shocked by the broken glass.\nA. He finds the video funny.\nA. He mimics the car wash scene."
        }
    ],
    "short_041": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here's the JSON output:\n```json\n{\n  \"color\": \"green\",\n  \"features\": [\n    \"large teeth\",\n    \"tail\",\n    \"fire breathing\",\n    \"scales\",\n    \"wings\"\n  ],\n  \"actions\": [\n    \"flying\",\n    \"breathing fire\",\n    \"falling through a hole in the screen\"\n  ],\n  \"size_relative_to_character\": \"much larger\"\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Start: **A cartoon character shows curiosity, excitement, determination, confusion, and joy while interacting with a hand holding a fruit. A dragon later appears, breathes fire, and interacts with the fruit.** *The dragon flies in, breathes fire at the fruit, creates a hole in the screen, and then interacts with the fruit outside the screen.* End:"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "wood, explosion, dragon, apple, cartoon."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. A hand holds a yellow apple and moves it towards the screen, where a cartoon character shows changing emotions (curiosity, excitement, confusion) as it interacts with the apple.\nB. The cartoon character rides a green dragon that appears on the screen; the dragon breathes fire towards the apple held by the hand, showing a dynamic interaction between the dragon and the apple.\nC. The dragon continues to interact with the apple, with actions like flying around the screen and the character on its back reacting, while the hand moves the apple, leading to the dragon eventually \"biting\" or interacting physically with the apple outside the screen."
        }
    ],
    "short_042": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, I'm ready to create the table.\n\n| Action | Object Acted Upon | Approximate Timestamp (seconds) |\n| ------- | -------- | ------- |\n| Assembling |  Papercraft Minecraft house | 34 |\n| Assembling | Papercraft Minecraft house | 18 |\n| Putting | Papercraft bed on gray block | 16 |\n| Assembling | Papercraft building | 4 |\n| Spinning | Minecraft crafting table | 0 |\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Building Process: Use ==axe== to gather **wood** from the crafting table, construct walls with **cobblestone** and **wood planks**, add doors/windows, build a roof with **wood planks**, place the finished house on a grassy platform. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"constructing/assembling\", \"crafting\", \"cutting\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A hand uses pixelated tools and blocks to chop wood, mine stone, craft items, shear a sheep, and build a small house, ending with placing the house on a grassy base."
        }
    ],
    "short_043": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Black jersey player: Runs toward the goal\n- White jersey player: Chases the black jersey player\n- Red jersey player: Tries to intercept the ball but fails"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "\n```json\n[\n  {\"player color\": [\"black\", \"red\"], \"action\": \"defending\", \"emotion_inference\": \"angry\"},\n  {\"player color\": [\"black\", \"red\"], \"action\": \"scoring goal\", \"emotion_inference\": \"happy\"}\n]\n```\n```json\n[\n  {\"player color\": [\"green\", \"white\"], \"action\": \"defending\", \"emotion_inference\": \"determined\"},\n  {\"player color\": [\"green\", \"white\"], \"action\": \"scoring goal\", \"emotion_inference\": \"excited\"}\n]\n```\n```json\n[\n  {\"player color\": [\"black\", \"white\"], \"action\": \"celebration\", \"emotion_inference\": \"joyful\"}\n]\n```\n```json\n[\n  {\"player color\": [\"blue\", \"white\"], \"action\": \"acrobatic kick\", \"emotion_inference\": \"determined\"}\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "run, compete, football, field, player; The scene is exciting and tense because players are running and competing fiercely for the football on the field, with the outcome of scoring or defending uncertain."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In the video, players run, kick the ball, and celebrate goals with excitement and joy, showing energetic movements and gestures. The video also shows moments of tension, like a close call with \"NO GOAL!\" text, and ends with a player's acrobatic move near the stands."
        }
    ],
    "short_044": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Look! Hands are mixing colorful clay balls. The clay balls are being squished together. The clay changes colors when mixed."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Place the clay balls together.\n2. Press and fold the clay balls to mix them.\n3. Roll the mixed clay into a new ball."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the descriptive words for the video:\n\nBlack + Pink + Purple = Gray | White + Blue + Purple = Blue | Red + Yellow + Green = Brown | Mixing | Squashing | Clay"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Okay, here are the ordered descriptions and the purpose of this video:\n\n1.  Black, pink, and purple clay combine and mix to make gray clay.\n2.  White, light-blue, and purple clay combine and mix to make light-blue clay.\n3.  Red, yellow, and green clay combine and mix to make brown clay.\n\nThe purpose of this video is to show how clay colors can be mixed."
        }
    ],
    "short_045": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- The left man in a gray suit, sunglasses and blond hair.\n- The middle man in blue pants, black jacket, and dark hair.\n- The right girl in a blue dress and brown hair."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The camera focuses on the man standing still on the wooden platform.\nThe spring rapidly extends, launching the man high into the air with a sudden upward motion."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "the man on the spring platform talks; the woman throws money boxes down; the man jumps to the clouds and dances"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. **Woman**: Initially shocked and concerned, then determined when throwing the money briefcase, and finally surprised after the man reaches the upper platform.\n2. **Man on the springboard**: First nervous and trying to balance, then resolute when making gestures, and finally confident and celebratory upon reaching the upper platform.\n3. **Man in the suit**: Remains composed and observant throughout, showing approval and encouragement towards the end."
        }
    ],
    "short_046": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\"Archer Queen\":\"crossbow\",\"Barbarian\":\"hammer\",\"Goblin\":\"sack\",\"Skeleton\":\"bomb\",\"Balloon\":\"none\",\"Arrows\":\"none\"}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "{\n    \"shots\": [\n        {\n            \"camera_movement\": \"static\",\n            \"focus_entity\": \"**Archer Queen**\",\n            \"action_occurring\": \"Archer Queen kneels and continuously fires arrows with a crossbow while various characters run past her.\"\n        },\n        {\n            \"camera_movement\": \"static\",\n            \"focus_entity\": \"**Skeleton**\",\n            \"action_occurring\": \"Skeleton runs holding a bomb with a lit fuse, approaches a stone structure, and the structure explodes as the bomb is near it.\"\n        }\n    ]\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"Goblin\",\"Barbarian\",\"Balloon\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The Archer Queen defeats a horde of attacking troops in Clash of Clans in this clip. The Archer Queen is first shown smirking confidently after a skeleton holding a lit bomb explodes, destroying a rock wall. The skeleton is shown with a bomb, and it is lit and explodes. The Archer Queen is then shown angrily firing her crossbow at the army, which includes Barbarians, balloons, goblins, and hog riders that run past her."
        }
    ],
    "short_047": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Rotate and place the toy house.\n2. Move polar bear toy to door.\n3. Press the red button on toy house door.\n4. Open the toy house to reveal interiors.\n5. Place pig toy in kitchen area.\n6. Place penguin toy near piano.\n7. Move bear toy up ladder to bedroom.\n8. Place bear toy on bed in bedroom.\n9. Place fox toy on chair in study.\n10. Place frog toy in bathtub.\n11. Slide frog toy down green slide.\n12. Slide penguin toy down green slide.\n13. Move pig and penguin toys on seesaw."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Playtime Scene: Toy home with characters|Slide & seesaw play. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"carry toy\",\"press doorbell\",\"open toy house\",\"place toy figures\",\"play on seesaw\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A hand holds the toy house by its green handle and moves it."
        }
    ],
    "short_048": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Two cats are boxing in a ring. One cat gets hurt and goes to the hospital. The little cat trains hard. After three years, the cat wins the boxing match!"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "\npractise boxing; skip rope; The small kitten becomes a muscular cat and participates in boxing matches."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the video keywords: boxing, feline, AI-generated, competition, emotional."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. 愤怒，因为在拳击比赛中出拳攻击对手；\nB. 悲伤，因为抱着小猫时面露难过神情。"
        }
    ],
    "short_049": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 0, 1000, 585], \"label\": \"fruit\"},\n  {\"box_2d\": [0, 598, 1000, 999], \"label\": \"fruit\"}\n]\n```\nHere are the objects with faces:\n- fruit\n- fruit"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**Pregnancy and Ultrasound**  \nI lay still as a gloved hand moves a small tool over my surface, and a phone shows tiny faces—my babies! I feel a mix of excitement and nervousness, wondering how many little ones are growing inside me.  \n\n**Surgery and Meeting My Babies**  \nHands in blue gloves prep me with a wipe, then a syringe. I feel a small pinch, and soon, they carefully open me up. Out come my babies—tiny, green, and smiling! I watch as they’re gently placed on a tray, each with their own cute expressions. Finally, I feel relief and joy, proud to have brought so many little watermelons into the world."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 0, 1000, 999], \"label\": \"still\"}\n]\n```\nHere are the keywords for the video:\n```json\n[\n  \"watermelon\",\n  \"animation\",\n  \"fruit\",\n  \"surgery\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Video Description: A cartoon watermelon undergoes a \"surgery\" to remove baby watermelons (baby watermelons: 西瓜宝宝). Gloved hands use tools, show ultrasounds, and extract the small watermelons. Ends with a follow prompt. ---"
        }
    ],
    "short_050": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here are the clothing colors based on your instructions:\n\n- Yellow shirt\n- White dress\n- Blue shirt\n- Red shirt"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "boy approaches old woman; they touch fingers; boy leaves happily"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"grandma\", \"boy\", \"energy\", \"touch\", \"family\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! A boy makes his grandma feel tired, and her battery goes low! Then, she holds hands, and they hug, making her feel better. Her battery is full of energy again! Everyone is so happy!"
        }
    ],
    "short_051": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "[{\"action\": \"A boy in green clothes holds a red video camera, speaks to a pink dinosaur, then steps back in fear.\", \"involved_characters\": [\"green-clothed boy\", \"pink dinosaur\"]}, {\"action\": \"A boy in orange clothes pulls the green-clothed boy away, and a girl in blue clothes watches from behind.\", \"involved_characters\": [\"green-clothed boy\", \"orange-clothed boy\", \"blue-clothed girl\"]}, {\"action\": \"The orange-clothed boy restrains the struggling green-clothed boy, with the blue-clothed girl still watching.\", \"involved_characters\": [\"green-clothed boy\", \"orange-clothed boy\", \"blue-clothed girl\"]}, {\"action\": \"The green-clothed boy and the orange-clothed boy sit on the ground, with the green-clothed boy speaking to the pink dinosaur, and the orange-clothed boy covering the green-clothed boy's mouth. The pink dinosaur approaches them, and the blue-clothed girl continues to watch.\", \"involved_characters\": [\"green-clothed boy\", \"orange-clothed boy\", \"pink dinosaur\", \"blue-clothed girl\"]}, {\"action\": \"The pink dinosaur lowers its head to eat peanuts on the ground, while the green-clothed boy and orange-clothed boy look on in surprise, and the blue-clothed girl continues to watch.\", \"involved_characters\": [\"green-clothed boy\", \"orange-clothed boy\", \"pink dinosaur\", \"blue-clothed girl\"]}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"description\": \"Pink dinosaur with purple eyes\",\n        \"interaction\": \"Interacts with boy, eats snacks\"\n    },\n    {\n        \"description\": \"Boy in green hoodie, purple shorts\",\n        \"interaction\": \"Films dinosaur, argues, gets held\"\n    },\n    {\n        \"description\": \"Chubby boy in orange tank top\",\n        \"interaction\": \"Restrains green - hoodie boy, reacts\"\n    },\n    {\n        \"description\": \"Blue robotic cat with red nose\",\n        \"interaction\": \"Observes the scene with others\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Suneo, dinosaur, camera, quarrel, eating"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. Look! A boy takes photos of a pink dinosaur.\nB. Look! A big boy pulls the small boy away.\nC. Look! The pink dinosaur eats snacks on the floor."
        }
    ],
    "short_052": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- has a dark handle\n- has a golden hilt with red gem decorations\n- has a large and wide blade with visible cracks"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. camera pans down; a man approaches a sword placed on a table\n2. camera remains static; the man picks up the sword with both hands\n3. camera cuts to a front view of the man; the man raises the sword, and subtitles appear at the bottom of the screen\n4. camera cuts to a close - up of the sword hilt, then moves along the sword to the tip; the man holds the sword up to display it\n5. camera cuts to a side view of the man; the man speaks while holding the sword, with subtitles at the bottom\n6. camera cuts to a close - up of the man's face; the man shouts loudly, and then the camera cuts to a close - up of a woman's face\n7. camera cuts to an overhead view of the room; soldiers with swords surround several people, and subtitles appear at the bottom\n8. camera cuts to a close - up of the man's back; the man speaks, and then the camera cuts to a close - up of the woman's face\n9. camera cuts to the man speaking, with subtitles at the bottom, and then cuts to the woman's face"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here is the video description:\nThe man is furious after hearing that his son died in the Aura battle. His son's sword, which was given by the emperor, returned to his possession. He is going to execute the messengers to revenge his son. He has lost his son, the reason he wants peace negotiation in the first place. He loses control over his anger."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man draws a sword, speaks angrily, and points the sword at others."
        }
    ],
    "short_053": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Person's arm is extended, hand open. A second person puts their hand into the first person's hand to hold. Feeling of longing for comfort.\n2. A man with a serious look on his face looks upwards. A woman beside him looks down with a slight smile. Feeling of trust and hope.\n3. A man and woman ride in a buggy on a dusty terrain. The man is excited. The woman is ready for action. Feeling of freedom and readiness."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "close-up|the camera moves down to the woman's hands|close-up|a hand reaches out to the woman's hand|wide shot|the man and woman jump off the car|close-up|the two sit in the car|close-up|the woman starts the car|wide shot|the car drives forward on the ground"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "handshake, driving, moon surface, neon light"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In the video: A woman extends her hand, a man takes it, they jump, drive a car, and speed across the ground."
        }
    ],
    "short_054": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Masked character throws scimitar; blonde character blocks it.\n2. Blue-clad character stands protectively in front of blonde character.\n3. Two masked characters retreat as blue-clad character watches."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- camera angle changes (low angle, close - up, etc.)\n- shot scale changes (medium shot, close - up, long shot)"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "The images show a video game scene featuring characters, Link and Zelda.  Link, wearing a blue tunic, and Zelda, with long blonde hair and a blue dress, face two Yiga Clan members. Link is standing protecting Zelda, with his sword drawn, while the Yiga Clan members approach holding sickle like weapons. A fallen Yiga clan member lies behind Link."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look! A character in blue steps forward with a sword drawn, blocking an attack aimed at the blonde character."
        }
    ],
    "short_055": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Character | Clothing Attributes       | Primary Action               | Interaction Target |\n|-----------|---------------------------|------------------------------|--------------------|\n| Woman     | Pink, long - sleeved, paw - print | Cleaning ceiling fixture     | Man                |\n| Man       | Blue shirt, yellow shorts, yellow cap | Approaching and interacting with woman | Woman              |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I was reaching up to wipe the light when I noticed the black door and the small Mexican flag on the wall, feeling a bit of focus as I worked. Then he entered—wearing that yellow cap—interrupting my rhythm. We joked, and he handed me something, making the task feel lighter, though my concentration had shifted."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"cleaning ceiling fixture\",\n  \"secondary_tags\": [\"playful atmosphere\", \"indoor setting\", \"tissue paper\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "As I clean the ceiling light, I focus on wiping it well. When he enters, I feel a mix of surprise and slight irritation, especially when our interaction turns playful yet chaotic.\n\nI approach her to see what she’s doing. Watching her clean the light, I want to join in, so I offer help. Her reaction to my gestures is playful, making the moment feel light - hearted despite the mess."
        }
    ],
    "short_056": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the objects found in the video:\n1. A bag of money\n2. Green blocks\n3. A toy car\n4. A house\n5. Clouds\n6. Land\n7. Persons\n\nHere is the JSON output:\n```json\n{\n    \"Woman\": \"House\"\n}\n```\nThe middle person falls due to object disappearance.\n"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here are the shot-by-shot descriptions:\n\n1. [00:00:00 to 00:00:02] MS: A man on the left drops a bag of money into a pit. A woman stands on the middle block, looking at the bag. A man on the right is reaching out to place a block on his side.\n2. [00:00:02 to 00:00:06] MS: A man on the left drops a toy car into the pit. A woman stands on the middle block, looking at the car. A man on the right is reaching out to place a block on his side.\n3. [00:00:06 to 00:00:09] MS: A man on the left drops a toy house into the pit. A woman stands on the middle block, looking up. A man on the right is reaching out to place a block on his side.\n4. [00:00:09 to 00:00:12] MS: A man on the left is trying to convince the woman to come with him. A woman stands on the middle block, considering. A man on the right is waiting for her decision.\n5. [00:00:12 to 00:00:19] MS: A man on the left is trying to convince the woman to come with him. A woman stands on the middle block, looking at the man on the right. A man on the right is waiting for her decision.\n6. [00:00:19 to 00:00:20] MS: The woman leaps off the middle block toward the man on the right."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"timestamp\": \"00:01\", \"thrown object\": \"Money bag\", \"person\": \"left\"},\n  {\"timestamp\": \"00:04\", \"thrown object\": \"Toy car\", \"person\": \"left\"},\n  {\"timestamp\": \"00:08\", \"thrown object\": \"Toy house\", \"person\": \"left\"},\n  {\"timestamp\": \"00:18\", \"thrown object\": \"Person\", \"person\": \"center\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Three people stand on separate platforms; the person on the right repeatedly places blocks while the person on the left drops objects like money, a car, and a house into a gap, and eventually, the middle person falls into the gap after losing balance."
        }
    ],
    "short_057": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n        \"timestamp\": \"00\",\n        \"action\": \"Hold hands and stand on carpet\",\n        \"actors\": [\"child\", \"woman\"]\n    },\n    {\n        \"timestamp\": \"01\",\n        \"action\": \"Carpet cracks, move to bedside table\",\n        \"actors\": [\"child\", \"woman\"]\n    },\n    {\n        \"timestamp\": \"06\",\n        \"action\": \"Child steps onto bedside table\",\n        \"actors\": [\"child\", \"woman\"]\n    },\n    {\n        \"timestamp\": \"11\",\n        \"action\": \"Child jumps from table to bed\",\n        \"actors\": [\"child\", \"woman\"]\n    },\n    {\n        \"timestamp\": \"16\",\n        \"action\": \"Woman steps onto table, then jumps\",\n        \"actors\": [\"child\", \"woman\"]\n    }\n]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The video takes place in a bedroom with a bed covered in a red blanket, a white nightstand, and a wall with a light fixture. A hole appears on the floor, initially small and then expanding. The child is wearing a neon green top and pink leggings, while the adult is in a neon green and pink outfit with pink shoes.\n\n1. The hole appears on the floor. The child and adult are standing on the intact part of the floor, holding hands.\n2. The hole expands. The child steps back towards the nightstand, and the adult follows.\n3. The child stands on the nightstand, and the adult kneels nearby.\n4. The child jumps onto the bed, and the adult stands up.\n5. The adult steps onto the nightstand, and the child sits on the bed.\n6. The adult falls into the hole, and the child reaches out.\n7. The child jumps off the bed towards the hole.\n8. Both fall onto the floor, laughing."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\"interaction\": \"holding hands\", \"timestamp\": \"00\"},\n  {\"interaction\": \"collaborative jumping\", \"timestamp\": \"06\"},\n  {\"interaction\": \"assisted jumping\", \"timestamp\": \"16\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A hole appears in the floor. The woman helps the child avoid the hole. The child jumps onto the bed. Both laugh at the end."
        }
    ],
    "short_058": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, I understand. Here is the table summarizing the entities as requested:\n\n| Entity Type | Name/Identifier | Color | State |\n|---|---|---|---|\n|Airplane | Air Niugini Boeing 737 | White, Red | Submerged |\n| Rescue Boat | Rescue Boat | Gray, Black | Floating |\n| Rescue Equipment | Life Vest | Red, Black | In Use|"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Alright, here is the video description.\n\nThe scene begins with a small motorboat approaching an Air Niugini Boeing 737 in the water. Overcast skies and choppy waves.\n\nScene 1: The Rescue.\nLocals in small boats and US Navy sailors are approaching the half-submerged plane to rescue the passengers and crew. Some passengers are being helped out of the plane and onto the boat. Some passengers are carrying their carry-on luggage. Some of the rescuers and passengers are wet, cold, but relieved.\n\nScene 2: The Cockpit\nThere are some video recordings of the interior of the cockpit as the plane is landing. Viewers can see the dashboard and the wipers are on due to the thunderstorm and heavy rain. The video mentions that the flight engineer recorded this crash landing on his cellphone. The pilots are distressed by the rough weather conditions during landing."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"name\": \"plane\", \"type\": \"object\", \"state\": \"in the water\"},\n  {\"name\": \"boat\", \"type\": \"object\", \"state\": \"moving\"},\n  {\"name\": \"water\", \"type\": \"object\", \"state\": \"still\"},\n  {\"name\": \"person\", \"type\": \"person\", \"state\": \"on the boat\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I felt urgency and determination as we sped toward the downed plane. Every second counted, and the need to help survivors pushed us forward. The water’s chop didn’t slow our resolve—we had to reach them.\n\nI felt terror and helplessness as the plane descended. Alarms blared, and the realization of impending crash flooded me. The descent felt endless, each moment a battle to stay calm amid the chaos."
        }
    ],
    "short_059": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here is the information based on the provided video.\n```json\n[\n  {\n    \"color\": \"orange\",\n    \"emotion_trajectory\": [\n      \"worried\",\n      \"happy\"\n    ]\n  },\n  {\n    \"color\": \"purple\",\n    \"emotion_trajectory\": [\n      \"happy\",\n      \"sad\"\n    ]\n  },\n  {\n    \"color\": \"red\",\n    \"emotion_trajectory\": [\n      \"angry\",\n      \"angry\"\n    ]\n  },\n  {\n    \"color\": \"green\",\n    \"emotion_trajectory\": [\n      \"sad\",\n      \"angry\"\n    ]\n  }\n]\n```\nA. The first scene shows a purple blob handing out tests. The blob appears excited. _The background is a simple yellow._\nB. The second scene shows an orange blob sitting at a desk in a classroom. The orange blob is worried about the test, but then the blob thinks of something and becomes happy.\nC. The last scene shows **red**, purple, orange, and green blobs at the desk. The orange and green blobs want the purple blob to help them cheat, but the purple blob protests."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here you go:\n\n## Test Time\n- Fear\n- Sneaky\n\n## Help From a Friend\n- Angry\n- Desperate\n- Resigned\n- Reluctant"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"orange\", \"study\", \"classroom\", \"anxious\", \"comical\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The video opens with the teacher announcing a test. An orange character with a shocked expression says, “A test! What do I dooo?”  He becomes happy when he thinks of a study partner. Next, a blue character is writing when the orange character moves in close. A pink character says, “Hey don’t hog him!” Followed by a green character. The blue character exclaims, “Just because I wear glasses doesn’t mean I’m smart!” The green character asks, “Are you smart?” The blue character says, “Yes.” Then, the pink and green characters attack the blue character."
        }
    ],
    "short_060": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here's the JSON object:\n```json\n{\n  \"child\": {\n    \"attributes\": [\n      \"red\"\n    ],\n    \"actions\": [\n      \"writing on a board\",\n      \"correct the answer\"\n    ]\n  },\n  \"woman\": {\n    \"attributes\": [\n      \"black, khaki\"\n    ],\n    \"actions\": [\n      \"looks at a board\",\n      \"smiles\"\n    ]\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I am writing down the answers on the whiteboard. I am writing the number in increasing order.  I can hear the sound of music playing in the background. I thought it was a simple task to do but it turned out not to be so easy when I made a couple of mistakes. I hope I can get better at math soon. \n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\"moment\": \"00:08|9*9= |77|81\"},\n  {\"moment\": \"00:09|8*9=|7|72\"},\n  {\"moment\": \"00:11|5*9=|4|45\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "This is a math learning scene in a classroom. A young student is writing math problems on the board as the woman watches him from his side. At first, the kid is just writing 1, 2, 3... as the answer for the times tables, but the woman lets him correct it and make it right. Finally, the kid corrects all of the answer."
        }
    ],
    "short_061": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"entities\": [\n    {\n      \"color\": \"orange and black\",\n      \"wing pattern\": \"distinct black veins\"\n    }\n  ],\n  \"events\": [\n    \"00:00-00:10\": \"Catching **monarch butterfly** with white net; moving butterfly to **glass jar**\",\n    \"00:10-00:20\": \"Multiple **monarch butterfly** clinging to hands, flying around **glass jar**\"\n  ],\n  \"cinematic\": \"POV perspective\"\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I fluttered in panic as the net closed around me, then felt the confinement of the jar, until my companions arrived and I was relieved—together, we lifted our captor high into the sky."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here are the video descriptions based on your instructions.\n\n00:01|Catches butterfly\n00:04|Jar transfer begins\n00:16|Carried to the air"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Look closely, our journey begins in a serene meadow under a clear blue sky. A butterfly flits playfully, teasing the net like a child playing tag, held skillfully by an adventurer.\n\n==With a triumphant catch, the butterfly is gingerly placed into a glass jar. A second flutters onto his arm, then another, until his arm is adorned with a dozen vibrant butterflies. They take to the sky! Suddenly, the man is carried aloft, soaring above the world. The scene transforms to reveal a breathtaking view of a sprawling city below.==\n\nWhat started as a moment of triumph turns to panic as he is lifted by these winged creatures to such heights. His exclamation of excitement quickly fades to fear."
        }
    ],
    "short_062": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, here's the JSON object based on the video:\n```json\n{\n  \"black-haired boy\": {\n    \"static_attributes\": [\n      \"black\",\n      \"yellow\"\n    ],\n    \"interactions\": [\n      {\n        \"target\": \"muscular man\",\n        \"action\": \"receive apple\"\n      },\n      {\n        \"target\": \"white-haired cat-eared woman\",\n        \"action\": \"runs after\"\n      }\n    ]\n  },\n  \"muscular man\": {\n    \"static_attributes\": [\n      \"red\",\n      \"pink\",\n      \"green\"\n    ],\n    \"interactions\": [\n      {\n        \"target\": \"black-haired boy\",\n        \"action\": \"give apple\"\n      }\n    ]\n  },\n  \"white-haired cat-eared woman\": {\n    \"static_attributes\": [\n      \"white\",\n      \"green\"\n    ],\n    \"interactions\": []\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- If you choose to have the black-haired boy catch up to Satella:\n- *He apologizes earnestly, admitting his mistakes. Satella, touched by his sincerity, forgives him. They embrace, promising to work through their issues together.*\n- If you choose to have the black-haired boy not catch up to Satella:\n- *He stands alone, filled with regret. His pleas go unheard as Satella disappears from view. He vows to make amends but is left with a heavy heart, haunted by what could have been.*"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"gray-haired man\", \"chase\", \"street\", \"find girl\", \"anxious\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Ladies and gentlemen, welcome to this bustling market, busy as a beehive! Here, a muscular man offers a red apple to a boy. The boy, after a moment, takes the apple, then runs off through the crowd, chasing after a woman in a white and purple dress."
        }
    ],
    "short_063": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. List of characters:\n1. Girl with black hair tied in a bun\n2. Monster with red hair\n3. Hooded figure\nJSON objects:\n- Girl with black hair tied in a bun:\n{\n\"main action\": \"running on the beach, standing on a rock, looking angry\"\n}\n- Monster with red hair:\n{\n\"main action\": \"splashing out of the water, floating in the water, looking scared\"\n}\n- Hooded figure:\n{\n\"main action\": \"appearing, standing in the water\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, I'll get right to it. Here is the interactive script for the provided video:\n\nHere is a beach showdown, and tensions rise. A small, determined character confronts a monstrous, green ogre, who has the little child caught in its slimy grip. Suddenly, out of the sky, appears a figure in white clothing, which is sure to change the odds. Can the hooded figure help the little girl take down the monster? This is what happens:\n\n- A character with a hooded cloak is revealed to fight the green ogre.\n- The child is captured by a creature, making her the ogre's hostage."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n\"primary_tag\": [\"battle\"],\n\"secondary_tags\": [\"action\", \"adventure\", \"animation\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome to this beach scene! The confrontation between the Monster and the Hooded Figure is like a storm brewing on the horizon, with tension building as they face off. The Monster, with its menacing presence, and the Hooded Figure, shrouded in mystery, create a dynamic clash of forces.\nThe firm child stands determined, like a rock in the tide, unyielding and resolute. With a fierce expression and a stance that commands attention, the child is a symbol of strength and courage in the face of adversity."
        }
    ],
    "short_064": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"person\": {\n        \"attire\": \"dark\",\n        \"actions\": [\"folding\", \"throwing\"]\n    },\n    \"paper_boat\": {\n        \"color\": \"white\",\n        \"quantity\": 10\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I sit cross - legged on the floor, folding paper boats one by one. Each fold feels like a *gentle* promise, and as I toss them onto the wooden planks, the room fills with these little vessels of hope. My hands move *automatically*, creating more and more boats, until the floor is dotted with them, each one a tiny dream.\n\nThen, the scene shifts. I'm in a forest, the air thick with *autumnal* hues. I hold a paper boat, and as I release it, it floats up, joining countless others. The sky fills with these white paper boats, dancing in the breeze. It's **magical**, like all my folded dreams have taken flight, painting the sky with possibilities."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"00:00|fold paper into boat|1\", \"00:02|throw paper boat|2\", \"00:04|fold paper into boat|3\", \"00:06|throw paper boat|4\", \"00:08|fold paper into boat|5\", \"00:10|throw paper boat|6\", \"00:12|fold paper into boat|7\", \"00:14|throw paper boat|8\", \"00:16|fold paper into boat|9\", \"00:18|throw paper boat|10\", \"00:20|fold paper into boat|11\", \"00:22|throw paper boat|12\", \"00:24|fold paper into boat|13\", \"00:26|throw paper boat|14\", \"00:28|fold paper into boat|15\", \"00:30|throw paper boat|16\", \"00:32|fold paper into boat|17\", \"00:34|throw paper boat|18\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome to this serene forest! See the paper boats floating like autumn leaves caught in a gentle breeze. The person folding and releasing them seems contemplative, finding calm in this quiet ritual—their mood peaceful, as if sharing secrets with the woods."
        }
    ],
    "short_065": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Shape (head/body): Round/round, Color: Gray and white, Expression: Happy, Personality: Cheerful\n2. Shape (head/body): Round/round with a light bulb on the back, Color: Gray and white, Expression: Neutral, Personality: Curious\n3. Shape (head/body): Round/round with a more industrial look, Color: Gray and white, Expression: Sad, Personality: Lonely"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Today, I Watched The Other Robots March With Their Bright Bulbs, Their Metal Joints Clinking Rhythmically. I Heard The Faint Whir Of Gears Turning And The Soft Thud Of Their Feet On The Ground. I Felt A Twinge Of Longing As I Stood In The Shadows, My Rusty Frame Creaking With Each Step I Took To Follow Them. I Wonder If I’ll Ever Shine Like They Do, Or If I’m Forever Doomed To Be The Dim One In The Back. ---End---"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"walk\", \"robot\", \"industrial\", \"mechanical\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Robots march forward in a line; one robot at the front smiles widely, then a robot at the back smiles and jumps. A robot with a light bulb on its back runs forward, the bulb lights up, and other robots follow. A small robot with a dull expression stands in a doorway, looking sad as other robots pass by. Two robots chat happily, then the robot with the light bulb on its back lights up and flies forward. Stay tuned for more!"
        }
    ],
    "short_066": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"dog\": {\n    \"attributes\": [\n      \"long\",\n      \"animated\"\n    ],\n    \"actions\": [\n      \"standing\"\n    ]\n  },\n  \"chicken\": {\n    \"attributes\": [\n      \"brown\",\n      \"animated\"\n    ],\n    \"actions\": [\n      \"standing\"\n    ]\n  },\n  \"chicks\": {\n    \"attributes\": [\n      \"yellow\",\n      \"animated\"\n    ],\n    \"actions\": [\n      \"standing\"\n    ]\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. {\n    \"shot_scale\": \"Medium\",\n    \"camera_movement\": \"Static\",\n    \"narrative\": \"A brown dog with a red hat stands by a stream in a forest, then drinks from the stream.\"\n  }\n2. {\n    \"shot_scale\": \"Medium\",\n    \"camera_movement\": \"Static\",\n    \"narrative\": \"A hen and two chicks approach the stream from the right, and the dog interacts with them.\"\n  }\n3. {\n    \"shot_scale\": \"Medium\",\n    \"camera_movement\": \"Static\",\n    \"narrative\": \"The dog stretches its body across the stream, allowing the hen and chicks to cross over it, then the hen and chicks walk away to the left.\"\n  }"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "\n{\n  \"primary_tag\": \"dog helps cross\",\n  \"secondary_tags\": [\"forest stream\", \"stretch body\", \"hat - wearing dog\"]\n}\n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome to our forest stream! Take a moment to enjoy the **sparkling blue stream** that winds its way through the trees. Here, we see an elongated orange dachshund wearing a hat, looking as long as a licorice whip. \n\nNearby, a hen stands with her two chicks, gazing at the dog, her crest twitching with curiosity. It seems that the dog's peculiar shape, or the stream, might soon be of some concern to the chicken. It is possible that the chicken is going to try crossing this stream with her chicks. Let's watch closely; I have a feeling she's going to be our next main character."
        }
    ],
    "short_067": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Color | Action/State |\n| --- | --- | --- |\n| Main Man | Light brown (clothing) | Walking, smoking |\n| Truck | White with orange logo | Parked |\n| House | Red and green (exterior) | Having items unloaded in front |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here is the interactive script:\n\n1. A moving crew begins delivering to a house with an ornate front porch.\n\n- Box movement\n If you choose to focus on the movers taking boxes into the house, describe the colors and sizes of the boxes, and whether they use dollies or carry them.\n If you choose to focus on the movers carrying the boxes, explain how many are involved, their methods, and obstacles.\n- House approach\n If you choose to analyze the building, describe its architecture and unique decorations.\n If you choose to focus on the house’s layout, explain its dimensions and unique features."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"mover\",\"unload\",\"house\",\"truck\",\"sunny\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Main man's view: He smokes while walking toward a house, observing movers carrying boxes. He moves past them as they work.\nMover 1's view: Focused on carrying a box with another mover, navigating toward the house, ensuring steady movement."
        }
    ],
    "short_068": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"interviewer\": {\n        \"attributes\": {\n            \"clothing_color\": \"light beige\",\n            \"held_items\": \"microphone, phone\"\n        }\n    },\n    \"interviewees\": [\n        {\n            \"id\": 1,\n            \"attributes\": {\n                \"clothing\": \"black shirt, patterned pants\",\n                \"held_object\": \"yellow can, black crossbody bag\"\n            },\n            \"question\": \"make up two decades?\",\n            \"response\": \"January. February. March. April. May. June. July.\",\n            \"interaction_duration\": \"0-8\"\n        },\n        {\n            \"id\": 2,\n            \"attributes\": {\n                \"clothing\": \"black 'Houston 34' shirt, light pants\",\n                \"held_object\": \"red cup with straw\"\n            },\n            \"question\": \"What does 20 squared equal to?\",\n            \"response\": \"20 Squared is 400\",\n            \"interaction_duration\": \"8-12\"\n        },\n        {\n            \"id\": 3,\n            \"attributes\": {\n                \"clothing\": \"white shirt, white pants\",\n                \"held_object\": \"\"\n            },\n            \"question\": \"What is the square root of 400?\",\n            \"response\": \"That means it's like uh, it's got the square root symbol. It's not an actual number.\",\n            \"interaction_duration\": \"12-17\"\n        },\n        {\n            \"id\": 4,\n            \"attributes\": {\n                \"clothing\": \"black shirt, patterned pants\",\n                \"held_object\": \"yellow can, black crossbody bag\"\n            },\n            \"question\": \"In Roman numerals, how is the number 20 written?\",\n            \"response\": \"We first get the zero and the two backwards. Like upside down.\",\n            \"interaction_duration\": \"17-23\"\n        }\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the video content described in a storyboard script.\n\nShot 1:\n00:00 to 00:02. \nnarrative_description: A man in sunglasses being interviewed asks a question to another man with a microphone while holding a can.\nShot 2:\n00:08 to 00:15. \nnarrative_description: A man with curly hair is being interviewed, answering questions on the stage platform. \n\nEnd of storyboard\n\nThe number of questions get wrong answer: 2"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Here are the bounding box detections:\n```json\n[\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 453, 1000, 659], \"label\": \"activity\"},\n  {\"box_2d\": [138, 499, 424, 552], \"label\": \"key object\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [0, 340, 643, 659], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 745, 507, 890], \"label\": \"background setting\"},\n  {\"box_2d\": [6, 408, 369, 488], \"label\": \"background setting\"}\n]\n```json\n```json\n[\n  {\"activity\": \"interview\"},\n  {\"key object\": \"microphone\"},\n  {\"main question type\": \"mathematical\"},\n  {\"background setting\": \"outdoor\"},\n  {\"emotional tone\": \"conversational\"}\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From Interviewee 1's perspective: I'm outdoors, holding a drink, answering the interviewer's questions. People walk by in the background as I talk about months and Roman numerals, gesturing to explain.  \n\nFrom Interviewee 2's perspective: I'm in a busy outdoor area, responding to the interviewer. Others walk around behind me. I discuss math concepts like square roots, using hand movements to clarify my points."
        }
    ],
    "short_069": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"pre_cave_actions\": [\"pointing at the colorful object\", \"picking up the colorful object\"],\n    \"cave_features\": [\"stalactites\", \"a glowing colorful object\"],\n    \"dragon_interaction\": \"The person interacts with a green dragon toy, which then flies and lands on their lap.\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I awoke from the glowing stone, the cave’s warmth wrapping around me. I stretched my wings, feeling the rough stone walls as I pushed outward. The cool air hit my scales as I soared, wind roaring in my ears. Spotting the figure below, I descended, heart pounding. Landing softly, my claws resting gently on their sweater."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"Lego dragon transformation magic show\",\n  \"secondary_tags\": [\n    \"fantasy themed\",\n    \"slow-motion\",\n    \"creative\"\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I was stoked finding that colorful object! Then the ground cracked, and a dragon popped up—total shock but awe too. Ended up bonding with that dragon, which was wild.\n\nThat human found my hidden object! I had to show up, protect my spot, but then we connected. Flying with them felt right—time to team up and have fun."
        }
    ],
    "short_070": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Celestial Body | External Color | Internal Core Description |\n|----------------|----------------|---------------------------|\n| Uranus         | Light blue     | Rock and ice core        |\n| Sun            | Orange/red     | Hot, glowing core         |\n| Jupiter        | Orange/brown   | Rock and ice core        |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I slice through Uranus, feeling its icy texture. Then, the Sun's fiery layers resist but yield, releasing intense heat. Jupiter's core, with crystals, sparkles as I cut, their facets catching light."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\n    \"body\": \"Uranus\",\n    \"start_time\": \"00:00\",\n    \"end_time\": \"00:04\"\n  },\n  {\n    \"body\": \"Sun\",\n    \"start_time\": \"00:06\",\n    \"end_time\": \"00:10\"\n  },\n  {\n    \"body\": \"Jupiter\",\n    \"start_time\": \"00:12\",\n    \"end_time\": \"00:15\"\n  }\n]\n```\n```json\n[\n  \"Sun\",\n  \"Uranus\",\n  \"Jupiter\"\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A hand slices three celestial models. First Uranus, showing blue layers and a core. Then the Sun, revealing fiery layers. Finally Jupiter, with brown layers and a core inside."
        }
    ],
    "short_071": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| State | Color | Container Used | Key Action |\n|-------|-------|----------------|------------|\n| Dry | Light green | Transparent plastic bottle | Opening the bottle |\n| Hydrated | Glowing green | Transparent plastic container | Pouring beads into container |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Shot 1: close-up, bottle with green beads, unscrew cap.\n2. Shot 2: close-up, bottle with green beads, pour beads into water.\n3. Shot 3: close-up, water with green beads, show expanded beads.\n4. Shot 4: close-up, gun magazine, fill with expanded beads.\n5. Shot 5: close-up, gun, attach magazine and fire at targets."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"toygun\",\"shoot\",\"indoor\",\"powerful\",\"realistic\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The person pours beads into water, waits for them to expand, loads the expanded beads into a gun's magazine, attaches the magazine to the gun, and then tests the gun by firing at targets."
        }
    ],
    "short_072": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Year | Color | Body Style | Background Setting |\n|------|-------|------------|--------------------|\n| 1908 | Black with gold accents | Open-top | Cobblestone street with brick buildings |\n| 1950 | Teal | Sedan | Suburban neighborhood |\n| 2000 | White | Sedan | Urban street with buildings |\n| 2050 | Silver with green accents | Futuristic enclosed | Urban tunnel with greenery |\n| 2100 | Orange with blue accents | Flying | Futuristic city with tall buildings and traffic |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Future Trends:\n```json\n[\n  {\n    \"trend\": \"Increased Aerodynamics\",\n    \"car_year\": 2150,\n    \"feature\": \"Full body airfoils\",\n    \"inspiration_decade\": \"2000s\",\n    \"function\": \"Direct airflow over and under the car to increase stability and decrease drag at high speeds.\"\n  },\n  {\n    \"trend\": \"Integrated Lighting\",\n    \"car_year\": 2150,\n    \"feature\": \"Adaptive LED matrix covering the vehicle body\",\n    \"inspiration_decade\": \"2020s\",\n    \"function\": \"Improve visibility, allow customized signaling, and enable dynamic lighting effects for communication and safety.\"\n  },\n  {\n    \"trend\": \"Vertical Takeoff and Landing (VTOL) Capability\",\n    \"car_year\": 2150,\n    \"feature\": \"Rotating turbine engines integrated into the car's body\",\n    \"inspiration_decade\": \"2070s\",\n    \"function\": \"Enable the car to take off and land vertically, allowing for air travel in dense urban environments where traditional runways are unavailable.\"\n  }\n]\n```\n\nIn reverse chronological order, the backgrounds transform from futuristic cityscapes with flying cars to lush tunnels with greenery, then to modern buildings, suburban streets, and ending with historic brick buildings. This illustrates the progression of transportation within our increasingly modernized environments."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"automotive timeline progression\",\n  \"secondary_tags\": [\"vintage to futuristic design\", \"setting transformation\", \"transport innovation\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Historian:\nThe evolution from 1908 to 1950 is a testament to technological advancement and aesthetic shifts. Early models prioritized function over form, with basic structures. By the 1930s, streamlining became popular, influenced by aviation and industrial design. Post-war, cars reflected optimism with rounded designs and vibrant colors, mirroring the era's economic boom and cultural expression.\n\nFuturist:\nFrom 2050 to 2100, cars transform into sleek, self-driving pods, showcasing a focus on sustainability and integration with smart cities. As technology advances, designs prioritize efficiency, connectivity, and environmental consciousness. By the end of the century, vehicles resemble airborne devices, addressing urban congestion with creative solutions."
        }
    ],
    "short_073": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Key Attributes | Actions Caused | Final Outcome |\n| --- | --- | --- | --- |\n| Stone Golem | Large, made of rocks, moss - covered | Jumps, pushes boulder, endures village attacks | Stops boulder from destroying village; village intact |\n| Mountain Village | Multi - story buildings, red roofs, defensive structures | Launches projectiles at golem | Some damage from attacks but not destroyed |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- camera movement: tracking shot follows the stone golem as it descends from the mountain\n- shot scale: wide shot shows the entire village with the golem preparing to attack, then shifts to close-up of the golem's face\n- editing transition: quick cut from the golem tossing boulders to the village, then to the golem pushing a large boulder down towards the village\nThe stone golem exhibits a solemn, determined mood, with a focused expression as it carries out its task. The village, initially bustling with activity, shows signs of panic and chaos as structures are destroyed by falling rocks and the approaching boulder. The fundamental reason for the village's final outcome is that the stone golem, driven by an unseen purpose—likely anger, protection, or a curse—has been activated to destroy the village, and its overwhelming power and deliberate actions lead to the village's destruction."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n    {\n        \"timestamp\": \"00:00\",\n        \"entity\": \"stone golem\",\n        \"interaction_desc\": \"The stone golem leaps off a cliff, descending towards a boulder.\"\n    },\n    {\n        \"timestamp\": \"00:05\",\n        \"entity\": \"stone golem\",\n        \"interaction_desc\": \"The stone golem grabs the boulder and begins to push it, causing parts of a nearby castle to collapse.\"\n    }\n]\nThe stone golem no longer blocks the boulder because it actively pushes the boulder forward. As the golem exerts force on the boulder, it dislodges it from its previous position. The momentum generated by the golem's push propels the boulder down the slope, away from the castle. The golem's strength and the dynamic motion of pushing overcome any friction or stability that previously held the boulder in place, allowing it to move freely."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Ladies and gentlemen, if you'll look to your left... A colossal stone golem, rugged and moss-clad, crouches atop the mountain peak. With a heave that shakes the earth, it dislodges a boulder—an immense mass that rolls like a thunderous avalanche down the slope. The boulder crashes through forests, its path a relentless tide of destruction, trees splintering like matchsticks in its wake. As it hurtles toward the village, the golem gives chase, its stone limbs grinding and groaning with each stride. The village, a cluster of timber and tile, scrambles to defend itself—catapults and ballistae launch a storm of projectiles, yet the golem presses on, undeterred. With a final, Herculean effort, the golem intercepts the boulder, diverting it into the sea where it crashes with a mighty splash, saving the village from ruin."
        }
    ],
    "short_074": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Character | Clothing (top/pants) | Room Wall Color | 3 Key Dance Moves | Outdoor Location |\n|-----------|----------------------|-----------------|-------------------|------------------|\n| Woman 1   | Red top/orange pants | Red             | Spinning, leaning back, high kick | Street with shops and fruit stands |\n| Woman 2   | Light blue crochet top/blue patterned pants | Teal            | Spinning, bending forward, jumping | Street with diners and bicycles |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the JSON array of the described scenes.\n```json\n[\n  {\n    \"shot_id\": 1,\n    \"camera_movement\": \"tracking\",\n    \"narrative_desc\": \"The woman, wearing orange pants and a red shirt, spins along the street as she continues to dance in the dark.\"\n  },\n  {\n    \"shot_id\": 2,\n    \"camera_movement\": \"tracking\",\n    \"narrative_desc\": \"In the dark the woman in orange pants, keeps twisting and turning in her unique dance style on the street.\"\n  },\n  {\n    \"shot_id\": 3,\n    \"camera_movement\": \"tracking\",\n    \"narrative_desc\": \"The woman, wearing orange pants, spins, and performs a backbend as she dances in the dark city to music.\"\n  }\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\":\"00:00\",\"object\":\"phone\",\"action\":\"holds phone in hands\"},{\"timestamp\":\"00:00\",\"object\":\"balloon\",\"action\":\"catches and plays with balloon\"},{\"timestamp\":\"00:00\",\"object\":\"car\",\"action\":\"leans against car door\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here is the video caption describing the activity:\n\n[00:00:01 to 00:00:06]\nThe woman with red shirt and yellow pants is walking out of the bed to start her day in a hurry. She stretches her upper body upwards and backward, then crouches down and leans over, reaching out to the screen with both hands, her hair flowing down.\n\nThe woman in a light blue sweater and blue patterned pants gets out of bed as well. She stretches her body up high and leans backwards to reach something above her. As she leans forward she can be seen touching the screen.\n\n[00:00:06 to 00:00:12]\nThe woman in red clothes runs down the street, her hair flying behind her. The shot is taken from the side. She passes by a shop with fruits and vegetables, and continues toward the restaurant, as she continues to run toward her destination.\n\nThe woman in blue pants runs down the street towards a building that says 'Jordan North's DINER'. The camera is overhead and follows as she runs. People are sitting at tables enjoying their meals, not knowing what surprises are to come.\n\n[00:00:12 to 00:00:18]\nThe woman with a red shirt starts dancing on the streets as she spins her body. The people seating on the table inside the restaurant stare at her with a big smile. She is so happy and excited and showing off her skills.\n\nThe woman in a light blue sweater is also dancing on the street, as she twists and turns while the camera follows her. You can see people sitting at a table looking at her, as the woman dances towards a streetlight.\n\n[00:00:18 to 00:00:24]\nAs the woman wearing red keeps dancing, she finds a red ballon and starts to dance with it. It seems like everything is so exciting and wonderful. The woman has a smile on her face the entire time.\n\nThe other woman in blue stops to take a rose that an older man with a gray suit is handing to her. She is smiling. The woman takes it and proceeds to dance around the street. \n\n[00:00:24 to 00:00:30]\nAs the red shirt woman dancing around, she suddenly grabs the hood of a yellow cab and jumps in. She tries to pull it down with her hair flowing down. She makes the cab stop to jump in.\n\nThe woman in blue patterned pants is dancing on the street and spots a yellow car, she stops to put her hands on it, trying to do a handstand. The car starts driving and the woman grabs on tightly to the car.\n\n[00:00:30 to 00:00:36]\nThe woman jumps off the car and dances in the streets. She twirls around and moves her arms to the beat of the music. She enjoys the streets as she spins her body to the song.\n\nThe woman in blue twirls on the street with the cars moving on. She is enjoying herself in the streets as people pass by. The girl is making the moment her runway as the music blasts on.\n\n[00:00:36 to 00:00:41]\nShe keeps dancing in the streets as she sees a red phone booth and tries to do a handstand. The streets are filled with music and laughter as she moves her body to the song. This is the moment the dancer lives for.\n\nThe last part of the video shows the woman doing a handstand in the streets in front of a travel agency. It looks like the girl is putting her last moves in as she wraps it up. She smiles on the road to the journey that is to come.\n"
        }
    ],
    "short_075": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"person_1\": {\n        \"clothing\": \"dark jacket\",\n        \"activity_area\": \"window\"\n    },\n    \"person_2\": {\n        \"clothing\": \"light-colored shirt\",\n        \"activity_area\": \"server_rack\"\n    },\n    \"person_3\": {\n        \"clothing\": \"dark clothing\",\n        \"activity_area\": \"wall\"\n    },\n    \"person_4\": {\n        \"clothing\": \"light-colored shirt\",\n        \"activity_area\": \"table\"\n    },\n    \"person_5\": {\n        \"clothing\": \"dark jacket\",\n        \"activity_area\": \"server_rack\"\n    },\n    \"person_6\": {\n        \"clothing\": \"light-colored shirt\",\n        \"activity_area\": \"wall\"\n    },\n    \"person_7\": {\n        \"clothing\": \"dark clothing\",\n        \"activity_area\": \"desk\"\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n[\n  {\n    \"shot_id\": 1,\n    \"shot_content\": \"A man in a dark jacket is at a glass window, writing a math formula with a marker. The background shows a city skyline under a foggy, overcast sky. Another man in a white shirt is visible beside a large monitor showing computer code and diagrams. He is standing next to computer equipment.\",\n    \"camera_focus\": \"Man writing on window\"\n  },\n  {\n    \"shot_id\": 2,\n    \"shot_content\": \"The room is shown from a wider angle. The man in the white shirt moves towards computer racks, interacting with them. The monitor displays diagrams related to planning ability, while the man at the window continues writing. The setting includes a chair and various objects on a small table.\",\n    \"camera_focus\": \"Man interacting with computer racks\"\n  },\n  {\n    \"shot_id\": 3,\n    \"shot_content\": \"The scene expands further, revealing a lounge area with a sofa, lamp, and whiteboards covered in notes and formulas. Two men are visible in the room—one standing in front of a desk, and the other moving towards a table.\",\n    \"camera_focus\": \"Room with men at desk and table\"\n  },\n  {\n    \"shot_id\": 4,\n    \"shot_content\": \"The room continues to be visible with changes of the actors in it. A man moves towards a table filled with papers and a laptop, examining the contents. Another man picks up a framed picture and carries it to a nearby wall.\",\n    \"camera_focus\": \"Man at the table and man carrying framed picture\"\n  },\n  {\n    \"shot_id\": 5,\n    \"shot_content\": \"The focus shifts again with changes in actors. A man walks through a room carrying a clear container on a wheeled platform, heading towards an elevator. He passes by a shelf with various objects and a cluttered kitchen counter.\",\n    \"camera_focus\": \"Man moving container on wheeled platform\"\n  },\n  {\n    \"shot_id\": 6,\n    \"shot_content\": \"A wall is shown with formulas on it in the setting of a cluttered room. A man writes equations on a wall covered in equations and notes, surrounded by a desk, piano, couch and computer racks.\",\n    \"camera_focus\": \"Man writing equations on wall\"\n  },\n  {\n    \"shot_id\": 7,\n    \"shot_content\": \"The focus shifts to the whole room again, with papers scattered, cluttered objects, and multiple men working on different tasks. The camera captures the room's disarray, from the large monitor showing code to the wall full of papers and the cart with computer servers.\",\n    \"camera_focus\": \"Entire cluttered room with men working\"\n  },\n  {\n    \"shot_id\": 8,\n    \"shot_content\": \"An exterior shot of the Beijing Space Center, showing its architecture under a grey, snowy sky. The center's logo and name are prominently displayed on the building's facade.\",\n    \"camera_focus\": \"Beijing Space Center exterior\"\n  }\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"room\", \"serious\", \"intense\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In a dimly lit lab, a man writes equations on a window while another adjusts equipment; others organize items and work on different tasks."
        }
    ],
    "short_076": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Person_ID | Clothing | Key Actions | Interactions |\n|-----------|----------|-------------|--------------|\n| 1 | dark clothing | operates camera, moves around | works with others in the room |\n| 2 | light clothing | moves furniture, adjusts items | interacts with multiple people |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Script: A split - screen shows a chaotic room (left) and a woman in a cluttered room (right). TV plays in the background.\n- Turning point 1: Woman moves table\n  - If you choose to *help move the table*, then *the room feels more organized, and she thanks you, building trust*.\n  - If you choose to *ignore the table*, then *she struggles alone, frustration grows, and distance forms*.\n- Turning point 2: Group enters chaotic room\n  - If you choose to *join the group*, then *energy rises, tasks get done fast, and you feel included*.\n  - If you choose to *observe the group*, then *you analyze dynamics, stay neutral, but miss bonding*.\n\n| Choice | Emotional Impact |\n| --- | --- |\n| Help move table | Positive (connection, relief) |\n| Ignore table | Negative (isolation, tension) |\n| Join group | Positive (camaraderie, purpose) |\n| Observe group | Neutral (detachment, awareness) |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n    {\n        \"timestamp\": \"00:02\",\n        \"person_id\": 1,\n        \"interaction_desc\": \"using phone\"\n    },\n    {\n        \"timestamp\": \"00:05\",\n        \"person_id\": 2,\n        \"interaction_desc\": \"eating food\"\n    },\n    {\n        \"timestamp\": \"00:15\",\n        \"person_id\": 3,\n        \"interaction_desc\": \"eating food\"\n    },\n    {\n        \"timestamp\": \"00:34\",\n        \"person_id\": 4,\n        \"interaction_desc\": \"using phone\"\n    }\n]\"\n        \"person_id\": 2,\n        \"interaction_desc\": \"eating food\"\n    },\n    {\n        \"timestamp\": \"00:15\",\n        \"person_id\": 3,\n        \"interaction_desc\": \"eating food\"\n    },\n    {\n        \"timestamp\": \"00:34\",\n        \"person_id\": 4,\n        \"interaction_desc\": \"using phone\"\n    }\n]\"\n    },\n    {\n        \"timestamp\": \"00:34\",\n        \"person_id\": 4,\n        \"interaction_desc\": \"using phone\"\n    }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Woman sits at table.\n2. TV shows man talking.\n3. Woman moves items on table.\n4. Room becomes empty."
        }
    ],
    "short_077": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. \n1. Outdoor street near buildings\n2. Bus interior\n3. Area near the \"Seahaven\" archway\n\nB. \n1. Outdoor street near buildings:\n{\n  \"entities\": [\"man in brown jacket\", \"man in checkered suit\", \"woman in maroon outfit\", \"other pedestrians\", \"security personnel\"],\n  \"dominant_action\": \"confrontation and pursuit\"\n}\n2. Bus interior:\n{\n  \"entities\": [\"man in brown jacket\", \"bus passengers\", \"security personnel\"],\n  \"dominant_action\": \"restraint and attempt to stop\"\n}\n3. Area near the \"Seahaven\" archway:\n{\n  \"entities\": [\"man in checkered suit\", \"taxi driver\", \"pedestrians\", \"dog\"],\n  \"dominant_action\": \"waiting and observing\"\n}\n\nThe outdoor street near buildings has the highest activity level due to the confrontation, pursuit, and multiple interactions."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "When the Older Man grabbed me, I felt a jolt of surprise, my heart racing as confusion and concern mixed—though I pushed that aside, focusing on the urgency of the moment. As the runners rushed past, I felt a surge of frustration and determination, my mind set on pushing through the chaos to reach what mattered. When the bus departed, a wave of helplessness washed over me, my chest tight with the weight of missed opportunity, yet I clung to the hope of catching up somehow."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"man\", \"run\", \"street\", \"surprised\", \"busy\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. Runs towards the bus. 2. Clings to the bus door. 3. Stops and looks around. He appears frantic, shown by his rapid movements and determined facial expressions."
        }
    ],
    "short_078": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Character       | Clothing                                                                 | Primary Action                                                                 | Emotional State |\n|-----------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------------|-----------------|\n| Young Forrest   | Blue and white checkered shirt, brown shorts, leg braces, red boots     | Having leg braces adjusted, walking with assistance, interacting with others   | Neutral         |\n| Doctor          | White shirt, brown suspenders, bow tie, glasses                         | Adjusting leg braces, examining, conversing with Mrs. Gump                     | Neutral         |\n| Mrs. Gump       | Floral dress, hat with flowers, white gloves, carrying a wicker basket   | Holding Forrest's hand, conversing with the doctor, guiding Forrest outside    | Neutral         |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Scene: Medical Office. Forrest takes a few steps with leg braces, managing to walk without falling. **successful first steps**  \n- Continue walking: Forrest gains more confidence, taking longer strides as he moves across the room.  \n- Rest: Forrest sits down, catching his breath, while the doctor notes progress and discusses next steps with his mother."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  \"Forrest Gump\",\n  \"walking\",\n  \"doctor's office\",\n  \"leg braces\",\n  \"medical\"\n]\n```\nThe boy looks uncomfortable and upset while wearing leg braces in the doctor's office. The mother, despite the boy's physical challenges, maintains a composed and supportive demeanor, providing encouragement."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome to Forrest's world... Here, young Forrest gets leg braces. He walks *like a wooden puppet learning to move*, stiff yet determined. Mrs. Gump, by his side, shows tender care—guiding him, her actions brimming with hope and motherly love, believing these braces will help her son find his stride."
        }
    ],
    "short_079": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Color | Type | Scene Location |\n| --- | --- | --- |\n| Green | Car | Road |\n| Red | Car | Gas Station |\n| Blue | Car | Gas Station |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"shot_id\": 1,\n        \"shot_scale\": \"long\",\n        \"camera_movement\": \"tracking\",\n        \"narrative_desc\": \"Teal vintage car drives on road, **tracking** alongside.\",\n        \"inferred_emotion\": \"nostalgic\"\n    },\n    {\n        \"shot_id\": 2,\n        \"shot_scale\": \"medium\",\n        \"camera_movement\": \"still\",\n        \"narrative_desc\": \"People interact at outdoor picnic table; cars park nearby.\",\n        \"inferred_emotion\": \"casual\"\n    },\n    {\n        \"shot_id\": 3,\n        \"shot_scale\": \"medium\",\n        \"camera_movement\": \"still\",\n        \"narrative_desc\": \"Women converse indoors; one reads from paper, others listen.\",\n        \"inferred_emotion\": \"intimate\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\":\"00:00\",\"person_label\":\"P1\",\"interaction\":\"drive a blue vintage car\"},{\"timestamp\":\"approximate 00:00\",\"person_label\":\"P1\",\"interaction\":\"drive a blue vintage car\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome to our journey! Key visuals: 1. A teal vintage car driving on a road. 2. People gathered at a picnic table and indoors. 3. A woman reading a letter to a group. Sounds: car engine hum, laughter. The setting is as warm as a cozy blanket on a winter eve."
        }
    ],
    "short_080": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Clothing | Location (outdoor/indoor) | 1 Key Action |\n| --- | --- | --- | --- |\n| Man in black coat | Black coat, dark pants | Outdoor | Climbs out of basement |\n| Man in gray coat | Gray coat, black headgear | Indoor | Runs into plastic wrap |\n| Young boy | Red sweater | Indoor | Pulls string to activate fan |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Walk through plastic wrap on door  \n*Outcome: Head gets stuck (close - up)*  \n- Trip wire triggering feather explosion  \n*Outcome: Covered in feathers (long shot)*"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"burglar\", \"ice\", \"outdoor\", \"frozen\", \"slippery\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Video Summary: A burglar steps into a snow trap, struggles, then runs. He sees a window with a boy, shouts, and moves. Another burglar enters a house, hits plastic wrap, and gets covered in feathers from a fan trap. The boy sets traps, burglars show anger and frustration."
        }
    ],
    "short_081": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- Red\n- Green\n- Blue\n- Orange\n- Silver\n\n[\n  {\n    \"object\": \"window curtain\",\n    \"action\": \"pull\",\n    \"consequence\": \"curtain moves to reveal window\"\n  },\n  {\n    \"object\": \"window\",\n    \"action\": \"climb through\",\n    \"consequence\": \"enter the room\"\n  },\n  {\n    \"object\": \"ornaments on floor\",\n    \"action\": \"step on\",\n    \"consequence\": \"pain and reaction to stepping on ornaments\"\n  },\n  {\n    \"object\": \"footwear\",\n    \"action\": \"remove\",\n    \"consequence\": \"expose feet to walk on ornaments\"\n  }\n]\n\n| Man | Entry Method | Difficulty (1-5) |\n| --- | --- | --- |\n| A | Climb through window | 3 |\n| B | Not shown | N/A |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The man wears a dark coat and jeans. He goes from cautious to angry as he enters through a window, stepping on ornaments."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "00:02|window|open|10|00:15|ornaments|step on|10|00:20|chair|fall on|10"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man enters through a window, steps on a toy, and shouts in pain. Another man shakes off feathers and talks to the first man. The first man walks over and speaks."
        }
    ],
    "short_082": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Clothing/Appearance | Key Attribute |\n|--------|---------------------|---------------|\n| boy | Red sweater, green pants | Sets traps |\n| Man A | Dark coat, curly hair | Gets injured by traps |\n| Man B | Green coat, black headband | Gets injured by traps |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Don't worry, Marv. I'll get him for you.,You guys give up, or are you thirsty for more?,3"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"home alone pranks\",\n  \"secondary_tags\": [\"comedy\", \"family\", \"christmas\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Ladies and gentlemen, observe the chaos before you! A boy has set a clever snare like a hunter's trick—tiny toy cars scattered on the floor to trip the men. Look at the men: feathers stick to their coats, and their faces show frustration and rage as they stumble and fall, victims of the boy's traps. One man’s face is red with anger, another has feathers clinging to him, both seething with annoyance at being outwitted by a child’s schemes."
        }
    ],
    "short_083": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"bald_man\": {\n    \"clothing\": \"dark green coat\",\n    \"headwear\": \"black headband\"\n  },\n  \"curly_man\": {\n    \"clothing\": \"dark brown coat\",\n    \"headwear\": null\n  }\n}\n\n1. The boy runs down the hallway.\n2. The boy picks up a spider.\n3. The boy places the spider on the curly man's face.\n\nThe boy picks up a spider, runs, and places it on the curly man's face, startling him, then runs up the stairs."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Shot 1: *Tilt down* from ceiling to two men at bottom of stairs. Boy hides, men look up cautiously. Bald man flinches; backstory: childhood spider bite left him with fear.  \nShot 2: *Pan right* as men climb stairs. Boy runs down hallway with toy gun. Men glare, muttering about catching him.  \nShot 3: Men step on tripwire, bald man falls. Curly-haired man stumbles. Boy smirks, runs up stairs. Men shout, chasing.  \nShot 4: Spider crawls on banister. Boy notices, picks it up. Men unaware, bald man lies on floor. Boy sneaks spider toward curly-haired man’s face.  \nShot 5: Spider placed on curly-haired man’s nose. He screams, flailing. Bald man jolts as spider crawls on him. Boy runs upstairs, men scramble in panic."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "In a comedic scene, a young blond boy runs away from two burglars in a house. The burglars pursue him. While holding a toy gun, the boy places a tarantula on one of the burglar's faces. The burglar screams and flails. As the burglar lies on the floor screaming, the other burglar looks on in surprise. The scene is marked by a shift from tension to humor as the boy uses a tarantula to incapacitate the burglar."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the boy’s perspective: My heart raced as I spotted the spider. Adrenaline surged— I had to act fast. I grabbed it, my hands trembling, then slyly placed it on the bald man. Panic fueled my quick escape up the stairs.  \n\nFrom the bald man’s perspective: Terror ripped through me when I felt the spider. My body tensed, every muscle screaming. I thrashed, vision blurring with fear, desperate to fling it off. Dread clung to me long after it was gone."
        }
    ],
    "short_084": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Character | Clothing Details | Accessories | Key Action |\n| --- | --- | --- | --- |\n| Man | Black sweater, dark pants | White headphones, black bag | Enters elevator, listens to headphones, interacts with woman, removes headphones |\n| Woman | White short - sleeved shirt with black polka dots and black ruffle details | None | Enters elevator, stands beside man, converses with man, exits elevator |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. Medium shot, static, elevator doors open and a man with headphones enters, followed by a woman who enters the elevator later; they interact and the woman exits first.\n2. **Hard cut**, Medium shot, static, a perfume bottle is shown on a reflective surface.\n3. Extreme close-up, static, screen fades to black."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\":\"19:58\",\"speaker\":\"Woman\",\"content\":\"Vetiver?\"},{\"timestamp\":\"21:00\",\"speaker\":\"Man\",\"content\":\"Hey.\"},{\"timestamp\":\"27:58\",\"speaker\":\"Woman\",\"content\":\"You smell good.\"},{\"timestamp\":\"29:58\",\"speaker\":\"Man\",\"content\":\"I'm sorry?\"},{\"timestamp\":\"31:58\",\"speaker\":\"Woman\",\"content\":\"I love your perfume.\"},{\"timestamp\":\"34:00\",\"speaker\":\"Man\",\"content\":\"You like my perfume?\"},{\"timestamp\":\"36:00\",\"speaker\":\"Woman\",\"content\":\"I love it.\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "An elevator door opens. A man with headphones enters, followed by a woman. They talk about perfume. The woman exits, and the man stays. The video ends with a perfume bottle shown."
        }
    ],
    "short_085": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Character | Appearance (clothing/hair color) | Key Action |\n| --- | --- | --- |\n| Male | Red hair, red military - style uniform with gold accents | Kneels in front of the female, extends hand, holds the female's hand, dances with her, and speaks |\n| Female | Purple hair, white dress with long white gloves | Sits on a chair initially, then extends hand to the male, dances with him, and speaks |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "My dearest... As I sit, I see you approach in that striking red uniform, its gold accents gleaming. Candles flicker, casting a warm glow on the room, and I feel my heart flutter at your presence.  \n\nMy dearest... The air hums with music, soft and melodious, while laughter floats around us. Your voice, steady and kind, reaches me, and I imagine the joy in this moment, a respite from the world.  \n\nMy dearest... When your hand extends, I feel *nervous yet hopeful*. My gloved hand meets yours, and that touch sends a thrill through me, a mix of *anticipation and tenderness*. In that grasp, I find courage and a connection that quiets my doubts."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Dancing is not suitable for the guy, indicated by subtitle 14; they are friends; the fourth subtitle says 'we practiced, might as well dance'."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Ladies and gentlemen, if you'll look to your left... there, a young man in a regal red uniform kneels before a woman in a white gown, his hand extended like an invitation to a secret world. She lifts her gloved hand, delicate as a butterfly’s wing, and places it in his—their fingers intertwining like vines weaving together. As they rise, they step into a dance, moving as one, fluid and graceful, like flames dancing in tandem. He leads with confidence, she follows with elegance, their steps a silent conversation, a harmony of trust and connection. Around them, the room glows warm, candles flickering as if spellbound by their rhythm. It’s a dance of longing, of unspoken words, each twirl and dip a brushstroke in a masterpiece of shared breath and beating hearts."
        }
    ],
    "short_086": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Location   | Key Action Performed | Time of Day (day/night) |\n|------------|----------------------|-------------------------|\n| Bedroom    | Wake up and get up   | day                     |\n| Street     | Walk along street    | day                     |\n| Bus        | Sit on bus           | day                     |\n| Airport    | Wait in airport      | day                     |\n| Airplane   | Board and sit        | day                     |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. shot_scale: close-up; camera_movement: static; content description: A person lies on a bed with a black and white patterned pillow in a room with a green wall and tiled floor.\n2. shot_scale: medium; camera_movement: static; content description: The person sits up on the bed in the same room, with a white curtain, air conditioner, and various items in the background.\n3. shot_scale: close-up; camera_movement: static; content description: The person is outdoors in front of a building with stone and glass features, then the scene shifts to them walking on a street with palm trees and cars.\n4. shot_scale: medium; camera_movement: static; content description: The person is inside a bus or train with brown seats, then the scene shifts to various locations including an airport, a train, and a street with a red torii gate, interacting with another individual and finally lying back on the bed."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"travel vlog\",\n  \"secondary_tags\": [\"lifestyle\", \"adventure\", \"personal journey\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A person wakes up, travels through a street, bus, airport, and airplane, then has a brief interaction on a city street at night before returning home."
        }
    ],
    "short_087": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. 1. Scene with two actors in motion capture suits dancing and interacting with others.\n2. Scene with multiple actors in motion capture suits performing group activities like sitting, skating, and combat.\n3. Scene with actors in motion capture suits around a table and one actor being pushed by others.\n\nB. 1. {\n  \"actors\": [\"green markers\", \"blue markers\"],\n  \"equipment\": [\"motion capture suits\", \"camera equipment\", \"tripods\"]\n}\n2. {\n  \"actors\": [\"green markers\", \"blue markers\", \"red markers\", \"orange markers\"],\n  \"equipment\": [\"motion capture suits\", \"skates\", \"weapons props\", \"tables\", \"chairs\"]\n}\n3. {\n  \"actors\": [\"green markers\", \"blue markers\", \"red markers\", \"orange markers\"],\n  \"equipment\": [\"motion capture suits\", \"tables\", \"chairs\", \"props for interaction\"]\n}\n\nThe second scene had the most actor interactions as it involved multiple actors performing diverse group activities like skating, combat, and group sitting, indicating more interactions compared to the others."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        'shot_scale': 'Close-up',\n        'camera_movement': 'Pan',\n        'narrative_desc': 'Woman in medieval dress spins, scene shifts to 3D model.',\n        'inferred_emotion': 'Joyful'\n    },\n    {\n        'shot_scale': 'Medium',\n        'camera_movement': 'Dolly',\n        'narrative_desc': 'Man in motion capture suit raises arm, 3D knight reacts.',\n        'inferred_emotion': 'Determined'\n    },\n    {\n        'shot_scale': 'Close-up',\n        'camera_movement': 'Pan',\n        'narrative_desc': 'Woman holds man\\'s face, scene shifts to motion capture.',\n        'inferred_emotion': 'Affectionate'\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"actor\",\"motion capture\",\"studio\",\"medieval\",\"action-packed\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "In the red marker suit, I danced and acted with others, feeling energized as we moved. Scenes shifted from medieval settings to the studio, blending digital and real, and I enjoyed the creative flow.\n\nIn the blue marker suit, I engaged in dynamic actions—fighting, riding, and interacting. The mix of motion capture and live acting was thrilling, and camaraderie with the team made each scene vibrant."
        }
    ],
    "short_088": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. \n1. Outdoor area near the store  \n2. Inside the 7 - Eleven store  \n\n{\n  \"motorcycle\": \"unknown\",\n  \"street lights\": \"white\"\n}\n\n{\n  \"hot dog roller\": \"silver\",\n  \"food trays\": \"white and red\",\n  \"condiment packets\": \"various\"\n}\n\nThe person rides a motorcycle to the 7 - Eleven, enters, prepares a hot dog with condiments, eats it, and then leaves."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "After my 12 - hour shift, I went to the store for dinner, feeling so lonely. When I saw the hot dog roller empty, disappointment washed over me; I’d been looking forward to that simple comfort. But as I ate my improvised meal, a strange mix of resignation and quiet contentment settled in—lonely, yet grateful for the little things that filled my stomach."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"buy food\",\"convenience store\",\"food\",\"lonely\",\"night\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the customer’s view, the loneliness of a long shift fades into the routine of assembling a hot dog—selecting toppings, sauces, and condiments, each step a small, solitary act of self-care. The quiet store and the focus on crafting a meal become a brief reprieve, though solitude lingers.  \n\nFrom the cashier’s view, the interaction is routine yet human: observing the customer’s hot dog assembly, exchanging a few words, and ensuring the transaction is smooth. The small exchange, even during a late shift, connects two people in the quiet store, highlighting the subtle warmth of daily interactions."
        }
    ],
    "short_089": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. Indoor scene with laptop and table items  \nB. Outdoor night scenes with vehicles and city lights  \n\n[\n{\n  \"timestamp\": \"00:00\",\n  \"participants\": [\"person\"],\n  \"action_desc\": \"close laptop\"\n},\n{\n  \"timestamp\": \"00:03\",\n  \"participants\": [\"person\"],\n  \"action_desc\": \"pick up helmet from windowsill\"\n},\n{\n  \"timestamp\": \"25:00\",\n  \"participants\": [\"motorcycle rider\", \"car passenger\"],\n  \"action_desc\": \"pass an item from motorcycle to car\"\n},\n{\n  \"timestamp\": \"31:00\",\n  \"participants\": [\"person\"],\n  \"action_desc\": \"press car interior light button\"\n},\n{\n  \"timestamp\": \"51:00\",\n  \"participants\": [\"person\"],\n  \"action_desc\": \"open laptop\"\n}\n]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I speed through the tunnel, seeing yellow lights flash by, then pull up next to the black SUV; I hear my engine roar and the wind whip past as I hand over the **small, dark-colored package** to the person in the car."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"drive\",\"hotel\",\"fast\",\"dark\",\"smooth\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I’m driving through the tunnel, lights flashing by. Then the biker pulls up, hands over the package. I take it, stow it, and we keep going—smooth, quick, just like we planned.\n\nFrom the passenger seat, I see the biker ride up. I lean out, grab the package he hands over. Quick exchange, then we stash it. Easy, like we’ve done this a million times."
        }
    ],
    "short_090": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"character\": {\n        \"appearance\": [\"dark clothing\", \"armor\", \"bearded\"],\n        \"actions\": [\"fighting\", \"sword swinging\", \"engaging in battle\"]\n    },\n    \"horses\": [\n        {\n            \"color\": \"white\",\n            \"state\": \"galloping\"\n        },\n        {\n            \"color\": \"brown\",\n            \"state\": \"galloping\"\n        }\n    ],\n    \"battle_elements\": [\"smoke\", \"fallen soldiers\"]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"shot_scale\": \"medium\",\n        \"description\": \"A horse gallops, then the scene shifts to a man running through a battlefield, engaging in combat with multiple opponents using a sword\",\n        \"emotion_tone\": \"intense\"\n    },\n    {\n        \"shot_scale\": \"medium\",\n        \"description\": \"The man continues fighting, encountering various enemies, including those on horseback, and struggles amidst the chaos of the battle\",\n        \"emotion_tone\": \"fierce\"\n    },\n    {\n        \"shot_scale\": \"medium\",\n        \"description\": \"The man keeps fighting, with arrows flying around, and he faces more enemies, showing determination and resilience in the midst of the violent battle\",\n        \"emotion_tone\": \"determined\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary\": \"character in battlefield\",\n  \"secondary\": [\"determined\", \"ferocious\", \"sword\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The central character fights fiercely, swinging a sword, dodging attacks, and taking down enemies. He moves through the battlefield, focused on combat, with determination in every strike.  \n\n2. The enemy soldier trembles, eyes wide with fear as chaos erupts. He fears the central character’s relentless attacks while arrows and horses blur his vision.  \n\nWhile the central character feels unyielding determination, the enemy soldier is paralyzed by fear."
        }
    ],
    "short_091": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Attire | Weapon | Key Actions (max 2) | Outcome |\n|--------|--------|---------------------|---------|\n| dark clothing | handgun | grapple underwater, shoot underwater | one fighter surfaces, other subdued |\n| dark clothing | handgun | grapple underwater, shoot underwater | one fighter surfaces, other subdued |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I lunged forward, gun in hand, as the assailant charged. We crashed into the water, pressure engulfing me. Underwater, I grappled, **twisting** their arm, **pressing** them against the pool wall. Bubbles erupted as I **fired**—the bullet’s force muffled. Then, surfacing, I faced another threat, ready. --Surface--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\n    \"timestamp\": \"00:04-00:05\",\n    \"person_id\": 2,\n    \"interaction\": \"grabs and punches Person 1's head\"\n  },\n  {\n    \"timestamp\": \"00:06-00:08\",\n    \"person_id\": 1,\n    \"interaction\": \"kicks Person 2, who then aims gun\"\n  },\n  {\n    \"timestamp\": \"00:09-00:12\",\n    \"person_id\": 2,\n    \"interaction\": \"shoots at Person 1, who evades and aims\"\n  },\n  {\n    \"timestamp\": \"00:17-00:22\",\n    \"person_id\": 2,\n    \"interaction\": \"delivers multiple punches to Person 1\"\n  }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Two fight over a gun; one pushes the other into a pool. Underwater, they grapple, with one gaining control, shooting the other, then surfacing as armed figures approach."
        }
    ],
    "short_092": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Key Attributes (3 items) | Actions/States |\n| --- | --- | --- |\n| Mech | Mechanical limbs, weapon装备, armored exterior | Flies, lands, runs, shoots, takes off |\n| Urban Environment | Dilapidated buildings, foggy atmosphere, ruined structures | desolate and foggy |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I survey the desolate skyline, fog clinging to shattered skyscrapers. Dilapidated structures loom, their broken forms stark against the hazy horizon. Dust drifts, settling on my armor as I scan for movement amid the ruins.  \n\nMy thrusters hum as I land, the whir of servos and clank of metal accompanying each step. Distant echoes—maybe debris shifting, maybe something else—keep me alert. The weight of silence is broken only by my own mechanical rhythms, a steady backdrop to the unease of this dead city.  \n\nResolve hardens in my circuits. Every joint, every sensor, is primed. I’m here to survive, to complete the mission. Fear? Irrelevant. Purpose drives me—through the fog, past the ruins, firing when threats emerge. This world is broken, but I stand, unyielding, ready to fight."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\"primary_tag\": \"mech urban combat\", \"secondary_tags\": [\"post - apocalyptic\", \"sci - fi\", \"action\"]}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I activated my thrusters to soar over the broken city, landed on a rooftop with a heavy thud, then stomped across the rubble. I knelt, aimed my railgun at distant targets, fired blazing shots, then boosted away into the haze.\n\nFog clung to the shattered skyscrapers as my metal boots crunched debris. Dust billowed where I landed, and the wind whistled through hollow building frames. Flames from my gun lit the gloom, echoing off the ruined walls as I vanished into the dust."
        }
    ],
    "short_093": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"villagers\": [\n        {\"clothing_color\": \"brown\", \"headwear\": \"hood\"},\n        {\"clothing_color\": \"green\", \"headwear\": \"hat\"},\n        {\"clothing_color\": \"white\", \"headwear\": \"none\"}\n    ],\n    \"creatures\": [\n        {\"color\": \"blue-green\", \"spikes\": true},\n        {\"fur_color\": \"gray\", \"attire\": \"brown clothing\"}\n    ],\n    \"setting\": \"village near a body of water with a stone arch formation in the background\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"shot_id\": 1,\n        \"camera_movement\": \"pan left\",\n        \"shot_scale\": \"medium\",\n        \"narrative\": \"Villagers gather around a large, struggling fish, with a cat-person observing.\"\n    },\n    {\n        \"shot_id\": 2,\n        \"camera_movement\": \"tilt up\",\n        \"shot_scale\": \"wide\",\n        \"narrative\": \"A man walks toward the dock, removing his outer garment, as onlookers watch.\"\n    },\n    {\n        \"shot_id\": 3,\n        \"camera_movement\": \"track forward\",\n        \"shot_scale\": \"close-up\",\n        \"narrative\": \"The man approaches the fish, calming it, while the cat-person looks on.\"\n    },\n    {\n        \"shot_id\": 4,\n        \"camera_movement\": \"pan right\",\n        \"shot_scale\": \"medium\",\n        \"narrative\": \"The man walks away from the dock, donning his garment, as villagers applaud.\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "The crowd's mood shifts from curiosity to relief and joy. The yellow - haired figure (not clearly shown) might be a bystander. The big fish, initially restrained, trusts the white - shirted person, shown by letting them take the creature from its mouth, indicating a shift to cooperation."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome, everyone! Look to your left—there’s that massive rock arch, like a giant's doorway framing the water! Now see the folks hauling that thrashing fish? It’s wriggling hard, but they’ve got it restrained. The crowd’s cheering, grinning from ear to ear—pure joy all around!"
        }
    ],
    "short_094": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"main_character\": \"Black man in brown coat\",\n    \"interactions\": [\n        {\"target\": \"Man in top hat\", \"action\": \"shoot\", \"timestamp\": \"00:02\"},\n        {\"target\": \"Man in gray suit\", \"action\": \"shoot\", \"timestamp\": \"00:04\"},\n        {\"target\": \"Maid in black and white uniform\", \"action\": \"shoot near\", \"timestamp\": \"00:05\"},\n        {\"target\": \"Man in gray suit at door\", \"action\": \"shoot\", \"timestamp\": \"00:07\"},\n        {\"target\": \"Man on staircase\", \"action\": \"shoot\", \"timestamp\": \"00:14\"},\n        {\"target\": \"Four men at door\", \"action\": \"shoot\", \"timestamp\": \"00:33\"}\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Shot List:\nA. shot_scale: close-up, camera_movement: static, content: A man looks intently forward.\nB. shot_scale: medium, camera_movement: pan left, content: The man moves, and the scene shifts to him grabbing a gun from another man's hand, then shooting.\nC. shot_scale: wide, camera_movement: dynamic, content: A chaotic gunfight ensues with multiple people involved, bullets flying, and characters reacting to the violence.\nEnd of Shots"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Total red crosses: 5. People numbered 1 - 4 (from left) have red crosses. Person 1: 2 crosses (chest, head). Person 2: 1 cross (chest). Person 3: 2 crosses (chest, head). Person 4: 1 cross (chest)."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I see the man in the brown coat. He looks determined, grabs a gun, and starts shooting at others. People around him fall. He moves quickly, takes cover, and keeps fighting.\n\nThe woman in uniform looks scared. She covers her ears as shots fire. People around her react to the gunfire. She seems overwhelmed by the chaos and violence."
        }
    ],
    "short_095": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Part Name       | Color | Function                          |\n|-----------------|-------|-----------------------------------|\n| Optic Sight     | Black | Aiming assistance                 |\n| Foregrip        | Black | Improve stability and control     |\n| Magazine        | Tan   | Hold ammunition                   |\n| Receiver        | Camouflage (Tan and Black) | Housing for internal components   |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"camera_angle\": \"first-person\",\n        \"action\": \"Raise the assault rifle, load the bullet, aim at the target in the distance, and fire continuously.\",\n        \"inferred_sound\": \"gunfire, bullet loading\"\n    },\n    {\n        \"camera_angle\": \"first-person\",\n        \"action\": \"Lower the assault rifle.\",\n        \"inferred_sound\": \"none\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "In the video, people fire 4 shots. There is 1 humanoid target located in the distance. Objects present in the setting include a camouflaged rifle, a scope, a magazine, leaves on the ground, trees, a tire swing, and a wooden structure."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Welcome to the shooting range! Today, we'll watch a precision drill. Here’s a rifle with a camouflage pattern like autumn leaves—earth tones blending with the fall foliage. Its sight is sharp as an eagle's eye, helping aim at distant targets. The shooter handles the rifle, adjusting grips, checking the magazine (loaded with bullets), and aiming at targets downrange. See the steady stance, the sight aligning with targets—tires and silhouettes. Shots fire, brass ejects, and the drill shows controlled, precise shooting—each round aimed with the sight’s keen focus, like an eagle locking on prey. The rifle’s camo melts into the leaf - strewn ground, while its sight cuts through distance, making each shot land true."
        }
    ],
    "short_096": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Coffee shop counter\n2. City street\n3. Subway train\n4. Hotel hallway\n\n{\n  \"emotion\": \"cheerful\",\n  \"evidence\": \"Pikachu is smiling while carrying the coffee bag\"\n}\n\nI got my coffee, hopped around the city, took the subway, and delivered it with a smile!"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Pikachu's Coffee Run  \nOne sunny day, Pikachu dashed into **Cotti Coffee**, snagged a steaming coffee bag, and bounded through the city—crossing streets, riding trains, and balancing on bridges. Finally, it delivered the bag to a cozy hotel. --End of Adventure--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Total scene switches: 11. Actions: waiting for coffee; running on street; waiting at crosswalk; running on bridge railing; taking subway; entering hotel; delivering coffee; working in coffee shop; dancing on beach."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Pikachu Is Yellow With Long Ears And A Lightning Bolt Tail. It Gets A Coffee From A Shop And Runs Through The City. It Travels By Train And Finally Reaches A Hotel.\n\nPikachu Seems Happy. Its Ears Wiggle And It Smiles Often. It Also Dances With Other Pikachus On The Beach, Which Shows It Is Joyful."
        }
    ],
    "short_097": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Color |\n|-------------|-------|\n| Dragon | Blue |\n| Flamingo | Pink |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n[\n  {\n    \"setting\": \"A vibrant, fantastical landscape with mountains, valleys, and open skies, initially viewed through a dark cave-like opening.\",\n    \"characters\": [\n      \"Blue dragon\",\n      \"smaller flying creatures\"\n    ],\n    \"conflict\": \"navigating dense forest\",\n    \"resolution\": \"The creatures are seen freely flying and interacting within their environment as the camera moves through the landscape.\"\n  },\n  {\n    \"setting\": \"A bright blue sky over a body of water, transitioning rapidly into a lush, dense forest with tall, green trees.\",\n    \"characters\": [\n      \"Red dragon\",\n      \"flamingos\"\n    ],\n    \"conflict\": \"competing for airspace\",\n    \"resolution\": \"The red dragon successfully flies past the flamingos and plunges into the dense forest.\"\n  }\n]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Four human-like figures are visible in the artwork: one on a distant cliff (0:02), two on a green peak (0:03-0:06), and one walking through a forest (0:15). The camera begins zoomed into a cave, then rapidly zooms out to unveil a sprawling landscape. It pans and zooms continuously, revealing diverse scenes like flying creatures, mountains, another cave, a flock of flamingos, and a dense forest, simulating a dynamic journey. Between 0:11 and 0:12, a large red dragon flies swiftly through a flock of flamingos, causing them to scatter."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Video Summary: A hand uses a stylus to draw on a tablet, creating scenes with a dragon, flamingos, and vibrant landscapes, showcasing dynamic digital art transitions. --End--"
        }
    ],
    "short_098": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A. Rooftop with Boxes and Planks  \nB. Adjacent Rooftop with Water Tank and Barrels  \n\n{\n  \"A\": {\n    \"objects\": [\"boxes\", \"planks\", \"buildings\", \"human_figure\"],\n    \"shadow_direction\": \"left-facing\"\n  },\n  \"B\": {\n    \"objects\": [\"water_tank\", \"barrels\", \"buildings\", \"human_figure\"],\n    \"shadow_direction\": \"left-facing\",\n    \"timestamp\": \"15:00\"\n  }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I traverse rooftops, passing **crates**, a **water tower**, and a **green plank bridge**. The cityscape of cardboard buildings looms around me, with shadows stretching across the paths.  \n\nMy steps thud softly on cardboard, crates shift with faint scrapes, and the plank bridge creaks underfoot. Wind whispers through the scene, carrying subtle rustles of cardboard structures.  \n\nDetermined, I press on, curious about what lies ahead. Each jump and climb fuels my resolve, turning uncertainty into focus as I navigate this whimsical, paper - crafted world."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Objects: crates, water tank. Ran left: 3 times. Ran right: 4 times."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I stand on a rooftop, surrounded by boxes. I jump across gaps, climb walls, and navigate around obstacles like a water tower, moving steadily through the cardboard city.\n\nThe scene is a cardboard-built urban area with rooftops, boxes, a water tower, and buildings with columns. A stick figure moves across these structures, jumping and climbing."
        }
    ],
    "short_099": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Static Attributes (2 max) | Key Actions (no more than 2) |\n|-------------|---------------------------|------------------------------|\n| Monkey      | Brown fur, uses joystick | Manipulates joystick, interacts with game |\n| Blue glowing character | N/A | Engages in combat, performs skills |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Today, I sat on the branch and looked at the bright screen. The colors on it were so vivid! My paws felt the smooth controller, and I moved them carefully. Then, a blue character appeared on the screen. It moved so fast, and I got excited, focusing hard to keep up with its actions."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\"primary_tag\": \"monkey plays game\", \"secondary_tags\": [\"whimsical\", \"RPG\", \"engaged\"]}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Ladies and gentlemen, observe the fascinating interaction: a monkey grips a controller, eyes locked on the screen like a scholar studying a book. The game’s most striking visual element, a **white wolf**, dances across the display as the monkey’s focus never wavers, manipulating inputs with surprising skill."
        }
    ],
    "short_100": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Name | Appearance Features | Key Action Performed |\n| --- | --- | --- |\n| The bearded man in white robe | Bearded, wears white robe with a red sash, brown sandals | Runs, kneels to comfort the calf, offers water, commands water to flow |\n| The white - and - brown calf | White with brown patches, appears weak | Stands weakly, drinks water |\n| The horned figure in red plaid shirt | Wears red plaid shirt, has horns, later seen with blue shorts | Receives a black case, looks surprised during the storm, loses the case contents |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "[\n    {\n        \"shot_id\": 1,\n        \"shot_scale\": \"Medium shot\",\n        \"camera_movement\": \"Static\",\n        \"narrative_description\": \"Bearded man in white robe runs in desert, stops near weak calf.\"\n    },\n    {\n        \"shot_id\": 2,\n        \"shot_scale\": \"Medium shot\",\n        \"camera_movement\": \"Static\",\n        \"narrative_description\": \"Man offers water to boy and calf, then they face a wealthy man.\"\n    },\n    {\n        \"shot_id\": 3,\n        \"shot_scale\": \"Long shot\",\n        \"camera_movement\": \"Static\",\n        \"narrative_description\": \"Storm comes, man prays, water flows, wealthy man regrets.\"\n    }\n]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "The bearded man runs through the desert, likely to reach something or someone in need. He then kneels beside a weak-looking calf, showing compassion and the intent to help the animal. Next, he stands protectively in front of the calf as a boy with a knife approaches, likely to shield the calf from harm. He later offers water from his pouch to the boy and the calf, addressing their thirst in the desert. When encountering a man with a horned hat who seems to hoard resources, the bearded man takes action, possibly to confront injustice or share resources, leading to a dramatic event where lightning strikes and water flows, suggesting a divine or transformative intervention to provide for the needy and correct imbalances."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The bearded man runs towards a weak calf and offers it water, then the desert landscape transforms into a fertile area with a river after he prays and lightning strikes."
        }
    ],
    "short_101": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Attributes |\n|-------------|------------|\n| Object | Book, red cover with text, opens to show illustrations and text. |\n| Scene | City street with buildings, transitions from book illustration to real - like setting. |\n| Person | Seated on balcony, reading and writing in a book, surrounded by stacks of books. |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "```json\n{\n  \"man_perspective\": \"The man is sitting on the balcony of a hotel in New Orleans, surrounded by books, engrossed in writing in his book.\",\n  \"book_thoughts\": [\n    \"The crisp pages are filled with my scribbles.\",\n    \"The balcony gives me the sense of flight.\",\n    \"I am both observer and recorder.\"\n  ]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n \"primary_tag\": \"Animated book to life scene\",\n \"secondary_tags\": \"Whimsical, Quaint, Nostalgic\"\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The camera opens to a book with a symbol, then reveals a painted illustration of a hotel in New Orleans. The camera zooms in to a man reading on the balcony, surrounded by stacks of books. The man is writing in a notebook, looking down thoughtfully, and appears to be contemplative."
        }
    ],
    "short_102": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, I understand. Here's the JSON output:\n```json\n{\n  \"scenes\": [\n    {\n      \"timestamp_range\": \"0-4s\",\n      \"entities\": {\n        \"**hummingbird**\": {\n          \"type\": \"bird\",\n          \"state\": \"flying\",\n          \"location\": \"near a plant\"\n        },\n        \"**plant**\": {\n          \"type\": \"flora\",\n          \"state\": \"silhouetted\",\n          \"location\": \"front of sunlight\"\n        }\n      },\n      \"events\": [\n        \"A hummingbird is feeding on a plant, silhouetted by the sun.\"\n      ]\n    },\n    {\n      \"timestamp_range\": \"4-30s\",\n      \"entities\": {\n        \"**storm clouds**\": {\n          \"type\": \"meteorological phenomena\",\n          \"state\": \"dark, heavy\",\n          \"location\": \"sky\"\n        },\n        \"**rain**\": {\n          \"type\": \"precipitation\",\n          \"state\": \"heavy\",\n          \"location\": \"falling from storm clouds\"\n        },\n        \"**ground**\": {\n          \"type\": \"land surface\",\n          \"state\": \"barren\",\n          \"location\": \"below the storm clouds\"\n        }\n      },\n      \"events\": [\n        \"Dark storm clouds gather.\",\n        \"Heavy rain falls on a barren landscape.\",\n        \"There is a cloudburst.\"\n      ]\n    },\n    {\n      \"timestamp_range\": \"30-50s\",\n      \"entities\": {\n        \"**floodwater**\": {\n          \"type\": \"natural element\",\n          \"state\": \"muddy\",\n          \"location\": \"flowing through a canyon\"\n        },\n        \"**canyon**\": {\n          \"type\": \"geological formation\",\n          \"state\": \"rocky\",\n          \"location\": \"desert\"\n        },\n        \"**desert**\": {\n          \"type\": \"land\",\n          \"state\": \"arid\",\n          \"location\": \"from a bird's eye view\"\n        }\n      },\n      \"events\": [\n        \"Muddy floodwater surges through a canyon.\",\n        \"An aerial view shows a desert landscape.\"\n      ],\n      \"transformation cause\": \"cloudburst, rain, and floodwater transform the desert.\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "### # Panel 1 (Hummingbird and Flower)\n**Tone**: Serene  \nA hummingbird hovers near a flower silhouetted against a bright sun; camera remains static, focusing on the bird’s wing movements and the flower’s shape. Subtitles appear briefly, stating *“But on very special occasions,”* adding context to the scene.  \n\n\n### # Panel 2 (Storm Clouds and Lightning)\n**Tone**: Dramatic  \nDark storm clouds move across the sky, with the camera panning slowly to capture their churning motion. A lightning bolt flashes (Dramatic Element: sudden light flash), illuminating the clouds. Subtitles read *“deserts are transformed,”* hinting at environmental change.  \n\n\n### # Panel 3 (Desert Flash Flood and Landscape)\n**Tone**: Powerful  \nMuddy water rushes over rocks in a desert flash flood, with the camera close - up to emphasize the water’s force. The scene shifts to an aerial view of the desert landscape, showing the terrain’s transformation. Subtitles state *“A single one can turn the desert green,”* highlighting the flood’s impact."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{'primary': 'desert transformation', 'secondary': ['arid climate', 'weather change', 'ecosystem shift']}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A hummingbird hovers near flowers backlit by the sun. Dark storm clouds gather, releasing heavy rain and lightning. The downpour causes a flood, with muddy water rushing over rocks, transforming the terrain.  \n\n**Natural transformation** is shown as the calm scene shifts to turbulent weather, then to a flood reshaping the landscape. The flooded terrain hints at renewal, as such events can nurture new life in arid regions."
        }
    ],
    "short_103": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"painter\": {\n    \"attributes\": [\n      \"white hair\",\n      \"yellow backpack\",\n      \"brown hat\",\n      \"blue top\",\n      \"painting\",\n      \"paintbrushes\"\n    ],\n    \"interactions\": []\n  },\n  \"armored character\": {\n    \"attributes\": [\n      \"black armor\",\n      \"glowing blue eyes\",\n      \"spear\"\n    ],\n    \"interactions\": []\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I stand here, brush in hand: The seaside stretches before me, palm trees swaying gently, and the sunset paints the sky in warm hues. As I paint, the calm sea, the tall palms, and the glowing sunset fill me with peace. Finishing, I feel satisfied, then turn and run along the beach, the sand beneath my feet, the ocean breeze on my face, carrying the joy of capturing this beauty.--End of View--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  {\"timestamp\": \"00:00\", \"character\": \"armored character\", \"action\": \"walking towards the painter from behind, with a sword on his back\"},\n  {\"timestamp\": \"00:11\", \"character\": \"armored character\", \"action\": \"running away from the painter along the beach with trees\"}\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1.  The painter holds a brush and appears to be dabbing at the canvas.\n2.  The painter moves back from the canvas to view their work.\n3.  The painter returns to the canvas to continue working.\n\nThe painter is likely motivated by the scenic beauty of the tropical landscape. The clear turquoise waters, palm-fringed beaches, and traditional structures in the distance provide ample inspiration for an artist."
        }
    ],
    "short_104": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"character\": {\n        \"attributes\": [\"blue and white attire\"],\n        \"dynamic_actions\": [\n            {\"timestamp\": 0.0, \"action\": \"build wooden fence\"},\n            {\"timestamp\": 1.0, \"action\": \"encounter crocodile\"},\n            {\"timestamp\": 2.0, \"action\": \"fight crocodile\"},\n            {\"timestamp\": 5.0, \"action\": \"harvest crocodile meat\"},\n            {\"timestamp\": 8.0, \"action\": \"cook meat at campfire\"},\n            {\"timestamp\": 12.0, \"action\": \"continue building fence\"},\n            {\"timestamp\": 15.0, \"action\": \"collect gold\"},\n            {\"timestamp\": 20.0, \"action\": \"construct building\"},\n            {\"timestamp\": 24.0, \"action\": \"mine gold ore\"},\n            {\"timestamp\": 37.0, \"action\": \"build bridge\"},\n            {\"timestamp\": 38.0, \"action\": \"combat enemy soldiers\"},\n            {\"timestamp\": 47.0, \"action\": \"game promotion display\"}\n        ]\n    },\n    \"crocodile\": {\n        \"attributes\": {\"size\": \"large\", \"color\": \"gray\"},\n        \"attack_events\": [{\"timestamp\": 1.0, \"damage\": \"hits fence, breaks part of it\"}]\n    },\n    \"resources\": [\n        {\"type\": \"wood\", \"quantity\": \"multiple\", \"location\": \"near water\"},\n        {\"type\": \"gold\", \"quantity\": \"multiple\", \"location\": \"water and land\"},\n        {\"type\": \"meat\", \"quantity\": \"multiple\", \"location\": \"near campfire\"},\n        {\"type\": \"gold ore\", \"quantity\": \"multiple\", \"location\": \"land area\"}\n    ]\n}"
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "A. List the 4 resources needed to build a dock:\n1. Wood\n2. Stone\n3. Rope\n4. Metal\n\nTo collect more yellow resources (gold) in the water:\n- Use a boat or a specialized gathering unit to navigate to the gold - laden areas.\n- Ensure the gathering unit has enough capacity to carry the gold back to the base.\n- Protect the gathering unit from any potential threats like crocodiles or enemy raiders while it is collecting the gold.\n\nWhen placing dock planks, start from the shoreline and extend outward piece by piece to ensure stability. Make sure each plank is properly aligned and secured. As a precaution to avoid crocodile attacks, clear the water around the construction area of crocodiles before starting to place the planks. You can do this by sending combat units to scare them away or by using traps. If possible, build a temporary barrier around the construction zone to keep crocodiles at bay during the building process."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  {\"timestamp\": 1, \"action\": \"The man attacks the alligator\", \"effect\": \"The man kills the alligator\"},\n  {\"timestamp\": 5, \"action\": \"The man take the meat from alligator\", \"effect\": \"The man get some meat\"},\n  {\"timestamp\": 7, \"action\": \"The man pile the meat on the campfire\", \"effect\": \"Meat on campfire\"},\n  {\"timestamp\": 9, \"action\": \"The man heal himself\", \"effect\": \"The man get healed\"},\n  {\"timestamp\": 15, \"action\": \"The man carry a golden brick\", \"effect\": \"The man carries golden brick\"},\n  {\"timestamp\": 19, \"action\": \"The man pile the golden brick\", \"effect\": \"Golden bricks are piled\"},\n  {\"timestamp\": 22, \"action\": \"The hand removes a piece of wood\", \"effect\": \"Remove a piece of wood\"},\n  {\"timestamp\": 24, \"action\": \"The man use a hammer and break the golden lump\", \"effect\": \"Get some golden bricks\"},\n  {\"timestamp\": 26, \"action\": \"The man carry a golden brick\", \"effect\": \"The man carries golden brick\"},\n  {\"timestamp\": 31, \"action\": \"The hand removes a piece of wood\", \"effect\": \"Remove a piece of wood\"},\n  {\"timestamp\": 33, \"action\": \"Build a house\", \"effect\": \"Build up a house\"},\n  {\"timestamp\": 36, \"action\": \"Build a bridge\", \"effect\": \"Build up a bridge\"},\n  {\"timestamp\": 41, \"action\": \"War\", \"effect\": \"War\"}\n]"
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "## Scene 1: Fence Building\nThe man is building a fence with logs along the river. The man stops because a crocodile swims up to the fence. He is forced to stop in order to protect himself.\n\n## Scene 2: Crocodile Attack\nThe crocodile *attacks* the man and he *slays* it. He harvests the crocodile meat and cooks it over a fire. The man then builds a wall around his village and works the land. He uses gold bricks to build and upgrade buildings. He trains soldiers and then watches them fight another man. He builds a bridge to the other side of the river."
        }
    ],
    "short_105": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Type          | Attributes                              | Actions                                                                 |\n|---------------|-----------------------------------------|------------------------------------------------------------------------|\n| orange-capped | Color: orange; Spots: none; Stem color: grayish | Jump up and down on a moss - covered rock near water.                   |\n| blue-capped   | Color: blue; Spots: white; Stem color: light brown | Jump up and down on rocks near water, interact with a ladybug.         |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Setting  \nA serene aquatic landscape with small rocky islands covered in moss, flowers, and tall reeds. Bright sunlight casts rays across the calm water, creating a peaceful, whimsical atmosphere.  \n\n## Actions  \nMushrooms *bounce* rhythmically on the islands—some on orange-capped mushrooms on one island, others on blue-spotted mushrooms on another. A ladybug *perches* near a blue-spotted mushroom, then *shifts* as the mushroom moves. The mushrooms’ bouncing has a steady, playful tempo, syncing with the gentle water ripples.  \n\n## Mood  \nThe scene feels magical and lighthearted, with the bouncing mushrooms and bright sunlight evoking childlike wonder. The calm water and soft rays add tranquility, blending whimsy with peace."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\"sun position\": \"orange mushroom\", \"reaction\": \"the sun shines directly upon the orange mushrooms\"},\n  {\"sun position\": \"blue mushroom\", \"reaction\": \"the sun shines directly upon the blue mushrooms\"}\n]\n```\nThe sun's position has changed at around 0:13 because the angle of the camera has changed."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the mushroom's view: It stands on a rock by the water, seeing other mushrooms on a distant mossy rock, with sunlight streaming down and ladybug nearby.\nFrom the ladybug's view: It stays near the blue mushroom, observing the mushroom's movements and the surrounding water and distant mushroom - covered rock under the sun."
        }
    ],
    "short_106": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Appearance Features | Static Attributes |\n| ------------- |:-------------:|:-------------:|\n| Person |  Dark jacket, blue pants, blue rubber boots |  Lying down, larger |\n| Animal |  Orange fur with black stripes, small white patches   | Small, quadrupedal  |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Scene 1\nA person wearing a jacket, blue pants, and blue boots is sitting on a paved surface. The person has a tiger cub on their lap and is petting it. The cub is mostly golden-brown, with black stripes and white fur on its chest and face. It lies still in the person's lap.\n## Scene 2\nThe cub stands in front of the person's legs and begins sniffing the person's blue boot. It puts its front paws on the boot and licks it. The cub is still standing.\n---\nEnd of Script"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  {\"timestamp\": \"00:00\", \"interaction\": \"The person pets the tiger cub on their lap.\"},\n  {\"timestamp\": \"00:40\", \"interaction\": \"The tiger cub climbs on the person's boot.\"},\n  {\"timestamp\": \"00:54\", \"interaction\": \"The tiger cub licks and nibbles the person's boot.\"},\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "[00:00:00 to 00:00:04]\nI'm sitting on the ground and a cute tiger cub is playing on my lap. I gently pet the cub. The cub's fur is so soft. I'm enjoying spending time with this sweet creature. \n\n[00:00:41 to 00:00:59]\nI like climbing around on this person. I walk on their boots. I climb to the top of one boot and lie there, licking it. I stretch out with my little paws. My tiger tail is long and stripey. I look at the camera."
        }
    ],
    "short_107": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n\"character\": {\n  \"attribute\": [\"small\", \"blue\"],\n   \"weapon\": \"staff\"\n},\n\"monster\": {\n \"attribute\": [\"large\", \"orange\"],\n   \"weapon\": \"sword\"\n}\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "02",
            "response": "[\n  {\n    \"timestamp\": \"00:17\",\n    \"action\": \"rolls to the right\"\n  },\n  {\n    \"timestamp\": \"00:51\",\n    \"action\": \"rolls backwards\"\n  },\n  {\n    \"timestamp\": \"00:53\",\n    \"action\": \"rolls to the right\"\n  },\n  {\n    \"timestamp\": \"00:55\",\n    \"action\": \"rolls to the left\"\n  }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "Here comes a little guy with a stick to taunt me. I will smash him! Why is this guy still alive? He is so slippery! It seems I need to try harder."
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "04",
            "response": "A. Player|Attack|Monster|Hit\nB. Monster|Attack|Player|Hit\nC. Player|Attack|Monster|Hit\nD. Player|Attack|Monster|Miss\n\n| Actor | Action_Count |\n|-------------------|---------------|\n| Player | 17 |\n| Monster | 10 |"
        }
    ],
    "short_108": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1.  The lotus roots are peeled and get much smaller.\n2.  The lotus roots are sliced and get much smaller.\n3.  The lotus roots are put in a blender and turned into a paste.\n4.  The lotus paste is wrung to extract the water and becomes smaller.\n5.  The residue after the extraction is scraped out and it is now a powder."
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "| Step | Tool | Function |\n|---|---|---|\n| Washing lotus roots | Hands | Rinsing the lotus roots in the sink |\n| Peeling lotus roots | Peeler | Removing the skin from the lotus roots |\n| Slicing lotus roots | Knife | Cutting the lotus roots into slices |\n| Making lotus roots paste | Blender | Breaking down sliced lotus roots and water into pulp |"
        },
        {
            "field": "For Generation",
            "prompt_id": "03",
            "response": "I'm filled with round, light-colored lotus root slices. Water is added. Whirr, whirr, whirr! I'm vibrating.\n\nA. Slices of lotus roots are put in me.\nB. Water is poured in me.\nC. The lid is put on me."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "[\n  {\n    \"timestamp\": \"00:12\",\n    \"cross section\": \"holes\"\n  },\n  {\n    \"timestamp\": \"00:47\",\n    \"cross section\": \"solid\"\n  }\n]"
        }
    ],
    "short_109": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "[\n   {\n     \"Li Zhuhao\": {\n       \"outfit\": [\n         \"white jacket\",\n         \"white pant\"\n       ],\n       \"behaivor\": \"sitting\"\n    }\n   },\n   {\n     \"Masayuki UMEMOTO \": {\n       \"outfit\": [\n         \"black jacket\",\n         \"black pant\"\n       ],\n       \"behaivor\": \"waking\"\n     }\n  }\n]"
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "A. Yuuto IDA (CLB)\nA. Yuuya SAKAMOTO (CLB)\nA. Masato SAKAI (CLB)\nA. Li Zhuhao (CHN)\nA. Takumi TERADA (CLB)\nA. Yuuya YAJIMA (CLB)\nA. Nao HOROMURA (CLB)\nA. Masayuki UMEMOTO (JPN)"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n  {\n    \"timestamp\": \"00:37\",\n   \"rodent_count\": 3,\n    \"action\": \"Rodents line up for pawpsicles. \"\n  },\n  {\n    \"timestamp\": \"00:49\",\n    \"rodent_count\": 4,\n    \"action\": \"Rodents throw away pawpsicle sticks.\"\n  }\n]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The video opens with a shot of an indoor swimming pool with eight lanes, filled with clear blue water that reflects the overhead lighting, and the walls surrounding the pool are various shades of blue, creating a visually refreshing and sporty environment. Yellow lane dividers stretch across the pool's surface, defining each lane, and starting blocks are positioned at the end of each lane, ready for the swimmers. The edges of the pool are lined with grey tiles, and there are some plants in the background."
        }
    ],
    "short_110": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"fox\": {\n        \"attributes\": [\"anthropomorphic\", \"orange fur\", \"wears clothes\"],\n        \"location\": \"outdoor (near a building with a pipe pouring red liquid)\"\n    },\n    \"van\": {\n        \"attributes\": [\"red\", \"has decorative painting\", \"used for transporting\"],\n        \"location\": \"street (near a parking meter)\"\n    },\n    \"Pawpsicle\": {\n        \"attributes\": [\"red\", \"paw - shaped\", \"on a stick\"],\n        \"location\": \"outdoor (when the fox sells them on the street)\"\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Our Pawpsicle business starts with the **roof device**—a setup that lets bright red liquid flow down, filling jars below. We’ve got those jars lined up, ready to catch every drop, and the liquid looks rich, perfect for what we need. Then there’s the van, our mobile base, waiting to take the operation on the road.  \n\nSounds are key, too—the drip of the red liquid into jars, the hum of the van’s engine as we move, and the clinking of jars as we handle them. When we’re on the roof, you hear the steady flow of the liquid, and when we hit the street, the van’s engine rumbles, ready to go. Even the chatter of customers later adds to the buzz.  \n\nThe whole process comes together: the **roof device** feeds the liquid, we bottle it, load the van, and head out. Whether it’s the drip-drip of filling jars or the rev of the engine, every sound and sight pushes the business forward. From setup to selling, it’s a smooth rhythm—one that turns those red drops into Pawpsicles people love. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\"timestamp\": \"22:00\", \"rodent_count\": 1, \"action\": \"make pawpsicle\", \"judy_reaction\": \"surprised\"}, {\"timestamp\": \"26:00\", \"rodent_count\": 1, \"action\": \"sell pawpsicle\", \"judy_reaction\": \"surprised\"}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The fox collects red liquid, makes Pawpsicles, sells them to rodents with successful selling, then discards sticks and repeats."
        }
    ],
    "short_111": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity Type | Static Attributes | Dynamic Actions |\n|-------------|-------------------|-----------------|\n| Presenter | Holds paper, speaks | Walks, gestures |\n| Large Screen | Displays content | Changes visuals |\n| Newsroom | Glass walls, red table | People move in bg |"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "02",
            "response": "```json\n{\n  \"primary_topic\": \"news\",\n  \"key_visuals\": [\n    \"Utility trucks and fallen trees\",\n    \"President Biden, U.S. Capitol\"\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "The presenter walks, gestures, and speaks about topics like a city meltdown, heat-related issues, political anxiety, and a murder suspect; the tone is serious, evidenced by her hand gestures emphasizing key points."
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "Daytime; utility trucks line a street, people wait in long lines; generator hum inferred; triple - digit temperatures (weather - related detail)."
        }
    ],
    "short_112": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. A. 1. Walk towards the dragon 2. Ride the dragon underwater\n2. [{\"entity\": \"character\", \"dynamic_attr\": \"walk towards dragon\"}, {\"entity\": \"dragon\", \"dynamic_attr\": \"swim underwater\"}]"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- Underwater temple path: deep blue, dim aquatic glow\n- Coral reef garden: vibrant mix of blues and pinks, diffused light through water\n- Sunken dragon statue area: muted blue, faint light filtering from above"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "1. [00:00]|Character moves forward in underwater scene.\n2. [00:05]|Dragon appears in the background.\n3. [00:10]|Character rides on the dragon."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A. I walk fast through the underwater path, hold a staff, feel determined. See a big dragon, jump on its back, ride it through the sea, feel excited and brave.\n\nB. I swim steady, carry the character on my back. Move through corals and rocks, feel calm. Let the character ride me, take them through the underwater world, feel strong and reliable."
        }
    ],
    "short_113": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"speakers\": [\n    {\n      \"role\": \"President of Russia\",\n      \"static_attributes\": [\"Dark suit, white shirt\", \"Russian flag on podium\"],\n      \"dynamic_actions\": [\n        {\n          \"action\": \"Walks to podium\",\n          \"timestamp\": \"00:03\"\n        },\n        {\n          \"action\": \"Starts speaking\",\n          \"timestamp\": \"00:04\"\n        }\n      ]\n    },\n    {\n      \"role\": \"President of the United States\",\n      \"static_attributes\": [\"Dark suit, red tie\", \"American flag on podium\"],\n      \"dynamic_actions\": [\n        {\n          \"action\": \"Walks to podium\",\n          \"timestamp\": \"00:08\"\n        },\n        {\n          \"action\": \"Nods and gestures\",\n          \"timestamp\": \"00:44\"\n        }\n      ]\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "02",
            "response": "```\n{\n    \"primary_tag\": \"press conference\",\n    \"secondary_tags\": [\"political\", \"formal\", \"diplomatic\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "Live from the conference: Two men approach speaking stands as attendees raise phones and cameras. One man speaks about constructive negotiations, then the other thanks his counterpart, with audience devices capturing the event."
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "close - up shot of his hand with lighting focus; camera clicks; audience murmurs; translation audio; the U.S. President gestures while addressing the audience at a joint news conference. the event emphasizes diplomatic discussions between two nations."
        }
    ],
    "short_114": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "- tray\n- chopsticks\n- steamer\n- spray bottle\n- pot\n- strainer\n- bowl\n- glass jar\n\n{\"stage_name\": \"soaking\", \"duration\": \"2 minutes\", \"purpose\": \"moisten the noodles for further processing\"}\n---\n{\"stage_name\": \"steaming\", \"duration\": \"2 minutes\", \"purpose\": \"cook the noodles to proper texture\"}\n---\n{\"stage_name\": \"sauce mixing\", \"duration\": \"not specified\", \"purpose\": \"combine ingredients to flavor the noodles\"}"
        },
        {
            "field": "For Instructional",
            "prompt_id": "02",
            "response": "* 花椒\n* 八角\n* 桂皮\nIf the sauce is too thick after mixing, add a small amount of warm oil or water and stir until the desired consistency is reached.\n[\"Over-steaming leading to sogginess\", \"Uneven steaming causing raw spots\"]"
        },
        {
            "field": "For Generation",
            "prompt_id": "03",
            "response": "Scene 1: An overhead shot shows hands placing gluten strips onto a tray. The tray is arranged neatly as the gluten is prepared for the next step.\nScene 2: Gluten sits in a steamer with steam rising steadily; the sound of boiling water hums in the background. A lid covers the steamer, trapping heat to cook the gluten evenly.\nScene 3: Hands mix gluten with a rich red sauce, ensuring each strip is coated. The sauce clings to the gluten, creating a glossy, flavorful coating.\nTitle: “Homestyle Gluten: From Steam to Sauce”"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A curious child watches wide - eyed as hands use a yellow mini oven and a square tray. The tray gets filled with thin strips, then water is poured on them. Later, a red pot with oil and spices is used, and the child thinks the tools like the tiny oven and the spray bottle for oil are super cool.\n\nA home cook takes notes: First, soak the beef tendon noodles for 2 minutes. Then, steam them and spray oil on the surface before steaming again. These steps ensure the noodles have the right texture. Also, when making the spicy sauce, fry spices in oil first and then pour the oil into the spice mixture for a flavorful base."
        }
    ],
    "short_115": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"rabbit\": {\n    \"dynamic_attributes\": [\"motivated\", \"startled\", \"anxious\", \"doubtful\"],\n    \"actions\": [\n      {\"timestamp\": \"0:03\", \"description\": \"unfolds a drawing\"},\n      {\"timestamp\": \"0:08\", \"description\": \"smiles\"},\n      {\"timestamp\": \"0:10\", \"description\": \"picks up a shovel\"},\n      {\"timestamp\": \"0:14\", \"description\": \"faces a mole with a shovel\"},\n      {\"timestamp\": \"0:16\", \"description\": \"shakes hands with the mole\"},\n      {\"timestamp\": \"0:24\", \"description\": \"listens\"},\n      {\"timestamp\": \"0:29\", \"description\": \"takes back the drawing\"},\n      {\"timestamp\": \"0:30\", \"description\": \"looks at the drawing\"}\n    ],\n    \"interactions\": {\n      \"mole\": {\n        \"interaction_type\": \"cooperative\",\n        \"mutual_goal\": \"home_design\"\n      }\n    }\n  },\n  \"mole\": {\n    \"dynamic_attributes\": [\"aggressive\", \"friendly\"],\n    \"actions\": [\n      {\"timestamp\": \"0:13\", \"description\": \"emerges from a hole\"},\n      {\"timestamp\": \"0:16\", \"description\": \"shakes hands with the rabbit\"},\n      {\"timestamp\": \"0:20\", \"description\": \"presents blueprints\"},\n      {\"timestamp\": \"0:26\", \"description\": \"presents completed project\"},\n      {\"timestamp\": \"0:27\", \"description\": \"gives a thumbs up\"}\n    ],\n    \"interactions\": {\n      \"rabbit\": {\n        \"interaction_type\": \"cooperative\",\n        \"mutual_goal\": \"home_design\"\n      }\n    }\n  }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- \"MY HOME!\" text\n- labeled \"bed\" area\n- labeled \"bathroom/disco??\" area\n- drawing of the rabbit labeled \"me!\""
        },
        {
            "field": "For Communication",
            "prompt_id": "03",
            "response": "Rabbit: Looking at Mole's detailed blueprint, I feel envious yet inspired. His plan is so elaborate—bedrooms, a main living area! I thought my simple sketch was enough, but now I wonder if I should aim bigger. Excited, I want to improve my own design.\n\nMole: When I see Rabbit's hand - drawn \"MY HOME!\" sketch, I find it cute but basic. My blueprint is professional, with measurements and rooms. I feel proud of my expertise. I want to help Rabbit realize that a well - planned home needs structure, and I'm eager to share my knowledge."
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "If (unclear room labels), try (adding labels like the mole's blueprint \"BEDROOM A\" and \"BEDROOM B\")|If (lack of structural details), try (including measurements like the mole's blueprint scale and dimensions)|If (vague layout organization), try (defining clear areas like the mole's blueprint \"MAIN LIVING\" section)"
        }
    ],
    "short_116": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"red fire hydrant\": {\n    \"type\": \"Object\",\n    \"attributes\": [\"red\"]\n  },\n  \"gray trash can\": {\n    \"type\": \"Object\",\n    \"attributes\": [\"gray\"]\n  },\n  \"brown truck\": {\n    \"type\": \"Object\",\n    \"attributes\": [\"brown\"]\n  }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Dear Diary: Climbing these stairs is tough. I grip the metal railing, my breath heavy. People pass by, some giving quick glances. Their footsteps echo, mixing with my own labored breaths. The sun’s bright, making each step feel heavier. I keep going, though—gotta push through. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n[\n  {\n    \"entity1\": \"person in suit\",\n    \"entity2\": \"trash can\",\n    \"action\": \"interacts with trash can on street\"\n  },\n  {\n    \"entity1\": \"person in green hoodie\",\n    \"entity2\": \"stairs\",\n    \"action\": \"walks up stairs holding handrail\"\n  }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Urban Scene: A person in a dark coat, black pants, and sneakers is meticulously descending a long flight of concrete stairs, equipped with prominent metal handrails, set in an outdoor urban environment. The background suggests a park-like area with trees and other pedestrians. Their key action involves a slow, deliberate, and cautious descent, marked by a firm grip on the handrail. The individual appears to be struggling, concentrating intently on each step as they move downward. Two potential reasons why they might struggle with their action include *significant physical discomfort, possibly from leg fatigue or a recent minor injury*, making it painful or difficult to navigate the steps without extra support. Alternatively, it could stem from a *lack of confidence on stairs or a fear of instability*, leading them to adopt a very careful, almost hesitant, approach to maintain balance."
        }
    ],
    "short_117": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Analysis: ```json\n{\n  \"tank\": {\n    \"status\": \"destroyed\",\n    \"location\": \"street between buildings\"\n  },\n  \"player_actions\": [\n    {\n      \"action\": \"Aimed RPG at enemy tank.\",\n      \"weapon\": \"RPG\",\n      \"timestamp\": \"00:07\"\n    },\n    {\n      \"action\": \"Fired rocket at enemy tank.\",\n      \"weapon\": \"RPG\",\n      \"timestamp\": \"00:08\"\n    },\n    {\n      \"action\": \"Aimed RPG at damaged tank.\",\n      \"weapon\": \"RPG\",\n      \"timestamp\": \"00:11\"\n    },\n    {\n      \"action\": \"Fired rocket, destroyed tank.\",\n      \"weapon\": \"RPG\",\n      \"timestamp\": \"00:12\"\n    },\n    {\n      \"action\": \"Fired rocket at destroyed tank area.\",\n      \"weapon\": \"RPG\",\n      \"timestamp\": \"00:16\"\n    }\n  ],\n  \"grenade_launcher_used\": true\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "fired rifle at enemy; fired rocket launcher at enemy"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\": \"00:00\", \"description\": \"Player starts moving forward\"}, {\"timestamp\": \"00:04\", \"description\": \"Player throws a grenade\"}, {\"timestamp\": \"00:12\", \"description\": \"Player fires at enemies\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Player moves forward while shooting enemies.\nPlayer throws grenades and uses rocket launcher.\nPlayer continues attacking enemies with various weapons."
        }
    ],
    "short_118": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"timeline\": [\n        {\n            \"timestamp\": \"00:00\",\n            \"elements\": [\n                {\n                    \"name\": \"background\",\n                    \"attributes\": {\n                        \"shape_type\": \"rectangle\",\n                        \"color\": \"green\"\n                    }\n                }\n            ],\n            \"transition\": \"fade\"\n        },\n        {\n            \"timestamp\": \"00:02\",\n            \"elements\": [\n                {\n                    \"name\": \"text_1961\",\n                    \"attributes\": {\n                        \"font_color\": \"white\",\n                        \"text\": \"1961\"\n                    }\n                },\n                {\n                    \"name\": \"decorative_shapes\",\n                    \"attributes\": {\n                        \"shape_type\": \"circle\",\n                        \"color\": \"white\"\n                    }\n                },\n                {\n                    \"name\": \"decorative_shapes\",\n                    \"attributes\": {\n                        \"shape_type\": \"triangle\",\n                        \"color\": \"pink, lightgreen\"\n                    }\n                }\n            ],\n            \"transition\": \"pop\"\n        },\n        {\n            \"timestamp\": \"00:06\",\n            \"elements\": [\n                {\n                    \"name\": \"text_final_sprite\",\n                    \"attributes\": {\n                        \"font_color\": \"white, green\",\n                        \"text\": \"FINAL Sprite\"\n                    }\n                },\n                {\n                    \"name\": \"circle_background\",\n                    \"attributes\": {\n                        \"shape_type\": \"circle\",\n                        \"color\": \"white\"\n                    }\n                },\n                {\n                    \"name\": \"decorative_shapes\",\n                    \"attributes\": {\n                        \"shape_type\": \"circle\",\n                        \"color\": \"white\"\n                    }\n                }\n            ],\n            \"transition\": \"zoom\"\n        },\n        {\n            \"timestamp\": \"00:12\",\n            \"elements\": [\n                {\n                    \"name\": \"sprite_logo\",\n                    \"attributes\": {\n                        \"shape_type\": \"text\",\n                        \"font_color\": \"green, white\",\n                        \"text\": \"Sprite\"\n                    }\n                },\n                {\n                    \"name\": \"lemon_icon\",\n                    \"attributes\": {\n                        \"shape_type\": \"icon\",\n                        \"color\": \"yellow, green\"\n                    }\n                }\n            ],\n            \"transition\": \"slide\"\n        },\n        {\n            \"timestamp\": \"00:20\",\n            \"elements\": [\n                {\n                    \"name\": \"bottle_illustration\",\n                    \"attributes\": {\n                        \"shape_type\": \"bottle\",\n                        \"color\": \"white\"\n                    }\n                },\n                {\n                    \"name\": \"bubbles\",\n                    \"attributes\": {\n                        \"shape_type\": \"circle\",\n                        \"color\": \"white\"\n                    }\n                }\n            ],\n            \"transition\": \"fade\"\n        }\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- *Geometric shapes animation* with white circles and pink/cyan triangles on a vibrant green background, leading into text display.\n- *Logo morphing* from a detailed green Sprite logo with a lemon to a simpler white and green Sprite logo within a starburst shape.\n- *Bubbles filling* a white bottle outline, *expanding* and *contracting* on a bright green background.\n- *Text dissolving* and *forming* through white sparkling particles on a solid green background.\n- *Minimalist line animation* in white, green, and yellow around a bottle icon on a deep green background.\n---End of Creative Elements---"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "| Time | Element | Type |\n|------|---------|------|\n| 0:00 | Green background | Static |\n| 0:04 | White circles and triangles | Animated |\n| 0:08 | \"1961\" text | Animated |\n| 3:16 | Sprite logo (circle with \"FINAL Sprite\") | Animated |\n| 7:08 | Sprite logo (text with star shape) | Animated |"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The video begins with the year 1961, and an energetic animation introduces the initial **Sprite** logo, featuring the word \"Sprite\" in a simple font. Subsequent energetic animations cycle through various historical **Sprite** logos, showcasing different stylizations and accompanying graphic elements like bubbles and geometric shapes. These transitions highlight the evolution of the brand's visual identity over time. The segment concludes with a more refined, classic **Sprite** logo from around 2008.\n\n2. Following the 2008 **Sprite** logo, energetic animations introduce different bottle designs, emphasizing the distinctive shape and effervescence of the beverage. The **Sprite** wordmark appears on the bottles, evolving through several styles from the classic spiky design to a more streamlined look. Various bubbly and splash effects energetically animate around the bottle, reflecting the refreshing quality of the drink. This segment tracks the visual journey of the **Sprite** bottle and its changing branding.\n\n3. The video then shifts to a white background with the slogan \"Sprite obey your thirst,\" accompanied by subtle, energetic wavy lines. More dynamic animations feature the current **Sprite** logo, disintegrating and reassembling with energetic bubbly effects. The final slogan \"Release your summer\" appears, surrounded by a constellation of animated green dots, before the **Sprite** logo dissolves into a burst of energetic white bubbles, encapsulating the brand's refreshing and lively image. The video ultimately conveys the enduring, refreshing, and dynamic essence of the **Sprite** brand through its evolving visual identity."
        }
    ],
    "short_119": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"rock_formation\": {\n        \"attributes\": [\"rugged\", \"reddish-brown\", \"varied shapes\"],\n        \"location\": \"foreground, desert landscape\"\n    },\n    \"milky_way\": {\n        \"attributes\": [\"vast\", \"sparkling\", \"purple and white hues\"],\n        \"location\": \"night sky above the rock formations\"\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Scene: Night Sky\nThe **Milky Way** stretches across a dark sky, with countless stars twinkling. Silhouettes of rock formations stand in the foreground. Subtitles appear, providing information about deserts. A sense of vast stillness envelops the scene, with the faint glow of the galaxy creating a serene atmosphere. --End Scene--\n\n## Scene: Daytime Desert\nThe sun illuminates **red rock formations** and sandy dunes under a clear blue sky. The arid landscape extends into the distance, with shadows cast by the rocks. Subtitles appear, discussing the importance of deserts. The heat of the sun and the dryness of the air are palpable. --End Scene--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Primary: Desert night to day transition|Secondary: Cosmic|Vast|Arid"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From a star’s perspective: I twinkle above the silent desert, *eternal* in my glow. Below, rock formations stand still, shadows stretching under my light. I’m part of a vast dance, centuries old, watching the desert’s slow breath. A fifth of Earth’s land is desert—this quiet expanse, where time feels boundless.  \n\nFrom a desert rock’s perspective: I’ve stood here for eons, *enduring* heat and cold, wind carving my edges. Stars wheel above, distant and bright. Dawn turns my sandstone hues to gold. The Atacama, driest of deserts, has places where rain never falls—yet life clings. I’m a silent witness to this harsh, beautiful world, rooted in patience."
        }
    ],
    "short_120": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"book_movements\": [\n    \"flying through the sky like birds\",\n    \"walking and dancing in a circle on small legs\"\n  ],\n  \"entities\": [\"**boy**\", \"**woman**\", \"**books**\"],\n  \"interactions\": [\n    \"A boy sits under a tree reading before books fly from him into the sky.\",\n    \"He writes in a journal, and later, animated books dance on a wooden floor.\",\n    \"Inside a library, the boy swings from a ladder and hands a book to a woman.\",\n    \"The woman, who initially appears as a gray statue, accepts the book.\",\n    \"Finally, the woman walks away down a sunlit path with the book as the boy watches her leave.\"\n  ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Feelings: \n- peaceful as I hear the wind rustle the leaves and the faint flutter of birds flying\n- curious as books start floating and dancing around\n- nostalgic as memories of reading under this tree flood back\n---"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\"primary_tag\": \"book animation\", \"secondary_tags\": [\"flying books\", \"storytelling\", \"nostalgic\"]}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Reading under a tree, I’m *startled* as books float upward. Later, we walk, recalling stories, *content* with shared memories.  \n\nWatching him read, I feel *fond*. Time passes; we stroll, books and stories weaving our bond, *peaceful* in this shared journey."
        }
    ],
    "short_121": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"university\": {\n        \"exterior_features\": [\"beige walls\", \"large glass windows\", \"green dome structure\"],\n        \"statue_details\": {\n            \"name\": \"Ace\",\n            \"color\": \"black\",\n            \"accessory\": \"blue scarf\"\n        },\n  \"main_character_dog\": [\n  {\n  \"color\": \"white\", \n  \"action\": \"walk towards the university, then enter and walk down the hallway\",\n  \"emotion\": \"curious and determined\" \n  }\n ],\n    \"other_dogs\": [\n  {\n  \"color\": \"black\", \n  \"action\": \"run past the main dog\",\n  \"emotion\": \"excited\" \n   },\n    \"other_dogs\": [\n  {\n  \"color\": \"brown\", \n  \"action\": \"run past the main dog\",\n  \"emotion\": \"excited\" \n   },\n    \"other_dogs\": [\n  {\n  \"color\": \"yellow\", \n  \"action\": \"run past the main dog\",\n  \"emotion\": \"excited\" \n   },\n  \"other_dogs\": [\n  {\n  \"color\": \"gray\", \n  \"action\": \"run past the main dog\",\n  \"emotion\": \"excited\" \n   }\n  ]\n}\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Panel 1 (Wide Shot): The **\"SOUTHEASTERN GUIDE DOGS\"** arch frames Canine University. The modern building with a dome and large windows stands in the background, surrounded by greenery.    \nPanel 2 (Medium Shot):** A white puppy walks toward the university, *eyes wide with curiosity and excitement*. Other puppies run past, but it stays focused on the entrance.    \nPanel 3 (Close-Up): ** The puppy’s paws step onto the dark entrance mat, transitioning from the outdoor walkway to the university’s polished interior.  \n\n```json\n[\"Southeastern Guide Dogs Arch and University\", \"Curious White Puppy Approaches University Statue\", \"Puppy’s Paws Step Onto Building Entrance Mat\"]\n```"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\"university_name\": \"CANINE UNIVERSITY\", \"statue_name\": \"ACE\", \"main_character_color\": \"white\"}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here are the video captions:\n[00:00:00 to 00:00:04]: From outside the gate, one sees Canine University, a modern-style building surrounded by green lawns and palm trees. An archway proclaiming \"Southeastern Guide Dogs\" frames the view, leading to a statue of a dog called \"ACE\" guarding the entrance.\n[00:00:04 to 00:00:15]: 小白狗穿过写着“Southeastern Guide Dogs”的拱门，兴奋地走向学校。它的尾巴摇个不停，似乎对即将到来的大学生活充满了期待。其他小狗也紧随其后，它们也想尽快开始在狗狗大学的学习。"
        }
    ],
    "short_122": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"main_character_1\": {\n    \"clothing\": [\"**dark suit**\", \"**white shirt**\", \"**tie**\"],\n    \"actions\": [\"walk down hallway\", \"ask for direction\", \"enter classroom\", \"write on blackboard\", \"speak to class\"]\n  },\n  \"main_character_2\": {\n    \"clothing\": [\"**green and beige varsity jacket**\"],\n    \"actions\": [\"walk down hallway\", \"interact with peer\", \"enter classroom\", \"sit at desk\"]\n  },\n  \"main_character_3\": {\n    \"clothing\": [\"**dark dress**\", \"**headband**\"],\n    \"actions\": [\"apply lipstick\", \"respond to question\"]\n  }\n}\n\nA. main_character_1 | walk down hallway  \nB. main_character_1 | ask main_character_3 for direction  \nC. main_character_3 | respond to main_character_1  \nD. main_character_2 | walk down hallway  \nE. main_character_2 | interact with peer  \nF. main_character_1 | enter classroom  \nG. main_character_2 | enter classroom  \nH. main_character_1 | write on blackboard  \nI. main_character_1 | speak to class"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Sunlight streams through tall windows, casting long shadows on the polished hallway floor. Students mill about, their chatter a low hum, as lockers line the walls—cold to the touch. A boy in a dark blazer navigates the crowd, books in hand, the air thick with the bustle of a busy school day.  \n\n---\n\n**Boy**: Excuse me.  \n**CLAIRE**: Yes?  \n**Boy**: Do you know where room 17, French is?  \n**CLAIRE**: Yeah, it’s...  \n\n---\n\n## Reason 1  \nTo attend a French class, as indicated by his question about room 17 and later entering a classroom with French decor.  \n\n## Reason 2  \nTo assume a role, possibly as a substitute teacher, suggested by his actions of writing on the blackboard and addressing students as if in authority."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "locker:beige:wall;book:brown:hand;flag:blue/white/red:desk;chalkboard:black:wall"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A young man walks hurriedly through a school hallway, asking a girl for directions to a classroom. He then enters a classroom, where students react with amusement as he writes his name on the board, trying to assert authority as a substitute teacher."
        }
    ],
    "short_123": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Category | Details |\n| --- | --- |\n| Color | Brownish-gray top, yellowish underside with spines |\n| Shape | Five long, tapering arms with curved, flexible tips |\n| Texture | Rough, granular top; smooth, spiny underside with tube feet |\n| Dynamic Action | Arms curl and uncurl as it moves across the sand  |\n | Dynamic Action | Tube feet on underside contract and expand for locomotion |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## Starfish Movement  \nThe starfish curls its arms rhythmically, showcasing fluid motion. This curling might express *curiosity* or adaptation to the sandy terrain as it navigates.  \n\n## Environment  \n- The beach has smooth, wet sand, indicating recent tidal activity.  \n- Gentle waves roll in the background, creating a calm auditory and visual backdrop.  \n- Small shells and pebbles are scattered across the sand, adding texture to the coastal landscape."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\"starfish_attributes\":[\"brown and yellow\",5,\"sharp\",0.2,\"rough\"],\"wave_pattern\":\"gentle with small crests\"}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "I move my arms slowly across the warm sand, feeling the sun’s heat. The ocean’s rhythm echoes nearby, and I stretch my limbs, exploring the sandy surface.  \n\nA starfish lies on the wet sand, its arms curling and uncurling slowly. The ocean waves roll gently in the background, and the sun casts light on the scene, highlighting the starfish’s delicate movements."
        }
    ],
    "short_124": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n{\n  \"penguins\": [\n    {\n      \"position\": \"on an iceberg\",\n      \"reaction\": \"concerned\"\n    },\n    {\n      \"position\": \"on iceberg\",\n      \"reaction\": \"worried\"\n    },\n    {\n      \"position\": \"on iceberg\",\n      \"reaction\": \"scared\"\n    },\n    {\n      \"position\": \"on iceberg\",\n      \"reaction\": \"relief\"\n    }\n  ],\n  \"killer_whale\": {\n    \"behavior\": \"swimming around an iceberg\",\n    \"intent\": \"playfully trying to scare the penguins by bumping and tilting the iceberg with its body and mouth\"\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Huddled together on the tiny ice floe, we felt the chilling spray as we drifted, longing for the familiar comfort of the mainland. A sinister shadow slipped beneath the surface, and our collective breath caught in our throats as we instinctively understood the danger. The rhythmic pulse of the ocean seemed to amplify, and the pounding of my own heartbeat throbbed in my ears, echoing the fear of my companions."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n    \"primary_tag\": \"penguins on ice floe\",\n    \"secondary_tags\": [\"orca\", \"iceberg\", \"anxious\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Penguins huddle on ice as a whale approaches. Penguins react with fear, shifting on the ice. Whale's fin moves; penguins stay grouped, showing unity. Fear."
        }
    ],
    "short_125": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"level\": \"11\",\n    \"missiles_used\": 5,\n    \"target_building\": {\n        \"color\": \"blue\",\n        \"shape\": \"triangular\"\n    },\n    \"destruction_steps\": [\n        \"1. The first missile hits the middle section of the blue triangular building, causing an explosion and partial collapse of that section.\",\n        \"2. The second missile strikes the upper part of the building, resulting in a large explosion and further disintegration of the structure.\",\n        \"3. The third missile impacts the lower section, leading to a massive explosion and the building's complete collapse.\"\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I fire! Explosions and debris fly.\nAnother explosion. Debris scatter everywhere.\nI fire one more time. Kaboom!"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"missile destruction of skyscraper\",\n  \"secondary_tags\": [\"skyscraper\", \"explosive impact\", \"debris scattering\"]\n}\n```"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "Okay, here is the information in a Markdown table with the requested specifications:\n\n| Step_Number | Action | Precautions |\n| ----------- | ----------- | ----------- |\n| 1 | Aim the cannon at the building and fire. |  Scenes are fictional, for entertainment only. |\n| 2 |  Aim the cannon at another building and fire again. |  Scenes are fictional, for entertainment only. |\n| 3 |  Aim again and fire once more at the last building. |  Scenes are fictional, for entertainment only. |"
        }
    ],
    "short_126": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Entity | Type (Person/Object/Scene) | Static Attribute | Action |\n| --- | --- | --- | --- |\n| Count Binface | Person | Trash can helmet, cape, armored suit | Walks to podium, gestures, speaks humorously about identity and speaking without notes |\n| Podium | Object | Wooden, with microphones, yellow flower | Stands at center of room, used by Count Binface to speak  |\n| Audience Member (in blue dress) | Person | Blue formal dress, seated | Claps, reacts to Count Binface's entrance and speech |\n| Room | Scene | Wooden paneling, red walls, formal seating | Hosts a debate event with audience and speakers |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Event Highlight: **Count Binface** enters a formal hall, wearing a trash - can helmet and a cape. The audience claps as he moves toward the speaking area. \n **Count Binface** begins a humorous speech, introducing himself as an intergalactic warrior (and a “fucking bin”) and joking about not using notes due to his helmet’s poor visibility. --End of Highlight--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "A blonde woman in a blue dress is sitting in a chair in an upright posture. A lady in a gown is sitting and reading some papers at a desk in front of her. A man is sitting in a chair in a casual posture."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The host addresses the audience, introducing Count Binface to close the case for the opposition, as attendees in formal attire listen attentively.  \n\nCount Binface enters, wearing a tall, metallic helmet and a cape, prompting applause and smiles from the audience, who react with amusement to the costume.  \n\nCount Binface begins speaking, referencing the event’s motion and their role in opposing it. The costume’s absurdity engages the audience, as laughter and attentive listening show its success in capturing attention."
        }
    ],
    "short_127": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"person\": {\n    \"clothing_color\": \"brown\",\n    \"states\": [\"lying\", \"getting_up\"]\n  },\n  \"actions\": [\"crawling\", \"calling\", \"running\"]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I woke up on the dusty ground, the gritty texture of the dirt against my face, and the air thick with swirling dust. I pushed myself up to my knees, then to a sitting position, gasping for breath as I fumbled for my phone. I called for help, my hands shaking, then stood and surveyed the destruction around me, my mind racing with what had just happened."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\"action\":\"lie on ground\",\"objects_involved\":[{\"type\":\"person\",\"description\":\"man\"},{\"type\":\"ground\",\"description\":\"dusty\"}]} ,{\"action\":\"crawl on ground\",\"objects_involved\":[{\"type\":\"person\",\"description\":\"man\"},{\"type\":\"ground\",\"description\":\"dusty\"}]} ,{\"action\":\"sit up and check phone\",\"objects_involved\":[{\"type\":\"person\",\"description\":\"man\"},{\"type\":\"phone\",\"description\":\"mobile device\"}]} ,{\"action\":\"make call and run\",\"objects_involved\":[{\"type\":\"person\",\"description\":\"man\"},{\"type\":\"phone\",\"description\":\"mobile device\"}]}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The man lies on the dusty ground, looking exhausted and determined as he struggles to push himself up; he crawls forward with effort, then sits up, pulls out a phone, makes a call, and finally stands and runs toward a building, with dust swirling around him."
        }
    ],
    "short_128": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"main_speaker\": {\n        \"name\": \"Rachel Haddad\",\n        \"attire\": \"black dress\"\n    },\n    \"debated_motion\": \"This house believes populism is a threat to democracy\",\n    \"key_events\": [\n        {\n            \"description\": \"Audience claps as a man speaks at the front.\",\n            \"action\": \"clapping\"\n        },\n        {\n            \"description\": \"A woman stands up from the front table and moves to the side, then another person sits down.\",\n            \"action\": \"standing up\"\n        },\n        {\n            \"description\": \"Rachel Haddad speaks at the front, adjusting her hair and referring to notes.\",\n            \"action\": \"speaking\"\n        }\n    ]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I take a deep breath, feeling focused as I step to the mic. The audience’s applause quiets, anticipation in the air. The motion is clear: “This house believes populism is a threat to democracy.” I begin, steady, knowing the weight of the room. “Ladies and gentlemen, it was Trump in the United States…” My words carry, determined to make my case."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"Populism Debate\",\n  \"secondary_tags\": [\"formal\", \"intellectual\", \"engaged\"],\n  \"key_quotes\": [\n    \"we put the motion before the house that this house believes populism is a threat to democracy - Unknown Speaker\",\n    \"Ladies and gentlemen, it was Trump in the United States. who presented himself as a champion of working Americans, vowing to prioritize American jobs and protect them from immigration. - Rachel Haddad\"\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "People clap as a man speaks about a motion on populism and democracy. Then a woman speaks at a podium, and the audience claps again."
        }
    ],
    "short_129": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Analysis Result: {\n  \"clumsy_moments\": [\n    \"04:00-06:00\",\n    \"10:00-13:00\",\n    \"17:00-19:00\"\n  ]\n}\nInference: \"My Dog\" is labeled with 😂 as it shows awkward attempts like failing to jump over a gate, rolling clumsily, and tripping while running, which are humorous. These moments contrast with the smooth actions of \"My Friends Dog\", highlighting the comedic clumsiness."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "**Scene Heading** (EXT, poolside, daytime)  \n**Action** (Camera tilts up to capture the dog’s leap, slow - motion effect. The dog launches from the pool’s edge, body extended, paws reaching for ==highlight==mid - air at a height of around 3 feet==. Water shimmers under sunlight.)  \n**Character** (dog's emotion: excited)  \n\nWhat - if scenario: If the dog missed the pool, a *thud* sound as paws hit concrete. The owner gasps, rushes over, checking for injuries with worried calls of “Buddy?!”"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n    \"clumsy_moments\": [\n        {\n            \"dog_type\": \"white dog\",\n            \"timestamp\": \"00:04\",\n            \"cause\": \"gate too tall\",\n            \"outcome\": \"struggles to climb over|gets stuck on gate\"\n        },\n        {\n            \"dog_type\": \"black & white dog\",\n            \"timestamp\": \"00:17\",\n            \"cause\": \"stream too wide\",\n            \"outcome\": \"attempts to jump|falls into stream\"\n        }\n    ]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Video Narrative: My Dog clumsily tries to climb a baby gate, failing comically. Later, it attempts to jump a stream but falls in, showing playful, carefree energy. --End--"
        }
    ],
    "short_130": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Creature Type       | Number Shot | Impact Effect                                      |\n|---------------------|-------------|----------------------------------------------------|\n| **Slime**           | Multiple    | {\"particle_color\": \"blue\", \"spread_radius\": \"large\"} |\n| **Rabbit - like**   | Multiple    | {\"particle_color\": \"white\", \"spread_radius\": \"large\"} |\n| **Pink Slime**      | Multiple    | {\"particle_color\": \"pink\", \"spread_radius\": \"large\"} |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The starting health is 250, and the number of coins is 375,029."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\": \"15:13\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:14\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:15\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:16\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:17\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:18\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:19\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:20\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:21\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:32\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:39\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:40\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:41\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:42\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:43\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:44\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:45\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:46\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:47\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:48\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:49\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:50\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:51\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:52\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:53\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:54\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:55\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:56\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:57\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}, {\"timestamp\": \"15:58\", \"creature_type\": \"棉兔史莱姆\", \"action\": \"shoot\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A player uses a snowball gun to hit small, rabbit-like creatures. The creatures react by moving and bouncing when hit. The player continues shooting, and the creatures scatter or get pushed around in the snowy, colorful environment."
        }
    ],
    "short_131": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. The tiger walks on a snowy slope, initially facing the camera.\n2. The tiger walks through a snowy forest, pausing to look around.\n- Snow\n- Trees\n- Mountains\n```json\n{\n  \"time_segments\": {\n    \"start\": \"A Siberian tiger walks on a snow-covered slope, looking towards the camera.\",\n    \"end\": \"An aerial shot of a snow-covered mountain range and forest.\"\n  }\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I step carefully through the snow - crusted forest, my paws sinking slightly into the white blanket. The crisp air nips at my nose, and I scent the faint traces of prey. *Crunch, crunch*—the sound of my steps breaks the silence as I move past tall pines. Sunlight filters through the branches, dappling the snow. I pause, listening for any unwanted intruders. Satisfied, I continue, my territory secure."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{'primary_tag': 'Siberian tiger patrols territory', 'secondary_tags': ['tiger in snowy forest', 'wild animal in winter', 'snowy mountain landscape']}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From the tiger's eyes: The cold air nips as I tread through snow, each step deliberate. Trees and hills blur; I scan for prey, my territory vast. Survival drives me—every scent, sound matters.  \n\nFrom a distant observer: A tiger moves through the snowy forest, its form powerful against the white landscape. It glides between trees, a silent force in the wintry wilderness, governed by instinct and the need to thrive. --Observer end--"
        }
    ],
    "short_132": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Here are the video details:\n\nThe sky has some cloud cover.\n\n| Feature Type | Observable Trait |\n|---|---|\n| surface | snow-covered |\n| cave | ==blue ice== |\n| tunnel |  snow-covered exit |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "I formed centuries ago, born from compressed snowflakes, my texture *glistening* like shattered glass under faint light, and my color a deep, ancient blue, as if the sky itself had frozen. I was rigid, unyielding, a silent sentinel in the glacier’s cave. But even then, did I sense the warmth that would reshape me? How long until our icy realms vanish?  \n\nOver time, melting water kissed my edges, carving *delicate* pathways like veins through stone. I felt myself soften, fragments slipping away as droplets, joining the slow river that whispered through the glacier. The water was both sculptor and thief, reshaping me while carrying pieces of my being into the unknown. Will the melting ever cease, or are we doomed to dissolve?  \n\nEventually, I became part of the ice tunnel, my form molded into arches and walls that cradled the frigid air. The tunnel, a cathedral of ice, glowed with a *ghostly* blue light, a testament to the water’s patient work. Now, I stand as both remnant and monument, wondering: as the world warms, how many more ice stories will be lost to the sea?"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"feature\": \"glacier\", \"timestamp\": \"00:00\", \"attributes\": \"icy, vast\"}, {\"feature\": \"ice cave\", \"timestamp\": \"10:00\", \"attributes\": \"blue, enclosed\"}, {\"feature\": \"snow - covered mountains\", \"timestamp\": \"25:00\", \"attributes\": \"snowy, towering\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Inside the ice cave, the dim blue glow reflects off smooth ice walls, with droplets glistening. The stillness feels calm, as if time slows in this frozen sanctuary.  \n\nFrom afar, the rainbow arcs over snow - capped mountains, vibrant against the pale sky. The vast, silent landscape below enhances the grand mood, making the natural wonder seem even more majestic."
        }
    ],
    "short_133": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"entity_type\": \"animal\",\n  \"static_attributes\": [\"white\", \"black\", \"black\", \"visible\"],\n  \"key_actions\": [\"crawling\", \"rolling\", \"resting\"]\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Here is the video description:\n\nOh, what a glorious day here in the Arctic. I think I’ll start by lying down in this soft snow and looking up at the bright, warm sun. My eyes feel heavy and I can feel myself dozing off, but I can’t stay down for long. I want to stretch my legs! Okay, that’s enough of that. I’m going to roll around in the snow a little. Whoops, got some snow stuck to my whiskers! Oh well, it’s kind of refreshing, actually. Back to lying down. It’s hard work being so cute. Sometimes, I hear the wind howling as it sweeps across the ice. It makes me feel cozy and safe. \n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"fur_color:white\",\"eye_color:black\",\"nose_color:black\",\"presence_of_whiskers:yes\",\"body_part_movement:flipper_movement\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Ok. Here's the video description:\n\nThe seal pup rests on the cold, white snow. It rolls around, looking cute and silly. The baby seal opens its mouth, feeling playful."
        }
    ],
    "short_134": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"waterfall\": {\n        \"static_attributes\": [\"large\", \"between Brazil and Argentina\", \"powerful\"],\n        \"quantity\": 1\n    },\n    \"birds\": {\n        \"static_attributes\": [\"flying\", \"near waterfall\"],\n        \"quantity\": 3\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "1. A wide shot shows birds flying in front of a waterfall with water appearing as white as a cloudy sky.\n2. The camera zooms in on a wider view of the waterfall, showing more birds flying."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\"Iguazu on Brazi-Argentina border\", \"Largest waterfalls on the planet\", \"Thousands of tons water per second\"]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "- Iguazu, on the frontier between Brazil and Argentina.\n- These are the largest waterfalls on the planet.\n- Thousands of tons of fresh water thunder over them every second.\n- 伊瓜苏 在巴西和阿根廷的边界\n- 这是星球上最大的瀑布\n- 每秒钟都有数千吨的淡水轰隆隆而下"
        }
    ],
    "short_135": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Video Analysis:\n1. Fox approaches shoe\n2. Fox sniffs shoe\n3. Fox interacts with camera\n\n{\n  \"fox_attributes\": [\"white fur\", \"curved tail\"],\n  \"camera_color\": \"black\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "## The Arctic Explorer\n\nThe Arctic fox padded softly through the colorful tundra, its white coat a stark contrast against the dark rocks. Approaching the photographer, it hesitated, *apprehensive*, before a new scent filled the air. Its eyes focused, *curious*, on the strange object resting on the ground – a camera. The fox crept closer, sniffing tentatively at the lens. It was a silent, watchful eye staring back. Its *inquisitive* nature led it to nudge the cool glass with its nose, captivated by the sight of its own reflection.\n\n“Click, click,” the camera shutter sounded, capturing the moment. *Delighted*, it licked the lens, as if to say hello, then continued on its way, leaving the photographer with a memory worth cherishing.\n\n--End of Story--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"event\": \"fox sniffs and interacts with boot\", \"timestamp\": \"05\", \"object\": \"boot\"}, {\"event\": \"fox plays with stick\", \"timestamp\": \"20\", \"object\": \"stick\"}, {\"event\": \"fox sniffs and interacts with camera\", \"timestamp\": \"45\", \"object\": \"camera\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A white arctic fox cautiously approaches a person in a rocky, mossy environment with a body of water filled with icebergs in the background. The fox sniffs a brown hiking boot and then shifts to interacting with the camera, gently nudging its lens. The curious fox continues its interactions with the camera while in the same rocky and icy backdrop.\n"
        }
    ],
    "short_136": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Timestamp (s) | Character | Action |\n| --- | --- | --- |\n| 2 | blue_fish | move towards skeleton |\n| 4 | skeleton | lift blue_fish up |\n| 18 | blue_fish | walk away with skeleton |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Diary Entry: Today, at the baggage carousel, I watched suitcases loop by. People bustled around, and the conveyor belt hummed. I spotted a skeleton-costumed figure—*confused* if that was “me” coming! Then, they grabbed me, and I felt *startled* but also *relieved* it was all playful. Now, we’re off—what a day! -End of Entry-"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "In the video, a person is standing next to an airport baggage carousel, waiting for their luggage. He is wearing a white mask with a long nose, a black sweater, and yellow-green striped pants. Next to him is a large, stuffed fish. The top of the fish is blue, its belly is scales of pink, yellow, orange, and green, and its fins are green. The fish appears to have an open mouth and a light on the top."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "1. The skeleton looks at the luggage on the conveyor belt. 2. The skeleton turns to watch the blue fish approaching on the conveyor belt. 3. The skeleton hugs the blue fish and then falls down, while the blue fish walks away."
        }
    ],
    "short_137": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "Okay, here's a description of the video according to your instructions:\n\n1.  Lane 2: Jumps into the water\n2.  Lane 3: Jumps into the water\n3.  Lane 4: Jumps into the water\n4.  Lane 5: Jumps into the water\n5.  Lane 6: Jumps into the water\n6.  Lane 7: Jumps into the water\n7.  Lane 8: Jumps into the water\n8.  Lane 1: Jumps into the water"
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "{\n    \"race_details\": {\n        \"pre_race\": [\n            {\"lane\": 1, \"posture\": \"bent over starting block\"},\n            {\"lane\": 2, \"posture\": \"bent over starting block\"},\n            {\"lane\": 3, \"posture\": \"bent over starting block\"},\n            {\"lane\": 4, \"posture\": \"bent over starting block\"},\n            {\"lane\": 5, \"posture\": \"bent over starting block\"},\n            {\"lane\": 6, \"posture\": \"bent over starting block\"},\n            {\"lane\": 7, \"posture\": \"bent over starting block\"},\n            {\"lane\": 8, \"posture\": \"bent over starting block\"}\n        ],\n        \"during_race\": [\n            {\"lane\": \"unknown\", \"time\": \"unknown\"},\n            {\"lane\": \"unknown\", \"time\": \"unknown\"},\n            {\"lane\": \"unknown\", \"time\": \"unknown\"}\n        ],\n        \"post_race\": \"crowd cheers and some spectators take photos\"\n    }\n}"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Lane 1: white cap; Lane 2: white cap; Lane 3: white cap; Lane 4: yellow cap; Lane 5: red cap; Lane 6: white cap; Lane 7: white cap; Lane 8: white cap. The winner is in Lane 4 with a yellow cap."
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "From a spectator's view: *Thrilled*, I watch swimmers launch at the start. They race, arms churning water, until one touches the finish. Cheers erupt as the race ends, capturing the intensity from start to finish.\n\nFrom an official's view: I ensure rules are followed. At the start, swimmers dive; during the race, I monitor strokes and turns. At the finish, I confirm the first to touch, overseeing the race’s fairness from start to finish."
        }
    ],
    "short_138": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"man\": {\n        \"static_attributes\": [\"hat\", \"suit\", \"cane\"],\n        \"actions\": [\"walk\", \"look up\", \"use telescope\"]\n    },\n    \"woman\": {\n        \"static_attributes\": [\"long hair\", \"white dress\", \"red belt\"],\n        \"actions\": [\"fly\", \"hold books\", \"smile\"]\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Step 1: The woman has a sleek ponytail, wears a *flowing white dress with red accents*, and red shoes. She exudes grace as she soars, holding strings attached to colorful books.  \n\nStep 2: [\"wind rushing past\", \"pages fluttering\", \"books humming\"]  \n\nStep 3: *As she flies, she thinks:* “These crimson and sapphire books carry stories that must reach eager minds. With each glide, I’m bridging worlds—my purpose to share wisdom, letting these pages ignite imaginations below. Every book’s a key; together, they unlock endless possibilities.”"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"time\": \"00:00\", \"entity\": \"man\", \"details\": \"starts walking along a path with papers scattered around\"}, {\"time\": \"15:00\", \"entity\": \"woman\", \"details\": {\"book_strings\": \"flies through the sky holding strings of books, moving from right to left\"}}, {\"time\": \"20:00\", \"entity\": \"man\", \"details\": \"looks up at the sky and uses a telescope to observe the woman flying\"}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man walks along a path scattered with papers and bordered by a white fence, stops to look up at floating papers and a woman flying while holding books, then takes out a telescope to observe her."
        }
    ],
    "short_139": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "Okay, I'm ready to analyze the video. Here is the result:\n\nA. Cat 1: Orange tabby, tabby pattern, orange paws. Cat 2: Orange and white tabby, tabby pattern, white paws.\n\n```json\n[\n  {\"cat\": 1, \"actions\": [\n    {\"action\": \"licks foot\", \"duration\": 6.0},\n    {\"action\": \"looks up\", \"duration\": 1.0},\n    {\"action\": \"licks foot\", \"duration\": 7.0}\n  ]},\n  {\"cat\": 2, \"actions\": [\n    {\"action\": \"nuzzles foot\", \"duration\": 2.0},\n    {\"action\": \"walks away\", \"duration\": 3.0}\n  ]}\n]\n```\n\nThe cats appear to be showing affection to the human in the video. The first cat is actively licking the person's foot. The second cat nuzzles the person's foot, which is also a friendly gesture. Given that the first cat spends more time with the human foot, it could be inferred that the first cat has a closer bond to the human."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here's the script:\n\n**Cat Toe Licking Session**\n\nScene: Bright kitchen floor.\n\n00:00 **Ginger**, an orange tabby cat, starts licking a person's toes. \n00:02 **Orange**, an orange and white tabby, also investigates and licks the toes.\n00:16 The person exclaims: \"Hey!\"\n00:17 **Orange** walks away, but **Ginger** continues licking the toes."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"licking human foot\",\n  \"secondary_tags\": [\"affectionate\", \"grooming\", \"close interaction\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Here is a description of the video:\n\nThe video features two orange tabby cats interacting with a person's foot. Initially, both cats sniff and lick the person's toes. Soon after, one of the cats starts nibbling on the toes while the other cat moves away. Eventually, the second cat walks out of the frame, leaving the other to continue licking the foot.\n"
        }
    ],
    "short_140": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"man_in_vest\": {\n        \"clothing\": [\"gray vest\", \"white shirt\", \"black tie\", \"black pants\"],\n        \"actions\": [\"enter room\", \"place box on bed\", \"talk to woman\", \"gesticulate\"]\n    },\n    \"woman\": {\n        \"clothing\": [\"dark blue patterned top\"],\n        \"actions\": [\"sit on bed\", \"talk to man\", \"turn head\"]\n    }\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, here is the video caption you requested.\n\n1.   \"Attic Scene:\nFrom my perch here in the attic, the slanted walls are just above my head, and the light of the oil lamp casts an eerie glow, highlighting the bed’s headboard. The single candle barely illuminates the dusty chest across the room. From my corner, I sometimes hear the wind howling outside, rattling the window in its frame. And when I walk, the floorboards beneath me groan, whispering stories of the house’s past.\"\n\n2.   \n    -   Box on the bed\n    -   His own neck/collar\n\nThe man's mood is agitated and frustrated.\n\n--End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```\n{\n  \"primary_tag\": \"medical disagreement\",\n  \"secondary_tags\": [\"tense\", \"dimly lit\", \"confrontational\"]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "A man carrying a box enters a dimly lit attic room with a candle and a lamp, where a woman sits on a bed. He places the box on the bed and speaks angrily, gesturing emphatically, while the woman listens with a dejected expression. The man’s tone is confrontational, filled with frustration and tension, as he argues about medical treatment and dismisses traditional remedies, emphasizing his belief in “real medicine.” The woman remains mostly silent, looking resigned and upset, as the man’s agitation escalates, highlighting the emotional conflict between them."
        }
    ],
    "short_141": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n  \"children\": [\n    {\n      \"name\": \"Oldest\",\n      \"room_features\": [\"carpeted floor\", \"large bed\"],\n      \"reaction\": \"calm\"\n    },\n    {\n      \"name\": \"Middle\",\n      \"room_features\": [\"toys scattered\", \"wooden dresser\"],\n      \"reaction\": \"resistant\"\n    },\n    {\n      \"name\": \"Youngest\",\n      \"room_features\": [\"green carpet\", \"ceiling fan\"],\n      \"reaction\": \"energetic\"\n    }\n  ],\n  \"summary\": \"carpet\"\n}"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Okay, I will create the requested storyboard script based on the video frames.\n\n| Scene | Environment | Child Reaction |\n| ------------- | ------------- | ------------- |\n| Oldest | Tidy room with a neatly made bed. |  Appears asleep. |\n| Middle | Messy room with toys strewn on the floor and a haphazardly made bed.  | Asleep on the bed, head hanging over the edge. |\n| Youngest | Room with made bed and green carpet. | Throws pillow in the air.  |\n"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here are the descriptions based on the video at 2 frames per second:\n\nA. Oldest:\n1.  The room has a queen-size bed with white sheets, two pillows, a dark grey bed skirt and a white bedspread.\n2.  There is a nightstand to the right of the bed with a lamp and small items on it.\n3.  The man is wearing a white t-shirt and black sweatpants.\n4.  The room is covered in light tan colored carpet.\n\nB. Middle:\n1.  The man wears a navy blue t-shirt, a red eye mask and grey sweatpants. \n2.  The floor is covered in an assortment of toys and miscellaneous items.\n3.  The bed is a tan color with white pillows and a patterned comforter.\n4.  There is a brown dresser in the room.\n5.  The room is covered in green colored carpet.\n\nC. Youngest:\n1.  The room has a queen-size bed with white sheets, two pillows and a light brown bedspread.\n2.  The boy is wearing a black t-shirt.\n3.  The room is covered in green colored carpet.\n"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Oldest: Open door, person makes bed calmly. Mood: calm. Middle: Open door, toys everywhere, person sleeps with arm out. Mood: groggy. Youngest: Open door, person throws pillow. Mood: irritable."
        }
    ],
    "short_142": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"people\": [\n        {\n            \"appearance\": [\"red shirt\", \"black shorts\", \"black shoes\", \"white headband\"],\n            \"actions\": [\"running\"]\n        },\n        {\n            \"appearance\": [\"white shirt\", \"khaki pants\", \"red shoes\"],\n            \"actions\": [\"walking\", \"running\"]\n        },\n        {\n            \"appearance\": [\"blue cardigan\", \"khaki pants\", \"brown shoes\", \"white shirt\", \"black tie\"],\n            \"actions\": [\"walking\", \"standing\"]\n        },\n        {\n            \"appearance\": [\"beige robe\", \"red shirt\", \"gray pants\", \"brown shoes\"],\n            \"actions\": [\"walking\", \"standing\", \"reading\", \"drinking\"]\n        }\n    ],\n    \"text_elements\": [\"your phone\", \"iPhone\", \"Dramatization\", \"faster\", \"apple.com/switch\", \"smoother\", \"privacy matters\"]\n}"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "[{\"id\":1,\"left_movement\":[\"00:00\",\"00:01\",\"00:02\",\"00:03\",\"00:04\",\"00:05\",\"00:06\",\"00:07\",\"00:08\"],\"right_movement\":[\"00:09\",\"00:10\",\"00:11\",\"00:12\"],\"transition_moment\":\"00:09\",\"inference\":\"On - screen text 'faster' suggests iPhone side movement is better as it shows smoother and quicker motion compared to 'your phone' side.\"},{\"id\":2,\"left_movement\":[\"00:15\",\"00:16\",\"00:17\",\"00:18\",\"00:19\",\"00:20\"],\"right_movement\":[\"00:21\",\"00:22\",\"00:23\"],\"transition_moment\":\"00:21\",\"inference\":\"On - screen text 'smoother' indicates iPhone side movement is better as it displays a more fluid motion than 'your phone' side.\"}]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Key selling points: FASTER: a man runs from \"your phone\" side to \"iPhone\" side, leaving a shoe behind; SMOOTHER: a woman walks from \"your phone\" side to \"iPhone\" side with smoother movement; PRIVACY MATTERS: a man with a cup and papers walks from \"your phone\" side to \"iPhone\" side while another man stays on \"your phone\" side --End--"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "When I start running from the gray left side to the beige right side, my movement feels stiff and choppy at first—like each step is a struggle. I’m frustrated, panting, feeling like I can barely keep going. But as I push toward the right, something shifts. The moment I see the word “faster” pop up, it’s like a burst of energy—my stride smooths, and relief washes over me. I glide into the beige side, lighter, freer.\n\nThen I watch the woman in white walk from the gray to the purple side. At first, her steps on the gray side are glitchy, stuttering. But once she crosses into the purple “iPhone” side, her movement transforms—smooth, fluid, effortless. It’s like a switch flips, and she glides without a hitch, every step seamless."
        }
    ],
    "short_143": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "| Stork Action | Target Location | Delivered Item |\n| --- | --- | --- |\n| Fly and land at window | House window | Baby (human) |\n| Fly and land at doorstep | House doorstep | Kittens |\n| Fly and land at doghouse | Doghouse entrance | Puppies |\n| Fly away | Sky | None (after delivery) |"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "The first delivery is to a green house with a brown roof, depositing a baby into a second-story window. The second delivery is to a light blue house, placing a kitten on the brown front doorstep. The final delivery is to a red dog house in a grassy yard, where two puppies are delivered."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[{\"timestamp\": \"5-10\", \"target\": \"window of a house\", \"item\": \"baby\", \"success\": true}, {\"timestamp\": \"12-17\", \"target\": \"mat in front of a house door\", \"item\": \"kittens\", \"success\": true}, {\"timestamp\": \"17-22\", \"target\": \"doghouse\", \"item\": \"puppies\", \"success\": true}]"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Storks fly in the sky with bundles. One stork delivers a bundle to a house window. Another stork delivers a bundle to a red doghouse."
        }
    ],
    "short_144": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "{\n    \"game_board\": \"WINNER FOOSBALL\",\n    \"tokens\": [\n        {\"color\": \"black\", \"initial_position\": \"top\"},\n        {\"color\": \"white\", \"initial_position\": \"bottom\"}\n    ],\n    \"player_hands\": 2\n}"
        },
        {
            "field": "For Sports Analytics",
            "prompt_id": "02",
            "response": "Initial phase (0-10s): Black dominates as top hands push black tokens, creating an early offensive. White tokens are stationary, so black’s quantity and movement make it the focal color.\n\nMiddle phase (10-25s): White tokens activate; bottom hands launch whites, colliding with blacks. This exchange—white tokens countering black’s initial push—triggers the shift, balancing token interaction.\n\nFinal phase (25-35s): White gains control. Bottom hands sustain white token momentum, outnumbering blacks. Consistent white launches overwhelm black’s defense, so white will likely maintain dominance due to sustained offensive pressure."
        },
        {
            "field": "For Instructional",
            "prompt_id": "03",
            "response": "A. At 12 seconds:\n- Number of white pieces on the white side: 4\n- Number of black pieces on the white side: 2\n- Direction of launch relative to the center: Right\n- Color of the piece being launched: White\n\nB. At 21 seconds:\n- Number of white pieces on the white side: 4\n- Number of black pieces on the white side: 2\n- Direction of launch relative to the center: Left\n- Color of the piece being launched: White\n\nC. At 26 seconds:\n- Number of white pieces on the white side: 3\n- Number of black pieces on the white side: 2\n- Direction of launch relative to the center: Center\n- Color of the piece being launched: White"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "The game begins with hands poised over black and white tokens, tension thick. Fingers push tokens—clicking echoes—as they slide, collide, and ricochet. Excitement spikes with each rapid exchange, tokens clattering across the board. Hearts race as strategies clash, every move a gamble. Will the black tokens dominate, or will white seize victory? The pace quickens, clicks growing frantic. Who will win?"
        }
    ],
    "short_145": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. A news anchor reports on Kristen Welker's exclusive interview with Emmanuel Macron. 2. The scene shifts to show Welker interviewing Macron in a formal room. 3. Macron responds to questions about peace talks and interactions with Trump.\n{\n    \"Kristen Welker\": {\n        \"clothing\": \"Dark blue suit with purple inner layer\",\n        \"role\": \"Moderator of Meet the Press, interviewer\"\n    },\n    \"Emmanuel Macron\": {\n        \"clothing\": \"Dark suit with white shirt and dark tie\",\n        \"role\": \"French President, interviewee\"\n    }\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "02",
            "response": "News Summary: After White House peace talks, **Kristen Welker** interviews **Emmanuel Macron**. Welker questions Macron about Trump’s “hot mic” comment and ceasefire for a trilateral meeting. Macron, with formal gestures, emphasizes a compliant deal for peace as great news. --End--"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[00:00:00 to 00:00:42] The uploader is promoting English learning. The video shows the interior of an opulent room in the United States during the interview of the French President. The room features two lounge chairs, a sofa, an end table, a floor lamp, a painting, and a flag. The interviewer is wearing a ring on one of her fingers and has manicured fingernails."
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "## Scene 1\noutdoor, two men, speak  \n\n## Scene 2\nindoor, two people, talk"
        }
    ],
    "short_146": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "```json\n[\n  {\n    \"Action\": \"raise\",\n    \"Bet Amount\": 75\n  },\n  {\n    \"Action\": \"call\",\n    \"Bet Amount\": 75\n  },\n  {\n    \"Action\": \"fold\",\n    \"Bet Amount\": 0\n  },\n  {\n    \"Action\": \"check\",\n    \"Bet Amount\": 0\n  },\n  {\n    \"Action\": \"check\",\n    \"Bet Amount\": 0\n  },\n  {\n    \"Action\": \"bet\",\n    \"Bet Amount\": 100\n  },\n  {\n    \"Action\": \"all in\",\n    \"Bet Amount\": 146\n  },\n  {\n    \"Action\": \"call\",\n    \"Bet Amount\": 146\n  },\n  {\n    \"Action\": \"fold\",\n    \"Bet Amount\": 0\n  },\n  {\n    \"Action\": \"fold\",\n    \"Bet Amount\": 0\n  },\n  {\n    \"Action\": \"win\",\n    \"Bet Amount\": 536\n  }\n]\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "02",
            "response": "Okay, here's the description of the dealer's perspective, following your instructions:\n\n1.  I looked at my cards and saw Aces, then raised to 75. A few players called.\n\n2.  I laid the flop down, and I saw Q, 3, Ace, then the river, 9. Everyone checked.\n\n3. I laid the river card down, the 3. I made Aces full and won the pot."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "Okay, here is the JSON object based on your instructions:\n\n```json\n{\n  \"primary_tag\": \"Poker player wins big round\",\n  \"key_events\": [\n    {\n      \"time\": \"00:00\",\n      \"description\": \"Player receives two aces and raises\"\n    },\n    {\n      \"time\": \"00:50\",\n      \"description\": \"Player makes full house and wins\"\n    }\n  ]\n}\n```"
        },
        {
            "field": "For Generation",
            "prompt_id": "04",
            "response": "Here are the video captions:\n\n[00:00:04 to 00:00:08]\nFirst Person: I have pocket Aces so I raise to 75, hoping someone else will come along for the ride\n\n[00:00:31 to 00:00:44]\nThird Person: I see the pot going up, and based on the prior aggressive betting I assume my pocket pair will fall short."
        }
    ],
    "short_147": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "A.\n```json\n{\n  \"step_number\": 1,\n  \"tools_used\": [\"**hands**\", \"**metal bowl**\"],\n  \"approximate_duration\": \"9s\",\n  \"bowl_material\": \"metal\"\n}\n```\nB.\n```json\n{\n  \"step_number\": 2,\n  \"tools_used\": [\"**hands**\", \"**gloves**\", \"**wooden bowl**\"],\n  \"approximate_duration\": \"6s\",\n  \"bowl_material\": \"wooden\"\n}\n```\nC.\n```json\n{\n  \"step_number\": 3,\n  \"tools_used\": [\"**hands**\", \"**glass jar**\"],\n  \"approximate_duration\": \"7s\"\n}\n```\nD.\n```json\n{\n  \"step_number\": 4,\n  \"tools_used\": [\"**chopsticks**\", \"**pink ceramic bowl**\", \"**tray**\", \"**parchment paper**\"],\n  \"approximate_duration\": \"6s\",\n  \"bowl_material\": \"ceramic\"\n}\n```\nThe mixed rose jam appears purple because the *anthocyanin pigments* naturally present in the rose petals react with the acidic lemon juice and sugar. This *chemical reaction* causes a shift in the pigment's color, transforming the petals from their original red to a deep, rich purple."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "- I see vibrant red rose petals filling the tray, ready for use.\n- The air is fragrant with fresh roses as I handle the petals gently.\n- My fingers feel the soft, delicate texture of the rose petals as I sort them."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "[\n    {\"timestamp\": \"00:01\", \"object_interacted\": \"tray of roses\", \"action_performed\": \"place on countertop\"},\n    {\"timestamp\": \"00:02\", \"object_interacted\": \"bowl\", \"action_performed\": \"place on countertop\"},\n    {\"timestamp\": \"00:03\", \"object_interacted\": \"rose\", \"action_performed\": \"tear petals\"},\n    {\"timestamp\": \"00:06\", \"object_interacted\": \"rose petals\", \"action_performed\": \"put in bowl\"}\n]"
        },
        {
            "field": "For Instructional",
            "prompt_id": "04",
            "response": "The filling of one type of flower pastry has three kinds of ingredients, namely rose petals, sugar, and cooked low - gluten flour. A total of 12 delicious flower pastries are made."
        }
    ],
    "short_148": [
        {
            "field": "For Sports Analytics",
            "prompt_id": "01",
            "response": "Rally Breakdown:\n1. Player in yellow serves the shuttlecock.\n2. Player in black returns the serve.\n3. Player in yellow hits a forehand shot.\n4. Player in black misses the return.\n\n{\n  \"winner\": \"Player in yellow\",\n  \"decisive_action\": \"Player in yellow hits a forehand shot.\"\n}"
        },
        {
            "field": "For Understanding",
            "prompt_id": "02",
            "response": "16-10 to 0-0 | 0-0 to 5-0 | 5-0 to 6-0 | [{\"object_name\": \"net\", \"color\": \"white\"}, {\"object_name\": \"scoreboard\", \"color\": \"black\"}]"
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "There are 12 lines of subtitles in the video.\n1. 噢来了，噢噢！\n2. 林丹跃起，然后暴扣。他把李宗伟调动地满场跑，然后一记扣杀，砰！\n3. 这（一百万令吉）相当于三十万美元\n4. 噢！林丹抢网非常快！来自左手的扑杀！\n5. 他想从北京带着金牌回家\n6. 林丹的一个杀上网\n7. 男双比赛也是，头号种子印尼组合对战二号种子中国组合"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "比赛精彩瞬间:1. 穿黄色运动服的选手灵活移动并挥拍击球；2. 穿黑色运动服的选手快速回击，双方展开多回合对拉；3. 黄色运动服选手跃起暴扣，展现强大进攻力。"
        }
    ],
    "short_149": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. The three main buildings in the background are: a store with a teal and brick facade, a purple building with graffiti, and a light - colored building with a \"Eastside Pharmacy\" sign.\n\n| Entity         | Color                           | Location                     |\n|----------------|---------------------------------|------------------------------|\n| Donut truck    | Multicolored (with donut ads)   | Right side of the street     |\n| Neon sign      | Pink                            | On the purple building       |\n| Fire hydrant   | Red                             | Near the teal - fronted store|"
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "As I stride through the thick smoke, its acrid scent fills my nostrils, the gritty particles cling to my skin, and the hazy veil blurs my vision. Each step feels heavy, but I push forward, determined.  \n\nI reach for my mask, knowing putting it on is more than just a move—it’s a shield, a symbol of resolve. I need to feel hidden, yet empowered, ready to face whatever comes. Emotions surge—focus, duty, a hint of defiance. The mask settles, and I exhale, steeling myself.  \n\nSparks erupt behind us, bright and sharp. My first thought: Stay alert—they could be a distraction or a threat. Then, a flicker of irritation—why now? But I push it down, keeping my gaze forward. We can’t let sparks—or anything—break our stride. We’ve got a job to do, and I won’t let chaos stop us."
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "{\n  \"primary_tag\": \"two characters walking\",\n  \"secondary_tags\": [\"urban setting\", \"action sequence\", \"costumed figures\"]\n}"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Video Narrative: Wolverine and Deadpool walk into the frame, amidst smoke rising from the ground. They both walk toward the camera. Wolverine is on the left of the screen, wearing his iconic yellow and blue suit. Deadpool is on the right, in his red and black costume, complete with katanas strapped to his back. As they reach the center, Wolverine pauses and puts on his signature mask, looking at Deadpool as he does.\n\nWolverine seems determined, stepping confidently forward. Deadpool, with his stoic mask, is a bit more difficult to read, but his posture suggests anticipation. The scene is riddled with bullet holes, conveying a recent conflict. Overall, the mood is tense, but there's an underlying sense of anticipation as these two iconic characters prepare for what's next.\n --End--"
        }
    ],
    "short_150": [
        {
            "field": "For Understanding",
            "prompt_id": "01",
            "response": "1. Surprisingly, phytoplankton also play a vital role in cloud formation.\n2. Moisture evaporating from the ocean\n3. condenses around tiny particles created by the plankton.\n4. These droplets combine to grow into colossal clouds.\n5. They can rise 20 kilometers into the atmosphere."
        },
        {
            "field": "For Generation",
            "prompt_id": "02",
            "response": "Dark gray thunderheads drift over a calm ocean; text explains phytoplankton’s role in cloud formation. {\"particle_types\": [\"phytoplankton byproduct\"]} ==close-up=="
        },
        {
            "field": "For Retrieval",
            "prompt_id": "03",
            "response": "```json\n{\n  \"primary_tag\": \"Cumulus clouds form over the ocean.\",\n  \"secondary_tags\": [\n    \"Atmospheric\",\n    \"Cloudy\",\n    \"Sky\"\n  ]\n}\n```"
        },
        {
            "field": "For Communication",
            "prompt_id": "04",
            "response": "Clouds billow upward, growing larger and merging. They spread and shift across the sky, forming massive shapes. The clouds continue to rise and expand, filling the sky."
        }
    ]
}